{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9a7198-e5a9-42af-b8af-f44b7d937818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://support.google.com/trends/answer/12764470?hl=en#:~:text=You%20can%20access%20anonymized%2C%20indexed,from%20the%20past%2030%20days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d939b-c107-4fb4-a428-b2d56d1293a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Download Google Trends data (finicky so separate from download_data.py for now)\"\"\"\n",
    "\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import MonthBegin, MonthEnd\n",
    "import plotly.express as px\n",
    "from pytrends.request import TrendReq\n",
    "from pytrends.exceptions import ResponseError\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Load data\n",
    "gt_monthly_files = glob.glob('gt_monthly_*.csv')\n",
    "gt_monthly_latest = max(gt_monthly_files, key=os.path.getctime)\n",
    "gt_monthly_raw = pd.read_csv(gt_monthly_latest, parse_dates=['start_date','end_date'])\n",
    "\n",
    "gt_weekly_files = glob.glob('gt_weekly_*.csv')\n",
    "gt_weekly_latest = max(gt_weekly_files, key=os.path.getctime)\n",
    "gt_weekly_raw = pd.read_csv(gt_weekly_latest, parse_dates=['start_date','end_date'])\n",
    "\n",
    "gt_daily_files = glob.glob('gt_daily_*.csv')\n",
    "gt_daily_latest = max(gt_daily_files, key=os.path.getctime)\n",
    "gt_daily_raw = pd.read_csv(gt_daily_latest, parse_dates=['date'])\n",
    "\n",
    "params_return_empty_df_files = glob.glob('params_return_empty_df_*.txt')\n",
    "params_return_empty_df_files_latest = max(params_return_empty_df_files, key=os.path.getctime)\n",
    "with open(params_return_empty_df_files_latest, \"r\", encoding=\"utf-8\") as f:\n",
    "    params_return_empty_df_raw = [line.strip() for line in f]\n",
    "\n",
    "# Config\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',force=True)\n",
    "\n",
    "pytrends = TrendReq(retries=8, backoff_factor=2)\n",
    "\n",
    "past_weekly_requests = set(gt_weekly_raw['pytrends_params'])\n",
    "# params_return_empty_df_raw only in daily for now\n",
    "past_daily_requests = set(list(gt_daily_raw['pytrends_params'])+params_return_empty_df_raw) \n",
    "\n",
    "new_keyword = None\n",
    "\n",
    "if new_keyword:\n",
    "    my_kws = set(list(gt_daily_raw['search_term'].unique())+[new_keyword])\n",
    "else:\n",
    "    my_kws = set(gt_daily_raw['search_term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabace4-36b9-4926-9467-d1bd8992d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build year ranges to pull weekly data (Google Trends returns weekly data when a full year\n",
    "# is requested). Check if we already have the data for the keyword and year, don't need to\n",
    "# make the request again.\n",
    "years = list(range(2004, datetime.now().year+1))\n",
    "year_ranges = [(f'{year}-01-01 {year}-12-31') for year in years]\n",
    "\n",
    "logging.info('Since 2004 there are %d year ranges', len(year_ranges))\n",
    "kw_yrc = {}\n",
    "kw_yrtd = {}\n",
    "for kw in my_kws:\n",
    "    kw_data = gt_weekly_raw.loc[gt_weekly_raw['search_term']==kw]\n",
    "\n",
    "    year_ranges_completed = kw_data['pytrends_params'].str.extract(r'\"(\\d{4}-\\d{2}-\\d{2} \\d{4}-\\d{2}-\\d{2})\"')[0]\n",
    "    year_ranges_completed = list(set(year_ranges_completed))\n",
    "\n",
    "    kw_yrc[kw] = year_ranges_completed\n",
    "    logging.info('Already have %d year ranges for \"%s\"', len(kw_yrc[kw]), kw)\n",
    "\n",
    "    year_ranges_to_do = [x for x in year_ranges if x not in kw_yrc[kw]]\n",
    "    year_ranges_to_do.sort()\n",
    "\n",
    "    kw_yrtd[kw] = year_ranges_to_do\n",
    "    logging.info('Need to get %d year ranges for \"%s\"', len(year_ranges_to_do), kw)\n",
    "\n",
    "# Build week ranges to pull daily data (Google Trends returns daily data when one week is\n",
    "# requested) Check if we already have the data for the keyword and week, don't need to make\n",
    "# the request again.\n",
    "week_ranges = list(gt_weekly_raw['start_date'].astype(str)+\" \"+gt_weekly_raw['end_date'].astype(str))\n",
    "week_ranges = list(set(week_ranges))\n",
    "\n",
    "params_return_empty_df_dict ={}\n",
    "for kw in my_kws:\n",
    "    extracted_dates = [re.search(r'\"(\\d{4}-\\d{2}-\\d{2} \\d{4}-\\d{2}-\\d{2})\"', s) for s in params_return_empty_df_raw if kw in s]\n",
    "    params_return_empty_df_dict[kw] = [match.group(1) for match in extracted_dates]\n",
    "\n",
    "logging.info('Since 2004 there are %d week ranges', len(week_ranges))\n",
    "kw_wrc = {}\n",
    "kw_wrtd = {}\n",
    "for kw in my_kws:\n",
    "    kw_data = gt_daily_raw.loc[gt_daily_raw['search_term']==kw]\n",
    "\n",
    "    week_ranges_completed = kw_data['pytrends_params'].str.extract(r'\"(\\d{4}-\\d{2}-\\d{2} \\d{4}-\\d{2}-\\d{2})\"')[0]\n",
    "    week_ranges_completed = list(set(week_ranges_completed))\n",
    "\n",
    "    kw_wrc[kw] = week_ranges_completed\n",
    "    logging.info('Already have %d week ranges for \"%s\"', len(kw_wrc[kw]), kw)\n",
    "\n",
    "    week_ranges_to_do = [x for x in week_ranges if x not in kw_wrc[kw]]\n",
    "    week_ranges_to_do.sort()\n",
    "\n",
    "    kw_wrtd[kw] = week_ranges_to_do\n",
    "    logging.info('Need to get %d week ranges for \"%s\"', len(week_ranges_to_do), kw)\n",
    "\n",
    "    if params_return_empty_df_dict[kw]:\n",
    "        logging.info(\n",
    "            'But %d params returned empty data frames, so just need %d week ranges for \"%s\"',\n",
    "            len(params_return_empty_df_dict[kw]),\n",
    "            len(week_ranges_to_do)-len(params_return_empty_df_dict[kw]),\n",
    "            kw\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe3d0d-597a-4458-b1a0-38b0ee5fe238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the interest index by month since 2004\n",
    "dat = []\n",
    "for kw in my_kws:\n",
    "    try:\n",
    "        pytrends.build_payload([kw], cat=0, timeframe=f'2004-01-01 {datetime.now().strftime(\"%Y-%m-%d\")}', geo=\"US\")\n",
    "        df = pytrends.interest_over_time()\n",
    "        df = df.reset_index()\n",
    "        df = df.rename(columns={'date':'start_date', kw:'index'})\n",
    "        df['end_date'] = df['start_date'] + MonthEnd(0)\n",
    "        df['search_term'] = kw\n",
    "        df['pytrends_params'] = str(pytrends.token_payload)\n",
    "\n",
    "        dat.append(df)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(\"RequestException: %s\", e)\n",
    "\n",
    "    except ResponseError as e:\n",
    "        logging.error(\"ResponseError: %s\", e)\n",
    "\n",
    "if dat:\n",
    "    gt_monthly_new = pd.concat(dat)\n",
    "\n",
    "    gt_monthly = pd.concat([gt_monthly_raw,gt_monthly_new])\n",
    "    gt_monthly = gt_monthly.drop_duplicates()\n",
    "\n",
    "    gt_monthly.to_csv(f'gt_monthly_{datetime.today().strftime(\"%Y%m%d\")}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271cbc81-1a92-4f2a-af32-46540dcc335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the interest index by week for each year for the selected keywords\n",
    "for kw in my_kws:\n",
    "    try:\n",
    "        dat = []\n",
    "        for one_year_timeframe in kw_yrtd[kw]:\n",
    "            pytrends.build_payload([kw], cat=0, timeframe=one_year_timeframe, geo=\"US\")\n",
    "\n",
    "            if str(pytrends.token_payload) not in past_weekly_requests:\n",
    "                weekly_us = pytrends.interest_over_time()\n",
    "                weekly_us = weekly_us.reset_index()\n",
    "                weekly_us = weekly_us.rename(columns={'date':'start_date', kw:'index'})\n",
    "                weekly_us['end_date'] = weekly_us['start_date'] + pd.Timedelta(days=6)\n",
    "                weekly_us['search_term'] = kw\n",
    "                weekly_us['pytrends_params'] = str(pytrends.token_payload)\n",
    "\n",
    "                dat.append(weekly_us)\n",
    "            time.sleep(1)\n",
    "\n",
    "    finally:\n",
    "        if dat:\n",
    "            gt_weekly_new = pd.concat(dat)\n",
    "\n",
    "            gt_weekly = pd.concat([gt_weekly_raw,gt_weekly_new])\n",
    "            gt_weekly = gt_weekly.drop_duplicates()\n",
    "\n",
    "            gt_weekly.to_csv(f'gt_weekly_{datetime.today().strftime(\"%Y%m%d\")}.csv', index=False)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867a60d-52a4-487e-b612-9241f23cc126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the interest index by day for each week for the selected keyword\n",
    "params_return_empty_df_new = []\n",
    "for kw in my_kws:\n",
    "    try:\n",
    "        dat = []\n",
    "        for one_week_timeframe in kw_wrtd[kw]:\n",
    "            if one_week_timeframe in params_return_empty_df_dict[kw]:\n",
    "                continue\n",
    "            pytrends.build_payload([kw], cat=0, timeframe=one_week_timeframe, geo=\"US\")\n",
    "            logging.info('%s \"%s\" Payload built successfully', one_week_timeframe, kw)\n",
    "\n",
    "            if str(pytrends.token_payload) not in past_daily_requests:\n",
    "                logging.info(\"This week is new, gathering interest_over_time...\")\n",
    "\n",
    "                for _attempt in range(3):\n",
    "                    try:\n",
    "                        daily_us = pytrends.interest_over_time()\n",
    "                        daily_us = daily_us.reset_index()\n",
    "                        daily_us = daily_us.rename(columns={kw:'index'})\n",
    "                        daily_us['search_term'] = kw\n",
    "                        daily_us['pytrends_params'] = str(pytrends.token_payload)\n",
    "                        dat.append(daily_us)\n",
    "                        logging.info(\"Success!\")\n",
    "                        if len(daily_us)==0:\n",
    "                            params_return_empty_df_new.append(str(pytrends.token_payload))\n",
    "                        break\n",
    "                    except requests.exceptions.RequestException as e:\n",
    "                        logging.error('RequestException: %s',e)\n",
    "                        if _attempt<2:\n",
    "                            logging.error('Sleeping for 71s and then trying attempt %d...',_attempt+2)\n",
    "                            time.sleep(71)\n",
    "                    except ResponseError as e:\n",
    "                        logging.error(\"ResponseError: %s\", e)\n",
    "                        if _attempt<2:\n",
    "                            logging.error('Sleeping for 71s and then trying attempt %d...',_attempt+2)\n",
    "                            time.sleep(71)\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "    finally:\n",
    "        print(f\"hit finally block here on kw={kw}\")\n",
    "        if dat:\n",
    "            gt_daily_new = pd.concat(dat)\n",
    "\n",
    "            gt_daily = pd.concat([gt_daily_raw,gt_daily_new])\n",
    "            gt_daily = gt_daily.drop_duplicates()\n",
    "\n",
    "            gt_daily.to_csv(f'gt_daily_{datetime.today().strftime(\"%Y%m%d\")}.csv', index=False)\n",
    "\n",
    "        if params_return_empty_df_new:\n",
    "            params_return_empty_df = params_return_empty_df_raw+params_return_empty_df_new\n",
    "            with open(f\"params_return_empty_df_{datetime.today().strftime(\"%Y%m%d\")}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.writelines(f\"{item}\\n\" for item in params_return_empty_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669cdb68-dbad-42a9-b3a3-a64ce3657876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up (just uses raw files)\n",
    "index_of_month = gt_monthly_raw.copy()\n",
    "index_of_month['params_date_range'] = index_of_month['pytrends_params'].str.extract(r'\"(\\d{4}-\\d{2}-\\d{2} \\d{4}-\\d{2}-\\d{2})\"')[0]\n",
    "index_of_month = index_of_month.loc[index_of_month['params_date_range']==max(index_of_month['params_date_range'])]\n",
    "index_of_month = index_of_month.rename(columns={'start_date':'month_start','index':'index_of_month'})\n",
    "index_of_month['month_end'] = index_of_month['month_start'] + MonthEnd(0)\n",
    "index_of_month = index_of_month[['month_start','index_of_month','search_term']]\n",
    "index_of_month = index_of_month.drop_duplicates(subset=['month_start', 'search_term'], keep='first')\n",
    "\n",
    "# there are duplicate start_date/search_term rows because weeks can be spread across different years\n",
    "# smart way to adjust this would be weighted average based on days of week in each year\n",
    "# just keeping the first row for now, come back to this later\n",
    "index_of_week = gt_weekly_raw.drop_duplicates(subset=['start_date', 'search_term'], keep='first')\n",
    "index_of_week = index_of_week[['start_date','index','search_term']]\n",
    "index_of_week = index_of_week.rename(columns={'start_date':'week_start_sun','index':'index_of_week'})\n",
    "\n",
    "index_of_day = gt_daily_raw.copy()\n",
    "index_of_day['day_of_week'] = index_of_day['date'].dt.day_name()\n",
    "index_of_day['week_start_sun'] = index_of_day[\"date\"].dt.to_period(\"W-SAT\").dt.start_time\n",
    "index_of_day['month_start'] = index_of_day[\"date\"] - MonthBegin(1)\n",
    "\n",
    "gt_adjusted = index_of_day.merge(index_of_week, how='left', on=['week_start_sun','search_term'])\n",
    "gt_adjusted = gt_adjusted.merge(index_of_month, how='left', on=['month_start','search_term'])\n",
    "\n",
    "gt_adjusted['index'] = gt_adjusted['index']*gt_adjusted['index_of_week']/100\n",
    "gt_adjusted['index'] = gt_adjusted['index']*gt_adjusted['index_of_month']/100\n",
    "gt_adjusted = gt_adjusted[['date','day_of_week','search_term','index']]\n",
    "\n",
    "gt_adjusted.to_csv(f'gt_adjusted_{datetime.today().strftime(\"%Y%m%d\")}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eecd36-6947-4b2a-ad96-25d0c9be4567",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_adjusted_pivot = gt_adjusted.pivot(index='date', columns='search_term',values=['index'])\n",
    "\n",
    "gt_adjusted_pivot.columns = ['_'.join(col).strip() for col in gt_adjusted_pivot.columns.values]\n",
    "gt_adjusted_pivot = gt_adjusted_pivot.reset_index().rename_axis(None, axis=1)\n",
    "gt_adjusted_pivot = gt_adjusted_pivot.rename(columns={'date': 'Date'})\n",
    "gt_adjusted_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720a001f-a05e-45e1-acf9-9a87ed9d04d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "# gt_monthly_new   # just swith to use monthly new! always want the lastest anyway\n",
    "# gt_monthly_raw.loc[gt_monthly_raw['start_date']==\"2004-03-01\"]\n",
    "# xx = gt_monthly_raw.loc[gt_monthly_raw['search_term']==\"AAPL\"].sort_values(by='start_date')\n",
    "# xx['pytrends_params'][255]\n",
    "\n",
    "# gt_weekly_raw.loc[gt_weekly_raw['search_term']==\"AAPL\"]\n",
    "# gt_weekly_raw.sort_values(by='start_date')\n",
    "# gt_weekly_raw.loc[gt_weekly_raw['start_date']==\"2004-04-07\"]\n",
    "\n",
    "# gt_daily_raw.sort_values(by='date')\n",
    "# gt_daily_raw.loc[gt_daily_raw['date']==\"2004-03-26\"]\n",
    "# gt_daily_raw.loc[gt_daily_raw['search_term']==\"AAPL\"].sort_values(by='date')\n",
    "\n",
    "# index_of_week.loc[index_of_week['week_start_sun']==\"2004-03-21\"]\n",
    "# index_of_day.loc[index_of_day['date']==\"2004-03-26\"]\n",
    "\n",
    "# gt_adjusted.loc[gt_adjusted['date']==\"2004-03-26\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690fb9a5-e857-4228-9ca4-eceaa24e98e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_kw = \"AAPL\"\n",
    "\n",
    "for_monthly = gt_monthly_new.loc[gt_monthly_new['search_term']==selected_kw].sort_values(by='start_date')\n",
    "for_daily = gt_adjusted.loc[gt_adjusted['search_term']==selected_kw].sort_values(by='date')\n",
    "\n",
    "fig1 = px.line(for_monthly, x=\"start_date\", y=\"index\", labels={'start_date':'Month'},title=f'{selected_kw} Monthly index')\n",
    "fig2 = px.line(for_daily, x=\"date\", y=\"index\",labels={'date':'Date','index':'Scaled index'},title=f'{selected_kw} Daily scaled index')\n",
    "fig3 = px.box(index_of_day, x=\"day_of_week\", y=\"index\",labels={'day_of_week':'Day of week'},title=f'{selected_kw} index by Day of week')\n",
    "fig3.update_xaxes(categoryorder='array', categoryarray=['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'])\n",
    "fig1.show()\n",
    "fig2.show()\n",
    "fig3.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

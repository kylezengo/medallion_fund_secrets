{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a434b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import strat_defs # custom functions\n",
    "import prep_data\n",
    "\n",
    "sp_df_files = glob.glob('sp_df_*.csv')\n",
    "sp_df_latest = max(sp_df_files, key=os.path.getctime)\n",
    "sp_df_raw = pd.read_csv(sp_df_latest, parse_dates=['Date added'])\n",
    "\n",
    "stocks_df, wiki_pageviews, ffr_raw, weather, gt_adjusted = prep_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88598b0-2602-4f9a-bec4-fd0eeecd5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_date = \"2015-07-01\"\n",
    "exclude_vars = (\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\")\n",
    "\n",
    "initial_train_period = 2140 # 2015-07-01 start predicting in 2024\n",
    "\n",
    "# Stocks to test\n",
    "these_dont_work = ['BF.B', 'BRK.B', 'GOOG', 'FOX', 'NWS']\n",
    "to_test = list(sp_df_raw.loc[sp_df_raw['Date added']<=s_date,'Symbol'])\n",
    "to_test = [x for x in to_test if x not in these_dont_work]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ac32a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mMMM\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5300324675324676, time = 8.565546989440918\n",
      "\n",
      "\u001b[1mABT\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5385551948051948, time = 13.258584022521973\n",
      "\n",
      "\u001b[1mABBV\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5430194805194806, time = 12.903130054473877\n",
      "\n",
      "\u001b[1mACN\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5499188311688312, time = 13.17265772819519\n",
      "\n",
      "\u001b[1mADBE\u001b[0m\n",
      "Training on data set with 2465 rows and 28 features\n",
      "Logit score = 0.5369318181818182, time = 15.713664054870605\n",
      "\n",
      "\u001b[1mAES\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5271915584415584, time = 14.146892786026001\n",
      "\n",
      "\u001b[1mAFL\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5625, time = 12.656495094299316\n",
      "\n",
      "\u001b[1mA\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5430194805194806, time = 7.200598955154419\n",
      "\n",
      "\u001b[1mAPD\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5430194805194806, time = 15.155848979949951\n",
      "\n",
      "\u001b[1mAKAM\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5385551948051948, time = 12.64089584350586\n",
      "\n",
      "\u001b[1mALLE\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5292207792207793, time = 12.619155883789062\n",
      "\n",
      "\u001b[1mALL\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5353084415584416, time = 7.021751880645752\n",
      "\n",
      "\u001b[1mGOOGL\u001b[0m\n",
      "Training on data set with 2465 rows and 28 features\n",
      "Logit score = 0.5369318181818182, time = 12.742753028869629\n",
      "\n",
      "\u001b[1mMO\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5487012987012987, time = 12.94776701927185\n",
      "\n",
      "\u001b[1mAMZN\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5568181818181818, time = 12.591730117797852\n",
      "\n",
      "\u001b[1mAEE\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5450487012987013, time = 12.784030199050903\n",
      "\n",
      "\u001b[1mAEP\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.549512987012987, time = 12.682819128036499\n",
      "\n",
      "\u001b[1mAXP\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5243506493506493, time = 15.768457889556885\n",
      "\n",
      "\u001b[1mAIG\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5284090909090909, time = 12.516451835632324\n",
      "\n",
      "\u001b[1mAMT\u001b[0m\n",
      "Training on data set with 2465 rows and 28 features\n",
      "Logit score = 0.5373376623376623, time = 13.711375951766968\n",
      "\n",
      "\u001b[1mAMP\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5275974025974026, time = 13.795675039291382\n",
      "\n",
      "\u001b[1mAME\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5373376623376623, time = 12.651792049407959\n",
      "\n",
      "\u001b[1mAMGN\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.536525974025974, time = 6.986578941345215\n",
      "\n",
      "\u001b[1mAPH\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5458603896103896, time = 12.835889101028442\n",
      "\n",
      "\u001b[1mADI\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit score = 0.5284090909090909, time = 12.921689987182617\n",
      "\n",
      "\u001b[1mAON\u001b[0m\n",
      "Training on data set with 2465 rows and 29 features\n",
      "Logit "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "strat_bds, strat_mods = {}, {}\n",
    "for ticker in to_test:\n",
    "    print(f'\\n\\033[1m{ticker}\\033[0m')\n",
    "    prepd_data = prep_data.prep_data(\n",
    "        stocks_df,\n",
    "        wiki_pageviews,\n",
    "        ffr_raw,\n",
    "        weather,\n",
    "        gt_adjusted,\n",
    "        config=prep_data.IndicatorConfig(ticker=ticker),\n",
    "        drop_tickers=True\n",
    "    )\n",
    "\n",
    "    df_for_chart = prepd_data.loc[prepd_data['Date']>=s_date].reset_index(drop=True)\n",
    "    df_for_chart = df_for_chart.drop(columns=[\n",
    "        col for col in df_for_chart.columns \n",
    "        if any(col.startswith(prefix) for prefix in exclude_vars) and col != \"Adj Close_\"+ticker\n",
    "    ])\n",
    "    df_for_chart = df_for_chart.dropna(axis='columns') # drop columns with an na\n",
    "\n",
    "    print(f'Training on data set with {len(df_for_chart)} rows and {df_for_chart.shape[1]-1} features')\n",
    "    print(\"Logit\", end=\" \")\n",
    "    start_time = time.time()\n",
    "    backtested_data,model,score = strat_defs.backtest_strategy(\n",
    "        data=df_for_chart,\n",
    "        strategy=\"Logit\",\n",
    "        target='Adj Close',\n",
    "        ticker=ticker,\n",
    "        config=strat_defs.BacktestConfig(),\n",
    "        initial_train_period=initial_train_period,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    end_time = time.time()    \n",
    "    print(f'score = {score}, time = {end_time-start_time}')\n",
    "\n",
    "    strat_bds[f'{ticker}_Logit'] = backtested_data\n",
    "    strat_mods[f'{ticker}_Logit'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6204d65-c382-46f2-a58f-732657756631",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepd_data = prep_data.prep_data(\n",
    "    stocks_df,\n",
    "    wiki_pageviews,\n",
    "    ffr_raw,\n",
    "    weather,\n",
    "    gt_adjusted,\n",
    "    config=prep_data.IndicatorConfig(ticker=\"SPY\"),\n",
    "    drop_tickers=True\n",
    ")\n",
    "\n",
    "df_for_chart = prepd_data.loc[prepd_data['Date']>=s_date].reset_index(drop=True)\n",
    "\n",
    "spy_data,spy_model,spy_score = strat_defs.backtest_strategy(\n",
    "    data=df_for_chart.dropna(axis='columns'),\n",
    "    strategy=\"Hold\",\n",
    "    target='Adj Close',\n",
    "    ticker=\"SPY\",\n",
    "    config=strat_defs.BacktestConfig(),\n",
    "    initial_train_period=initial_train_period,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f75ec0-98a0-485d-9be3-be2fcb22f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_build = strat_bds[to_test[0]+\"_Logit\"][['Date']] # start with just date column\n",
    "\n",
    "# Get results for all tickers in to_test\n",
    "for ticker in to_test:\n",
    "    df = strat_bds[ticker+\"_Logit\"][['Date','Daily_Return','proba_1']]\n",
    "    df = df.rename(columns={'Daily_Return': f'Daily_Return_{ticker}', 'proba_1': f'{ticker}_proba_1Logit'})\n",
    "    df_to_build = df_to_build.merge(df,on='Date')\n",
    "\n",
    "proba_cols = [col for col in df_to_build.columns if 'proba_1' in col]\n",
    "\n",
    "# filter to after training period (avoid all rows nan error)\n",
    "df_to_build = df_to_build[initial_train_period:]\n",
    "\n",
    "df_to_build['proba_1max'] = df_to_build[proba_cols].max(axis=1) # max value acoss all proba_1 cols\n",
    "\n",
    "df_to_build['proba_1max_col'] = df_to_build[proba_cols].idxmax(axis=1,skipna=True) # column name that proba_1max is in\n",
    "df_to_build['proba_1max_ticker'] = \"Daily_Return_\"+df_to_build['proba_1max_col'].str.split('_').str[0] # daily return column name of relevant ticker\n",
    "\n",
    "# Daily return value of ticker with highest predicted probability of increase\n",
    "df_to_build['proba_1max_ticker_Daily_return'] = df_to_build.apply(\n",
    "    lambda row: row[row['proba_1max_ticker']] if pd.notnull(row['proba_1max_col']) else row['Daily_Return_SPY'], axis=1\n",
    ")\n",
    "\n",
    "df_to_build['Strategy_Return'] = df_to_build['proba_1max_ticker_Daily_return']\n",
    "\n",
    "df_to_build.loc[df_to_build['proba_1max'] < 0.7, 'Strategy_Return'] = df_to_build['Daily_Return_SPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62efc5b-df52-40a3-9ce6-56045f2a7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_capital = 10000 # scalar\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "df = spy_data[initial_train_period:].copy()\n",
    "df.loc[initial_train_period, 'Strategy_Return'] = 0\n",
    "df['Portfolio_Value'] = (1 + df['Strategy_Return']).cumprod() * initial_capital\n",
    "fig.add_trace(go.Scatter(x=df['Date'], y=df['Portfolio_Value'], mode='lines', name='PV SPY_Hold'))\n",
    "\n",
    "df_to_build.loc[initial_train_period, 'Strategy_Return'] = 0\n",
    "df_to_build['Portfolio_Value'] = (1 + df_to_build['Strategy_Return']).cumprod() * initial_capital\n",
    "fig.add_trace(go.Scatter(x=df_to_build['Date'], y=df_to_build['Portfolio_Value'], mode='lines', name=\"PV (Logit)\"))\n",
    "\n",
    "fig.update_layout(title=\"Portfolio\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

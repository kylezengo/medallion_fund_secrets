{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a434b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import strat_defs # custom functions\n",
    "import prep_data\n",
    "\n",
    "sp_df_files = glob.glob('sp_df_*.csv')\n",
    "sp_df_latest = max(sp_df_files, key=os.path.getctime)\n",
    "sp_df_raw = pd.read_csv(sp_df_latest, parse_dates=['Date added'])\n",
    "\n",
    "stocks_df, wiki_pageviews, ffr_raw, weather, gt_adjusted = prep_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c88598b0-2602-4f9a-bec4-fd0eeecd5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_date = \"2015-07-01\"\n",
    "exclude_vars = (\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\")\n",
    "\n",
    "initial_train_period = 2140 # 2015-07-01 start predicting in 2024\n",
    "\n",
    "# Stocks to test\n",
    "these_dont_work = ['BF.B', 'BRK.B', 'GOOG', 'FOX', 'NWS']\n",
    "to_test = list(sp_df_raw.loc[sp_df_raw['Date added']<=s_date,'Symbol'])\n",
    "to_test = [x for x in to_test if x not in these_dont_work]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "176ac32a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mMMM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5308943089430894, time = 13.495912313461304\n",
      "\n",
      "\u001b[1mABT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5219512195121951, time = 7.013761043548584\n",
      "\n",
      "\u001b[1mABBV\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5430894308943089, time = 16.54254174232483\n",
      "\n",
      "\u001b[1mACN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5495934959349593, time = 12.544852018356323\n",
      "\n",
      "\u001b[1mADBE\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5369918699186992, time = 12.60840392112732\n",
      "\n",
      "\u001b[1mAES\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5272357723577236, time = 12.415857076644897\n",
      "\n",
      "\u001b[1mAFL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5617886178861788, time = 13.336281061172485\n",
      "\n",
      "\u001b[1mA\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5426829268292683, time = 7.170608043670654\n",
      "\n",
      "\u001b[1mAPD\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5337398373983739, time = 7.3037309646606445\n",
      "\n",
      "\u001b[1mAKAM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5382113821138211, time = 12.617886066436768\n",
      "\n",
      "\u001b[1mALLE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5288617886178861, time = 12.693980932235718\n",
      "\n",
      "\u001b[1mALL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5414634146341464, time = 13.694118976593018\n",
      "\n",
      "\u001b[1mGOOGL\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5373983739837398, time = 15.105011940002441\n",
      "\n",
      "\u001b[1mMO\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5491869918699187, time = 13.062176942825317\n",
      "\n",
      "\u001b[1mAMZN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5634146341463414, time = 7.48367166519165\n",
      "\n",
      "\u001b[1mAEE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5443089430894309, time = 15.185624837875366\n",
      "\n",
      "\u001b[1mAEP\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5491869918699187, time = 12.805560111999512\n",
      "\n",
      "\u001b[1mAXP\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.524390243902439, time = 12.634376049041748\n",
      "\n",
      "\u001b[1mAIG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5284552845528455, time = 12.872886180877686\n",
      "\n",
      "\u001b[1mAMT\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5304878048780488, time = 12.6268892288208\n",
      "\n",
      "\u001b[1mAMP\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5365853658536586, time = 7.6317949295043945\n",
      "\n",
      "\u001b[1mAME\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5378048780487805, time = 17.346675157546997\n",
      "\n",
      "\u001b[1mAMGN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5414634146341464, time = 12.620657920837402\n",
      "\n",
      "\u001b[1mAPH\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5455284552845528, time = 12.819791316986084\n",
      "\n",
      "\u001b[1mADI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5284552845528455, time = 12.557631015777588\n",
      "\n",
      "\u001b[1mAON\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5487804878048781, time = 13.857230186462402\n",
      "\n",
      "\u001b[1mAPA\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.516260162601626, time = 13.604924201965332\n",
      "\n",
      "\u001b[1mAAPL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5430894308943089, time = 13.679928064346313\n",
      "\n",
      "\u001b[1mAMAT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5467479674796748, time = 6.990808963775635\n",
      "\n",
      "\u001b[1mAPTV\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5337398373983739, time = 16.663373947143555\n",
      "\n",
      "\u001b[1mADM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5341463414634147, time = 12.907376766204834\n",
      "\n",
      "\u001b[1mAIZ\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5439024390243903, time = 13.770094156265259\n",
      "\n",
      "\u001b[1mT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5382113821138211, time = 12.598670959472656\n",
      "\n",
      "\u001b[1mADSK\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.53130081300813, time = 13.036580085754395\n",
      "\n",
      "\u001b[1mADP\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5552845528455285, time = 12.744955062866211\n",
      "\n",
      "\u001b[1mAZO\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.526829268292683, time = 14.363253116607666\n",
      "\n",
      "\u001b[1mAVB\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5308943089430894, time = 12.568448066711426\n",
      "\n",
      "\u001b[1mAVY\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.541869918699187, time = 7.280350923538208\n",
      "\n",
      "\u001b[1mBALL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5235772357723577, time = 13.210905075073242\n",
      "\n",
      "\u001b[1mBAC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5170731707317073, time = 12.33745789527893\n",
      "\n",
      "\u001b[1mBAX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5296747967479675, time = 12.540834665298462\n",
      "\n",
      "\u001b[1mBDX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5426829268292683, time = 12.613919019699097\n",
      "\n",
      "\u001b[1mBBY\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5434959349593496, time = 12.512475967407227\n",
      "\n",
      "\u001b[1mBIIB\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5402439024390244, time = 6.903304815292358\n",
      "\n",
      "\u001b[1mBLK\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5280487804878049, time = 7.0841710567474365\n",
      "\n",
      "\u001b[1mBK\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5353658536585366, time = 13.551162719726562\n",
      "\n",
      "\u001b[1mBA\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.541869918699187, time = 7.15623664855957\n",
      "\n",
      "\u001b[1mBKNG\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5349593495934959, time = 12.662015914916992\n",
      "\n",
      "\u001b[1mBSX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5434959349593496, time = 13.21605896949768\n",
      "\n",
      "\u001b[1mBMY\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.540650406504065, time = 13.193795919418335\n",
      "\n",
      "\u001b[1mAVGO\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5321138211382114, time = 14.145719051361084\n",
      "\n",
      "\u001b[1mBXP\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5121951219512195, time = 14.127176284790039\n",
      "\n",
      "\u001b[1mCHRW\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5483739837398374, time = 13.7946937084198\n",
      "\n",
      "\u001b[1mCPB\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5349593495934959, time = 13.858306884765625\n",
      "\n",
      "\u001b[1mCOF\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5170731707317073, time = 7.569570064544678\n",
      "\n",
      "\u001b[1mCAH\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5329268292682927, time = 14.008044004440308\n",
      "\n",
      "\u001b[1mKMX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5276422764227642, time = 7.35468316078186\n",
      "\n",
      "\u001b[1mCCL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5186991869918699, time = 9.214185953140259\n",
      "\n",
      "\u001b[1mCAT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5199186991869919, time = 7.324726104736328\n",
      "\n",
      "\u001b[1mCBRE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5317073170731708, time = 13.566421031951904\n",
      "\n",
      "\u001b[1mCOR\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5264227642276422, time = 7.318397045135498\n",
      "\n",
      "\u001b[1mCNP\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.55, time = 14.22096061706543\n",
      "\n",
      "\u001b[1mCF\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5146341463414634, time = 7.236649036407471\n",
      "\n",
      "\u001b[1mSCHW\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5170731707317073, time = 13.930963039398193\n",
      "\n",
      "\u001b[1mCVX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5402439024390244, time = 7.187397003173828\n",
      "\n",
      "\u001b[1mCMG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5455284552845528, time = 7.603543996810913\n",
      "\n",
      "\u001b[1mCB\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.532520325203252, time = 13.727102994918823\n",
      "\n",
      "\u001b[1mCI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5292682926829269, time = 14.12887191772461\n",
      "\n",
      "\u001b[1mCINF\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5349593495934959, time = 13.766529083251953\n",
      "\n",
      "\u001b[1mCTAS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5646341463414634, time = 13.97897481918335\n",
      "\n",
      "\u001b[1mCSCO\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5369918699186992, time = 13.8473961353302\n",
      "\n",
      "\u001b[1mC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5345528455284553, time = 14.224303245544434\n",
      "\n",
      "\u001b[1mCLX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5451219512195122, time = 14.256935834884644\n",
      "\n",
      "\u001b[1mCME\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5369918699186992, time = 13.957077980041504\n",
      "\n",
      "\u001b[1mCMS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5532520325203252, time = 14.10606074333191\n",
      "\n",
      "\u001b[1mKO\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.540650406504065, time = 13.792567014694214\n",
      "\n",
      "\u001b[1mCTSH\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5410569105691057, time = 7.3754119873046875\n",
      "\n",
      "\u001b[1mCL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5304878048780488, time = 13.791538000106812\n",
      "\n",
      "\u001b[1mCMCSA\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5235772357723577, time = 13.761313915252686\n",
      "\n",
      "\u001b[1mCAG\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5447154471544715, time = 7.5163209438323975\n",
      "\n",
      "\u001b[1mCOP\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5178861788617887, time = 7.290217161178589\n",
      "\n",
      "\u001b[1mED\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5459349593495935, time = 14.123862743377686\n",
      "\n",
      "\u001b[1mSTZ\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5211382113821138, time = 13.696307897567749\n",
      "\n",
      "\u001b[1mGLW\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5247967479674797, time = 13.997272968292236\n",
      "\n",
      "\u001b[1mCOST\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.551219512195122, time = 13.975352048873901\n",
      "\n",
      "\u001b[1mCTRA\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5471544715447154, time = 7.706604719161987\n",
      "\n",
      "\u001b[1mCCI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5296747967479675, time = 14.14012598991394\n",
      "\n",
      "\u001b[1mCSX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.541869918699187, time = 14.305826902389526\n",
      "\n",
      "\u001b[1mCMI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5345528455284553, time = 7.72313380241394\n",
      "\n",
      "\u001b[1mCVS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5247967479674797, time = 7.297510862350464\n",
      "\n",
      "\u001b[1mDHR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.532520325203252, time = 13.64563798904419\n",
      "\n",
      "\u001b[1mDRI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5292682926829269, time = 14.334118843078613\n",
      "\n",
      "\u001b[1mDVA\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5329268292682927, time = 13.922338008880615\n",
      "\n",
      "\u001b[1mDE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5426829268292683, time = 7.455281972885132\n",
      "\n",
      "\u001b[1mDAL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5451219512195122, time = 13.836030960083008\n",
      "\n",
      "\u001b[1mDVN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5089430894308943, time = 7.481919050216675\n",
      "\n",
      "\u001b[1mDFS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5264227642276422, time = 13.918047904968262\n",
      "\n",
      "\u001b[1mDG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.516260162601626, time = 13.884130716323853\n",
      "\n",
      "\u001b[1mDLTR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5227642276422764, time = 7.358195066452026\n",
      "\n",
      "\u001b[1mDOV\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5422764227642276, time = 13.752048254013062\n",
      "\n",
      "\u001b[1mDHI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5288617886178861, time = 14.015257835388184\n",
      "\n",
      "\u001b[1mDTE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5516260162601626, time = 17.024369955062866\n",
      "\n",
      "\u001b[1mDUK\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5422764227642276, time = 13.687320709228516\n",
      "\n",
      "\u001b[1mEMN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5186991869918699, time = 12.922199010848999\n",
      "\n",
      "\u001b[1mETN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5345528455284553, time = 13.173737049102783\n",
      "\n",
      "\u001b[1mEBAY\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5252032520325203, time = 12.775582075119019\n",
      "\n",
      "\u001b[1mECL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.532520325203252, time = 12.660806894302368\n",
      "\n",
      "\u001b[1mEIX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5288617886178861, time = 12.526042222976685\n",
      "\n",
      "\u001b[1mEW\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5223577235772358, time = 12.981272220611572\n",
      "\n",
      "\u001b[1mEA\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5231707317073171, time = 12.842327117919922\n",
      "\n",
      "\u001b[1mELV\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5219512195121951, time = 6.864239931106567\n",
      "\n",
      "\u001b[1mEMR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5235772357723577, time = 12.696892023086548\n",
      "\n",
      "\u001b[1mETR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5349593495934959, time = 12.672039985656738\n",
      "\n",
      "\u001b[1mEOG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5117886178861789, time = 12.991159915924072\n",
      "\n",
      "\u001b[1mEFX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5443089430894309, time = 12.647196054458618\n",
      "\n",
      "\u001b[1mEQIX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5369918699186992, time = 12.91013503074646\n",
      "\n",
      "\u001b[1mEQR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5463414634146342, time = 7.247750997543335\n",
      "\n",
      "\u001b[1mESS\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5386178861788617, time = 12.64523696899414\n",
      "\n",
      "\u001b[1mEL\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5231707317073171, time = 12.644821882247925\n",
      "\n",
      "\u001b[1mES\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5353658536585366, time = 12.58174991607666\n",
      "\n",
      "\u001b[1mEXC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5487804878048781, time = 12.680867195129395\n",
      "\n",
      "\u001b[1mEXPE\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5138211382113821, time = 6.820927858352661\n",
      "\n",
      "\u001b[1mEXPD\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5321138211382114, time = 13.85084080696106\n",
      "\n",
      "\u001b[1mXOM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5146341463414634, time = 13.68940281867981\n",
      "\n",
      "\u001b[1mFFIV\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5308943089430894, time = 12.619046926498413\n",
      "\n",
      "\u001b[1mFAST\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5284552845528455, time = 12.6112380027771\n",
      "\n",
      "\u001b[1mFDX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5252032520325203, time = 12.792402744293213\n",
      "\n",
      "\u001b[1mFIS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5345528455284553, time = 12.969640970230103\n",
      "\n",
      "\u001b[1mFITB\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5349593495934959, time = 7.1818528175354\n",
      "\n",
      "\u001b[1mFE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5483739837398374, time = 13.642930030822754\n",
      "\n",
      "\u001b[1mFI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5483739837398374, time = 13.8051598072052\n",
      "\n",
      "\u001b[1mF\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5300813008130081, time = 15.70060110092163\n",
      "\n",
      "\u001b[1mBEN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5223577235772358, time = 7.205008268356323\n",
      "\n",
      "\u001b[1mFCX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5333333333333333, time = 7.567936182022095\n",
      "\n",
      "\u001b[1mGRMN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5337398373983739, time = 14.044127941131592\n",
      "\n",
      "\u001b[1mGE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5341463414634147, time = 13.878517866134644\n",
      "\n",
      "\u001b[1mGEN\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5252032520325203, time = 13.941483974456787\n",
      "\n",
      "\u001b[1mGD\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5361788617886178, time = 7.22104024887085\n",
      "\n",
      "\u001b[1mGIS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5300813008130081, time = 13.557250022888184\n",
      "\n",
      "\u001b[1mGM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.525609756097561, time = 13.772301197052002\n",
      "\n",
      "\u001b[1mGPC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5337398373983739, time = 13.89613389968872\n",
      "\n",
      "\u001b[1mGILD\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5410569105691057, time = 7.4520440101623535\n",
      "\n",
      "\u001b[1mGL\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5544715447154471, time = 13.782132148742676\n",
      "\n",
      "\u001b[1mGS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5126016260162601, time = 15.339580059051514\n",
      "\n",
      "\u001b[1mHAL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5085365853658537, time = 7.162827014923096\n",
      "\n",
      "\u001b[1mHIG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5410569105691057, time = 13.792418003082275\n",
      "\n",
      "\u001b[1mHAS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5223577235772358, time = 13.453866958618164\n",
      "\n",
      "\u001b[1mHCA\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5296747967479675, time = 7.158863067626953\n",
      "\n",
      "\u001b[1mDOC\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5280487804878049, time = 14.178873062133789\n",
      "\n",
      "\u001b[1mHSIC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5455284552845528, time = 16.549453020095825\n",
      "\n",
      "\u001b[1mHSY\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5292682926829269, time = 14.446091890335083\n",
      "\n",
      "\u001b[1mHES\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5451219512195122, time = 19.149736881256104\n",
      "\n",
      "\u001b[1mHD\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5361788617886178, time = 14.07495379447937\n",
      "\n",
      "\u001b[1mHON\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5402439024390244, time = 13.52679991722107\n",
      "\n",
      "\u001b[1mHRL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5357723577235772, time = 13.60525894165039\n",
      "\n",
      "\u001b[1mHST\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5211382113821138, time = 13.510040760040283\n",
      "\n",
      "\u001b[1mHPQ\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5434959349593496, time = 13.607741832733154\n",
      "\n",
      "\u001b[1mHUM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5235772357723577, time = 14.055045127868652\n",
      "\n",
      "\u001b[1mHBAN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5264227642276422, time = 13.822302103042603\n",
      "\n",
      "\u001b[1mIBM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5341463414634147, time = 13.788118124008179\n",
      "\n",
      "\u001b[1mITW\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5434959349593496, time = 13.924368143081665\n",
      "\n",
      "\u001b[1mINTC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5288617886178861, time = 7.542855978012085\n",
      "\n",
      "\u001b[1mICE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5333333333333333, time = 13.832206726074219\n",
      "\n",
      "\u001b[1mIFF\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5138211382113821, time = 13.749396085739136\n",
      "\n",
      "\u001b[1mIP\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5089430894308943, time = 13.610493898391724\n",
      "\n",
      "\u001b[1mIPG\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5365853658536586, time = 7.5219409465789795\n",
      "\n",
      "\u001b[1mINTU\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5439024390243903, time = 13.629631996154785\n",
      "\n",
      "\u001b[1mISRG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5613821138211382, time = 7.392122030258179\n",
      "\n",
      "\u001b[1mIVZ\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5398373983739837, time = 13.668352127075195\n",
      "\n",
      "\u001b[1mIRM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5475609756097561, time = 14.15604305267334\n",
      "\n",
      "\u001b[1mJBHT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5211382113821138, time = 13.630600929260254\n",
      "\n",
      "\u001b[1mJ\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5247967479674797, time = 13.647065162658691\n",
      "\n",
      "\u001b[1mJNJ\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5215447154471544, time = 13.4720458984375\n",
      "\n",
      "\u001b[1mJCI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5333333333333333, time = 13.781799793243408\n",
      "\n",
      "\u001b[1mJPM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5264227642276422, time = 7.3681910037994385\n",
      "\n",
      "\u001b[1mJNPR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5288617886178861, time = 13.594014883041382\n",
      "\n",
      "\u001b[1mK\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.532520325203252, time = 13.962570190429688\n",
      "\n",
      "\u001b[1mKEY\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5272357723577236, time = 7.646060943603516\n",
      "\n",
      "\u001b[1mKMB\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5300813008130081, time = 13.840464115142822\n",
      "\n",
      "\u001b[1mKIM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.53130081300813, time = 7.42192006111145\n",
      "\n",
      "\u001b[1mKMI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5146341463414634, time = 14.164245843887329\n",
      "\n",
      "\u001b[1mKLAC\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5443089430894309, time = 7.148849964141846\n",
      "\n",
      "\u001b[1mKR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5231707317073171, time = 13.707311153411865\n",
      "\n",
      "\u001b[1mLHX\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5345528455284553, time = 6.8736412525177\n",
      "\n",
      "\u001b[1mLH\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5288617886178861, time = 13.469586849212646\n",
      "\n",
      "\u001b[1mLRCX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5548780487804879, time = 14.182240009307861\n",
      "\n",
      "\u001b[1mLEN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.525609756097561, time = 13.827134132385254\n",
      "\n",
      "\u001b[1mLLY\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5357723577235772, time = 14.22096300125122\n",
      "\n",
      "\u001b[1mLIN\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.525609756097561, time = 14.003785848617554\n",
      "\n",
      "\u001b[1mLMT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.540650406504065, time = 13.71232295036316\n",
      "\n",
      "\u001b[1mL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5682926829268292, time = 13.599222183227539\n",
      "\n",
      "\u001b[1mLOW\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.541869918699187, time = 13.377939224243164\n",
      "\n",
      "\u001b[1mLYB\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5146341463414634, time = 7.225647926330566\n",
      "\n",
      "\u001b[1mMTB\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5483739837398374, time = 7.380479097366333\n",
      "\n",
      "\u001b[1mMPC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5341463414634147, time = 13.771278858184814\n",
      "\n",
      "\u001b[1mMAR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5321138211382114, time = 14.421396970748901\n",
      "\n",
      "\u001b[1mMMC\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5532520325203252, time = 6.992483854293823\n",
      "\n",
      "\u001b[1mMLM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.517479674796748, time = 13.5594801902771\n",
      "\n",
      "\u001b[1mMAS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.532520325203252, time = 14.064713954925537\n",
      "\n",
      "\u001b[1mMA\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5495934959349593, time = 14.10061001777649\n",
      "\n",
      "\u001b[1mMKC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5398373983739837, time = 13.774349212646484\n",
      "\n",
      "\u001b[1mMCD\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5398373983739837, time = 14.10481882095337\n",
      "\n",
      "\u001b[1mMCK\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5386178861788617, time = 13.585093975067139\n",
      "\n",
      "\u001b[1mMDT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5317073170731708, time = 16.011157989501953\n",
      "\n",
      "\u001b[1mMRK\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5207317073170732, time = 14.477052927017212\n",
      "\n",
      "\u001b[1mMETA\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5296747967479675, time = 13.745176076889038\n",
      "\n",
      "\u001b[1mMET\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5369918699186992, time = 13.845974922180176\n",
      "\n",
      "\u001b[1mMCHP\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.541869918699187, time = 13.831722974777222\n",
      "\n",
      "\u001b[1mMU\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5357723577235772, time = 7.27031397819519\n",
      "\n",
      "\u001b[1mMSFT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5451219512195122, time = 13.68316125869751\n",
      "\n",
      "\u001b[1mMHK\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5077235772357723, time = 13.591542959213257\n",
      "\n",
      "\u001b[1mTAP\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.526829268292683, time = 7.275220155715942\n",
      "\n",
      "\u001b[1mMDLZ\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5333333333333333, time = 13.67731785774231\n",
      "\n",
      "\u001b[1mMNST\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5341463414634147, time = 7.167882919311523\n",
      "\n",
      "\u001b[1mMCO\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5532520325203252, time = 13.726104736328125\n",
      "\n",
      "\u001b[1mMS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5195121951219512, time = 13.974435806274414\n",
      "\n",
      "\u001b[1mMOS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5516260162601626, time = 7.830381155014038\n",
      "\n",
      "\u001b[1mMSI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5491869918699187, time = 13.719035863876343\n",
      "\n",
      "\u001b[1mNDAQ\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5378048780487805, time = 13.826117038726807\n",
      "\n",
      "\u001b[1mNTAP\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5329268292682927, time = 13.559043884277344\n",
      "\n",
      "\u001b[1mNFLX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5296747967479675, time = 7.325244903564453\n",
      "\n",
      "\u001b[1mNEM\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5321138211382114, time = 16.031836986541748\n",
      "\n",
      "\u001b[1mNWSA\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5292682926829269, time = 13.650285959243774\n",
      "\n",
      "\u001b[1mNEE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5463414634146342, time = 13.817286014556885\n",
      "\n",
      "\u001b[1mNKE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5186991869918699, time = 13.764979839324951\n",
      "\n",
      "\u001b[1mNI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5487804878048781, time = 14.985388994216919\n",
      "\n",
      "\u001b[1mNSC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5280487804878049, time = 13.775930881500244\n",
      "\n",
      "\u001b[1mNTRS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5353658536585366, time = 13.871454954147339\n",
      "\n",
      "\u001b[1mNOC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5378048780487805, time = 13.501914024353027\n",
      "\n",
      "\u001b[1mNRG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5451219512195122, time = 15.720673084259033\n",
      "\n",
      "\u001b[1mNUE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5109756097560976, time = 13.677395343780518\n",
      "\n",
      "\u001b[1mNVDA\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5479674796747968, time = 13.869159936904907\n",
      "\n",
      "\u001b[1mORLY\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5434959349593496, time = 13.809728145599365\n",
      "\n",
      "\u001b[1mOXY\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5113821138211382, time = 14.10811996459961\n",
      "\n",
      "\u001b[1mOMC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.53130081300813, time = 7.358015060424805\n",
      "\n",
      "\u001b[1mOKE\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5430894308943089, time = 13.587121963500977\n",
      "\n",
      "\u001b[1mORCL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5414634146341464, time = 13.671592950820923\n",
      "\n",
      "\u001b[1mPCAR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5321138211382114, time = 14.559497833251953\n",
      "\n",
      "\u001b[1mPARA\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5138211382113821, time = 13.908135890960693\n",
      "\n",
      "\u001b[1mPH\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5239837398373983, time = 14.605731725692749\n",
      "\n",
      "\u001b[1mPAYX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5467479674796748, time = 7.156254768371582\n",
      "\n",
      "\u001b[1mPNR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5300813008130081, time = 13.829896926879883\n",
      "\n",
      "\u001b[1mPEP\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5357723577235772, time = 14.068718194961548\n",
      "\n",
      "\u001b[1mPFE\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5296747967479675, time = 7.202448129653931\n",
      "\n",
      "\u001b[1mPM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5369918699186992, time = 13.686215877532959\n",
      "\n",
      "\u001b[1mPSX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5292682926829269, time = 13.394442081451416\n",
      "\n",
      "\u001b[1mPNW\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5402439024390244, time = 14.321126699447632\n",
      "\n",
      "\u001b[1mPNC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5203252032520326, time = 15.085968971252441\n",
      "\n",
      "\u001b[1mPPG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.526829268292683, time = 14.255640745162964\n",
      "\n",
      "\u001b[1mPPL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5443089430894309, time = 13.778391122817993\n",
      "\n",
      "\u001b[1mPFG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.524390243902439, time = 14.077808141708374\n",
      "\n",
      "\u001b[1mPG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5382113821138211, time = 13.723541975021362\n",
      "\n",
      "\u001b[1mPGR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5439024390243903, time = 13.899470806121826\n",
      "\n",
      "\u001b[1mPLD\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.541869918699187, time = 13.556714057922363\n",
      "\n",
      "\u001b[1mPRU\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5260162601626016, time = 13.72821307182312\n",
      "\n",
      "\u001b[1mPEG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5463414634146342, time = 13.792908906936646\n",
      "\n",
      "\u001b[1mPSA\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5365853658536586, time = 13.53374195098877\n",
      "\n",
      "\u001b[1mPHM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5365853658536586, time = 14.02129316329956\n",
      "\n",
      "\u001b[1mPWR\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5365853658536586, time = 13.779027938842773\n",
      "\n",
      "\u001b[1mQCOM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5215447154471544, time = 13.908407926559448\n",
      "\n",
      "\u001b[1mDGX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5308943089430894, time = 13.75094223022461\n",
      "\n",
      "\u001b[1mRL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.516260162601626, time = 13.783217906951904\n",
      "\n",
      "\u001b[1mRTX\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5239837398373983, time = 13.535104036331177\n",
      "\n",
      "\u001b[1mO\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5422764227642276, time = 14.320035934448242\n",
      "\n",
      "\u001b[1mREGN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5182926829268293, time = 13.700690269470215\n",
      "\n",
      "\u001b[1mRF\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5284552845528455, time = 7.283046245574951\n",
      "\n",
      "\u001b[1mRSG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5577235772357724, time = 14.005345106124878\n",
      "\n",
      "\u001b[1mRVTY\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5272357723577236, time = 13.623778104782104\n",
      "\n",
      "\u001b[1mROK\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.525609756097561, time = 13.678499698638916\n",
      "\n",
      "\u001b[1mROP\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5463414634146342, time = 13.486940145492554\n",
      "\n",
      "\u001b[1mROST\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5264227642276422, time = 14.057519912719727\n",
      "\n",
      "\u001b[1mRCL\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5292682926829269, time = 7.526936054229736\n",
      "\n",
      "\u001b[1mSPGI\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5479674796747968, time = 15.55828595161438\n",
      "\n",
      "\u001b[1mCRM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5353658536585366, time = 7.178723096847534\n",
      "\n",
      "\u001b[1mSLB\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5276422764227642, time = 7.216896057128906\n",
      "\n",
      "\u001b[1mSTX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5357723577235772, time = 13.806595802307129\n",
      "\n",
      "\u001b[1mSHW\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5260162601626016, time = 13.631600856781006\n",
      "\n",
      "\u001b[1mSPG\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5369918699186992, time = 13.593390703201294\n",
      "\n",
      "\u001b[1mSWKS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.525609756097561, time = 13.769469261169434\n",
      "\n",
      "\u001b[1mSJM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5345528455284553, time = 7.529496192932129\n",
      "\n",
      "\u001b[1mSNA\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.541869918699187, time = 13.860573053359985\n",
      "\n",
      "\u001b[1mSO\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5451219512195122, time = 15.575065851211548\n",
      "\n",
      "\u001b[1mLUV\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5337398373983739, time = 13.849169731140137\n",
      "\n",
      "\u001b[1mSWK\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5146341463414634, time = 14.434340000152588\n",
      "\n",
      "\u001b[1mSBUX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5211382113821138, time = 7.388948917388916\n",
      "\n",
      "\u001b[1mSTT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5231707317073171, time = 13.597986698150635\n",
      "\n",
      "\u001b[1mSYK\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5341463414634147, time = 13.914441108703613\n",
      "\n",
      "\u001b[1mSYY\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5475609756097561, time = 13.5485360622406\n",
      "\n",
      "\u001b[1mTPR\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5215447154471544, time = 13.658679962158203\n",
      "\n",
      "\u001b[1mTGT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5321138211382114, time = 13.66061282157898\n",
      "\n",
      "\u001b[1mTEL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5272357723577236, time = 15.001754999160767\n",
      "\n",
      "\u001b[1mTXN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5646341463414634, time = 7.193037986755371\n",
      "\n",
      "\u001b[1mTXT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5345528455284553, time = 7.356920003890991\n",
      "\n",
      "\u001b[1mTMO\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5475609756097561, time = 14.009907960891724\n",
      "\n",
      "\u001b[1mTJX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.524390243902439, time = 7.35724401473999\n",
      "\n",
      "\u001b[1mTSCO\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5288617886178861, time = 14.440659284591675\n",
      "\n",
      "\u001b[1mTT\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.540650406504065, time = 14.100303173065186\n",
      "\n",
      "\u001b[1mTRV\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5479674796747968, time = 13.626897096633911\n",
      "\n",
      "\u001b[1mTFC\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5304878048780488, time = 13.519500970840454\n",
      "\n",
      "\u001b[1mTSN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5386178861788617, time = 16.20073390007019\n",
      "\n",
      "\u001b[1mUSB\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5321138211382114, time = 13.725707054138184\n",
      "\n",
      "\u001b[1mUNP\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.53130081300813, time = 7.272327899932861\n",
      "\n",
      "\u001b[1mUPS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5191056910569106, time = 14.098778247833252\n",
      "\n",
      "\u001b[1mURI\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.525609756097561, time = 13.57527232170105\n",
      "\n",
      "\u001b[1mUNH\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5398373983739837, time = 7.34602689743042\n",
      "\n",
      "\u001b[1mUHS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5227642276422764, time = 13.631919145584106\n",
      "\n",
      "\u001b[1mVLO\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5239837398373983, time = 14.039424180984497\n",
      "\n",
      "\u001b[1mVTR\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5422764227642276, time = 13.615936994552612\n",
      "\n",
      "\u001b[1mVRSN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5426829268292683, time = 16.187235116958618\n",
      "\n",
      "\u001b[1mVZ\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5207317073170732, time = 13.539626836776733\n",
      "\n",
      "\u001b[1mVRTX\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5308943089430894, time = 7.492475986480713\n",
      "\n",
      "\u001b[1mVTRS\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5073170731707317, time = 14.74190068244934\n",
      "\n",
      "\u001b[1mV\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5552845528455285, time = 13.999470949172974\n",
      "\n",
      "\u001b[1mVMC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5272357723577236, time = 7.425717115402222\n",
      "\n",
      "\u001b[1mGWW\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5296747967479675, time = 13.614509105682373\n",
      "\n",
      "\u001b[1mWBA\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.517479674796748, time = 13.763438940048218\n",
      "\n",
      "\u001b[1mWMT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5378048780487805, time = 13.64814305305481\n",
      "\n",
      "\u001b[1mDIS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5154471544715448, time = 7.655847072601318\n",
      "\n",
      "\u001b[1mWM\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5642276422764227, time = 14.16158413887024\n",
      "\n",
      "\u001b[1mWAT\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.5390243902439025, time = 7.282435178756714\n",
      "\n",
      "\u001b[1mWEC\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5426829268292683, time = 13.74976110458374\n",
      "\n",
      "\u001b[1mWFC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.525609756097561, time = 14.265905141830444\n",
      "\n",
      "\u001b[1mWELL\u001b[0m\n",
      "Training on data set with 2461 rows and 29 features\n",
      "Logit score = 0.5459349593495935, time = 13.5156090259552\n",
      "\n",
      "\u001b[1mWDC\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5142276422764228, time = 13.989117860794067\n",
      "\n",
      "\u001b[1mWY\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5252032520325203, time = 13.76149582862854\n",
      "\n",
      "\u001b[1mWMB\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5402439024390244, time = 7.443006992340088\n",
      "\n",
      "\u001b[1mWYNN\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5373983739837398, time = 7.586994886398315\n",
      "\n",
      "\u001b[1mXEL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5479674796747968, time = 15.653669118881226\n",
      "\n",
      "\u001b[1mXYL\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5317073170731708, time = 7.393893241882324\n",
      "\n",
      "\u001b[1mYUM\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5341463414634147, time = 13.643774032592773\n",
      "\n",
      "\u001b[1mZBH\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.5373983739837398, time = 13.671546697616577\n",
      "\n",
      "\u001b[1mZTS\u001b[0m\n",
      "Training on data set with 2461 rows and 30 features\n",
      "Logit score = 0.541869918699187, time = 13.794579029083252\n",
      "\n",
      "\u001b[1mSPY\u001b[0m\n",
      "Training on data set with 2461 rows and 27 features\n",
      "Logit score = 0.5504065040650407, time = 13.68081283569336\n",
      "CPU times: user 4h 48min 27s, sys: 1h 58min 6s, total: 6h 46min 34s\n",
      "Wall time: 1h 13min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "strat_bds, strat_mods = {}, {}\n",
    "for ticker in to_test:\n",
    "    print(f'\\n\\033[1m{ticker}\\033[0m')\n",
    "    prepd_data = prep_data.prep_data(\n",
    "        stocks_df,\n",
    "        wiki_pageviews,\n",
    "        ffr_raw,\n",
    "        weather,\n",
    "        gt_adjusted,\n",
    "        config=prep_data.IndicatorConfig(ticker=ticker),\n",
    "        drop_tickers=True\n",
    "    )\n",
    "\n",
    "    df_for_chart = prepd_data.loc[prepd_data['Date']>=s_date].reset_index(drop=True)\n",
    "    df_for_chart = df_for_chart.drop(columns=[\n",
    "        col for col in df_for_chart.columns \n",
    "        if any(col.startswith(prefix) for prefix in exclude_vars) and col != \"Adj Close_\"+ticker\n",
    "    ])\n",
    "    df_for_chart = df_for_chart.dropna(axis='columns') # drop columns with an na\n",
    "\n",
    "    print(f'Training on data set with {len(df_for_chart)} rows and {df_for_chart.shape[1]-1} features')\n",
    "    print(\"Logit\", end=\" \")\n",
    "    start_time = time.time()\n",
    "    backtested_data,model,score = strat_defs.backtest_strategy(\n",
    "        data=df_for_chart,\n",
    "        strategy=\"Logit\",\n",
    "        target='Adj Close',\n",
    "        ticker=ticker,\n",
    "        config=strat_defs.BacktestConfig(),\n",
    "        initial_train_period=initial_train_period,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    end_time = time.time()    \n",
    "    print(f'score = {score}, time = {end_time-start_time}')\n",
    "\n",
    "    strat_bds[f'{ticker}_Logit'] = backtested_data\n",
    "    strat_mods[f'{ticker}_Logit'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6204d65-c382-46f2-a58f-732657756631",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepd_data = prep_data.prep_data(\n",
    "    stocks_df,\n",
    "    wiki_pageviews,\n",
    "    ffr_raw,\n",
    "    weather,\n",
    "    gt_adjusted,\n",
    "    config=prep_data.IndicatorConfig(ticker=\"SPY\"),\n",
    "    drop_tickers=True\n",
    ")\n",
    "\n",
    "df_for_chart = prepd_data.loc[prepd_data['Date']>=s_date].reset_index(drop=True)\n",
    "\n",
    "spy_data,spy_model,spy_score = strat_defs.backtest_strategy(\n",
    "    data=df_for_chart.dropna(axis='columns'),\n",
    "    strategy=\"Hold\",\n",
    "    target='Adj Close',\n",
    "    ticker=\"SPY\",\n",
    "    config=strat_defs.BacktestConfig(),\n",
    "    initial_train_period=initial_train_period,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57f75ec0-98a0-485d-9be3-be2fcb22f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_build = strat_bds[to_test[0]+\"_Logit\"][['Date']] # start with just date column\n",
    "\n",
    "# Get results for all tickers in to_test\n",
    "for ticker in to_test:\n",
    "    df = strat_bds[ticker+\"_Logit\"][['Date','Daily_Return','proba_1']]\n",
    "    df = df.rename(columns={'Daily_Return': f'Daily_Return_{ticker}', 'proba_1': f'{ticker}_proba_1Logit'})\n",
    "    df_to_build = df_to_build.merge(df,on='Date')\n",
    "\n",
    "proba_cols = [col for col in df_to_build.columns if 'proba_1' in col]\n",
    "\n",
    "# filter to after training period (avoid all rows nan error)\n",
    "df_to_build = df_to_build[initial_train_period:]\n",
    "\n",
    "df_to_build['proba_1max'] = df_to_build[proba_cols].max(axis=1) # max value acoss all proba_1 cols\n",
    "\n",
    "df_to_build['proba_1max_col'] = df_to_build[proba_cols].idxmax(axis=1,skipna=True) # column name that proba_1max is in\n",
    "df_to_build['proba_1max_ticker'] = \"Daily_Return_\"+df_to_build['proba_1max_col'].str.split('_').str[0] # daily return column name of relevant ticker\n",
    "\n",
    "# Daily return value of ticker with highest predicted probability of increase\n",
    "df_to_build['proba_1max_ticker_Daily_return'] = df_to_build.apply(\n",
    "    lambda row: row[row['proba_1max_ticker']] if pd.notnull(row['proba_1max_col']) else row['Daily_Return_SPY'], axis=1\n",
    ")\n",
    "\n",
    "df_to_build['Strategy_Return'] = df_to_build['proba_1max_ticker_Daily_return']\n",
    "\n",
    "df_to_build.loc[df_to_build['proba_1max'] < 0.7, 'Strategy_Return'] = df_to_build['Daily_Return_SPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c62efc5b-df52-40a3-9ce6-56045f2a7628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "PV SPY_Hold",
         "type": "scatter",
         "x": [
          "2024-01-02T00:00:00",
          "2024-01-03T00:00:00",
          "2024-01-04T00:00:00",
          "2024-01-05T00:00:00",
          "2024-01-08T00:00:00",
          "2024-01-09T00:00:00",
          "2024-01-10T00:00:00",
          "2024-01-11T00:00:00",
          "2024-01-12T00:00:00",
          "2024-01-16T00:00:00",
          "2024-01-17T00:00:00",
          "2024-01-18T00:00:00",
          "2024-01-19T00:00:00",
          "2024-01-22T00:00:00",
          "2024-01-23T00:00:00",
          "2024-01-24T00:00:00",
          "2024-01-25T00:00:00",
          "2024-01-26T00:00:00",
          "2024-01-29T00:00:00",
          "2024-01-30T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-01T00:00:00",
          "2024-02-02T00:00:00",
          "2024-02-05T00:00:00",
          "2024-02-06T00:00:00",
          "2024-02-07T00:00:00",
          "2024-02-08T00:00:00",
          "2024-02-09T00:00:00",
          "2024-02-12T00:00:00",
          "2024-02-13T00:00:00",
          "2024-02-14T00:00:00",
          "2024-02-15T00:00:00",
          "2024-02-16T00:00:00",
          "2024-02-20T00:00:00",
          "2024-02-21T00:00:00",
          "2024-02-22T00:00:00",
          "2024-02-23T00:00:00",
          "2024-02-26T00:00:00",
          "2024-02-27T00:00:00",
          "2024-02-28T00:00:00",
          "2024-02-29T00:00:00",
          "2024-03-01T00:00:00",
          "2024-03-04T00:00:00",
          "2024-03-05T00:00:00",
          "2024-03-06T00:00:00",
          "2024-03-07T00:00:00",
          "2024-03-08T00:00:00",
          "2024-03-11T00:00:00",
          "2024-03-12T00:00:00",
          "2024-03-13T00:00:00",
          "2024-03-14T00:00:00",
          "2024-03-15T00:00:00",
          "2024-03-18T00:00:00",
          "2024-03-19T00:00:00",
          "2024-03-20T00:00:00",
          "2024-03-21T00:00:00",
          "2024-03-22T00:00:00",
          "2024-03-25T00:00:00",
          "2024-03-26T00:00:00",
          "2024-03-27T00:00:00",
          "2024-03-28T00:00:00",
          "2024-04-01T00:00:00",
          "2024-04-02T00:00:00",
          "2024-04-03T00:00:00",
          "2024-04-04T00:00:00",
          "2024-04-05T00:00:00",
          "2024-04-08T00:00:00",
          "2024-04-09T00:00:00",
          "2024-04-10T00:00:00",
          "2024-04-11T00:00:00",
          "2024-04-12T00:00:00",
          "2024-04-15T00:00:00",
          "2024-04-16T00:00:00",
          "2024-04-17T00:00:00",
          "2024-04-18T00:00:00",
          "2024-04-19T00:00:00",
          "2024-04-22T00:00:00",
          "2024-04-23T00:00:00",
          "2024-04-24T00:00:00",
          "2024-04-25T00:00:00",
          "2024-04-26T00:00:00",
          "2024-04-29T00:00:00",
          "2024-04-30T00:00:00",
          "2024-05-01T00:00:00",
          "2024-05-02T00:00:00",
          "2024-05-03T00:00:00",
          "2024-05-06T00:00:00",
          "2024-05-07T00:00:00",
          "2024-05-08T00:00:00",
          "2024-05-09T00:00:00",
          "2024-05-10T00:00:00",
          "2024-05-13T00:00:00",
          "2024-05-14T00:00:00",
          "2024-05-15T00:00:00",
          "2024-05-16T00:00:00",
          "2024-05-17T00:00:00",
          "2024-05-20T00:00:00",
          "2024-05-21T00:00:00",
          "2024-05-22T00:00:00",
          "2024-05-23T00:00:00",
          "2024-05-24T00:00:00",
          "2024-05-28T00:00:00",
          "2024-05-29T00:00:00",
          "2024-05-30T00:00:00",
          "2024-05-31T00:00:00",
          "2024-06-03T00:00:00",
          "2024-06-04T00:00:00",
          "2024-06-05T00:00:00",
          "2024-06-06T00:00:00",
          "2024-06-07T00:00:00",
          "2024-06-10T00:00:00",
          "2024-06-11T00:00:00",
          "2024-06-12T00:00:00",
          "2024-06-13T00:00:00",
          "2024-06-14T00:00:00",
          "2024-06-17T00:00:00",
          "2024-06-18T00:00:00",
          "2024-06-20T00:00:00",
          "2024-06-21T00:00:00",
          "2024-06-24T00:00:00",
          "2024-06-25T00:00:00",
          "2024-06-26T00:00:00",
          "2024-06-27T00:00:00",
          "2024-06-28T00:00:00",
          "2024-07-01T00:00:00",
          "2024-07-02T00:00:00",
          "2024-07-03T00:00:00",
          "2024-07-05T00:00:00",
          "2024-07-08T00:00:00",
          "2024-07-09T00:00:00",
          "2024-07-10T00:00:00",
          "2024-07-11T00:00:00",
          "2024-07-12T00:00:00",
          "2024-07-15T00:00:00",
          "2024-07-16T00:00:00",
          "2024-07-17T00:00:00",
          "2024-07-18T00:00:00",
          "2024-07-19T00:00:00",
          "2024-07-22T00:00:00",
          "2024-07-23T00:00:00",
          "2024-07-24T00:00:00",
          "2024-07-25T00:00:00",
          "2024-07-26T00:00:00",
          "2024-07-29T00:00:00",
          "2024-07-30T00:00:00",
          "2024-07-31T00:00:00",
          "2024-08-01T00:00:00",
          "2024-08-02T00:00:00",
          "2024-08-05T00:00:00",
          "2024-08-06T00:00:00",
          "2024-08-07T00:00:00",
          "2024-08-08T00:00:00",
          "2024-08-09T00:00:00",
          "2024-08-12T00:00:00",
          "2024-08-13T00:00:00",
          "2024-08-14T00:00:00",
          "2024-08-15T00:00:00",
          "2024-08-16T00:00:00",
          "2024-08-19T00:00:00",
          "2024-08-20T00:00:00",
          "2024-08-21T00:00:00",
          "2024-08-22T00:00:00",
          "2024-08-23T00:00:00",
          "2024-08-26T00:00:00",
          "2024-08-27T00:00:00",
          "2024-08-28T00:00:00",
          "2024-08-29T00:00:00",
          "2024-08-30T00:00:00",
          "2024-09-03T00:00:00",
          "2024-09-04T00:00:00",
          "2024-09-05T00:00:00",
          "2024-09-06T00:00:00",
          "2024-09-09T00:00:00",
          "2024-09-10T00:00:00",
          "2024-09-11T00:00:00",
          "2024-09-12T00:00:00",
          "2024-09-13T00:00:00",
          "2024-09-16T00:00:00",
          "2024-09-17T00:00:00",
          "2024-09-18T00:00:00",
          "2024-09-19T00:00:00",
          "2024-09-20T00:00:00",
          "2024-09-23T00:00:00",
          "2024-09-24T00:00:00",
          "2024-09-25T00:00:00",
          "2024-09-26T00:00:00",
          "2024-09-27T00:00:00",
          "2024-09-30T00:00:00",
          "2024-10-01T00:00:00",
          "2024-10-02T00:00:00",
          "2024-10-03T00:00:00",
          "2024-10-04T00:00:00",
          "2024-10-07T00:00:00",
          "2024-10-08T00:00:00",
          "2024-10-09T00:00:00",
          "2024-10-10T00:00:00",
          "2024-10-11T00:00:00",
          "2024-10-14T00:00:00",
          "2024-10-15T00:00:00",
          "2024-10-16T00:00:00",
          "2024-10-17T00:00:00",
          "2024-10-18T00:00:00",
          "2024-10-21T00:00:00",
          "2024-10-22T00:00:00",
          "2024-10-23T00:00:00",
          "2024-10-24T00:00:00",
          "2024-10-25T00:00:00",
          "2024-10-28T00:00:00",
          "2024-10-29T00:00:00",
          "2024-10-30T00:00:00",
          "2024-10-31T00:00:00",
          "2024-11-01T00:00:00",
          "2024-11-04T00:00:00",
          "2024-11-05T00:00:00",
          "2024-11-06T00:00:00",
          "2024-11-07T00:00:00",
          "2024-11-08T00:00:00",
          "2024-11-11T00:00:00",
          "2024-11-12T00:00:00",
          "2024-11-13T00:00:00",
          "2024-11-14T00:00:00",
          "2024-11-15T00:00:00",
          "2024-11-18T00:00:00",
          "2024-11-19T00:00:00",
          "2024-11-20T00:00:00",
          "2024-11-21T00:00:00",
          "2024-11-22T00:00:00",
          "2024-11-25T00:00:00",
          "2024-11-26T00:00:00",
          "2024-11-27T00:00:00",
          "2024-11-29T00:00:00",
          "2024-12-02T00:00:00",
          "2024-12-03T00:00:00",
          "2024-12-04T00:00:00",
          "2024-12-05T00:00:00",
          "2024-12-06T00:00:00",
          "2024-12-09T00:00:00",
          "2024-12-10T00:00:00",
          "2024-12-11T00:00:00",
          "2024-12-12T00:00:00",
          "2024-12-13T00:00:00",
          "2024-12-16T00:00:00",
          "2024-12-17T00:00:00",
          "2024-12-18T00:00:00",
          "2024-12-19T00:00:00",
          "2024-12-20T00:00:00",
          "2024-12-23T00:00:00",
          "2024-12-24T00:00:00",
          "2024-12-26T00:00:00",
          "2024-12-27T00:00:00",
          "2024-12-30T00:00:00",
          "2024-12-31T00:00:00",
          "2025-01-02T00:00:00",
          "2025-01-03T00:00:00",
          "2025-01-06T00:00:00",
          "2025-01-07T00:00:00",
          "2025-01-08T00:00:00",
          "2025-01-10T00:00:00",
          "2025-01-13T00:00:00",
          "2025-01-14T00:00:00",
          "2025-01-15T00:00:00",
          "2025-01-16T00:00:00",
          "2025-01-17T00:00:00",
          "2025-01-21T00:00:00",
          "2025-01-22T00:00:00",
          "2025-01-23T00:00:00",
          "2025-01-24T00:00:00",
          "2025-01-27T00:00:00",
          "2025-01-28T00:00:00",
          "2025-01-29T00:00:00",
          "2025-01-30T00:00:00",
          "2025-01-31T00:00:00",
          "2025-02-03T00:00:00",
          "2025-02-04T00:00:00",
          "2025-02-05T00:00:00",
          "2025-02-06T00:00:00",
          "2025-02-07T00:00:00",
          "2025-02-10T00:00:00",
          "2025-02-11T00:00:00",
          "2025-02-12T00:00:00",
          "2025-02-13T00:00:00",
          "2025-02-14T00:00:00",
          "2025-02-18T00:00:00",
          "2025-02-19T00:00:00",
          "2025-02-20T00:00:00",
          "2025-02-21T00:00:00",
          "2025-02-24T00:00:00",
          "2025-02-25T00:00:00",
          "2025-02-26T00:00:00",
          "2025-02-27T00:00:00",
          "2025-02-28T00:00:00",
          "2025-03-03T00:00:00",
          "2025-03-04T00:00:00",
          "2025-03-05T00:00:00",
          "2025-03-06T00:00:00",
          "2025-03-07T00:00:00",
          "2025-03-10T00:00:00",
          "2025-03-11T00:00:00",
          "2025-03-12T00:00:00",
          "2025-03-13T00:00:00",
          "2025-03-14T00:00:00",
          "2025-03-17T00:00:00",
          "2025-03-18T00:00:00",
          "2025-03-19T00:00:00",
          "2025-03-20T00:00:00",
          "2025-03-21T00:00:00",
          "2025-03-24T00:00:00",
          "2025-03-25T00:00:00",
          "2025-03-26T00:00:00",
          "2025-03-27T00:00:00",
          "2025-03-28T00:00:00",
          "2025-03-31T00:00:00",
          "2025-04-01T00:00:00",
          "2025-04-02T00:00:00",
          "2025-04-03T00:00:00",
          "2025-04-04T00:00:00",
          "2025-04-07T00:00:00",
          "2025-04-08T00:00:00",
          "2025-04-09T00:00:00",
          "2025-04-10T00:00:00",
          "2025-04-11T00:00:00"
         ],
         "y": [
          10000,
          9918.333477416903,
          9886.384968642476,
          9899.927074911608,
          10041.25665708719,
          10026.02424723114,
          10082.72517605198,
          10078.282635813637,
          10085.264238987551,
          10048.238260261107,
          9992.383467112419,
          10081.24345474703,
          10206.917559230485,
          10228.499266223278,
          10258.331123979084,
          10269.544061432865,
          10325.39951050068,
          10312.282439825,
          10393.949618327226,
          10385.909361684435,
          10216.439537178221,
          10350.153898304467,
          10459.113215707797,
          10421.029239431607,
          10451.286132780862,
          10538.453849071177,
          10543.107595267993,
          10604.041826126077,
          10599.386768091008,
          10453.401471961231,
          10548.397583016738,
          10621.17902512315,
          10568.286362746108,
          10510.103712620325,
          10519.62306689156,
          10737.332463497125,
          10744.736478587985,
          10705.384610641822,
          10725.272734452064,
          10711.098322145763,
          10749.603398500654,
          10850.523771099448,
          10838.887109890466,
          10730.561410362556,
          10784.935138125422,
          10891.991634145108,
          10826.615518967808,
          10817.306714735923,
          10933.672670906622,
          10916.534160071296,
          10894.953764916754,
          10820.142909035438,
          10884.447908280472,
          10944.936114133081,
          11046.167392397458,
          11082.673227257223,
          11061.66151398466,
          11031.100930080207,
          11010.72545835957,
          11103.258593098084,
          11101.136038807332,
          11081.823156070323,
          11011.364323587999,
          11023.458160427594,
          10888.905534658708,
          11002.66158862826,
          11008.815421865545,
          11021.549435771818,
          10911.190386954251,
          10993.534473994194,
          10841.791519779053,
          10705.963787229815,
          10686.437730776954,
          10623.19335275817,
          10601.33353605608,
          10508.801713155817,
          10605.578644637588,
          10731.431159123234,
          10726.337291193075,
          10685.588971428304,
          10786.824185207433,
          10825.024915087999,
          10653.542730704148,
          10618.949556014913,
          10718.272765542639,
          10851.129184452473,
          10963.185751967343,
          10975.282212483437,
          10976.345457386193,
          11039.589835404977,
          11053.810162050077,
          11055.29253927415,
          11106.017388940767,
          11243.542640187306,
          11220.410996300494,
          11236.540047601371,
          11249.486579304368,
          11277.074537731165,
          11244.603917332683,
          11162.471036251214,
          11236.327529804645,
          11244.17888173923,
          11165.442349890618,
          11091.374650378713,
          11192.395378603738,
          11201.520525480428,
          11214.043333428226,
          11347.32347609326,
          11347.110958296533,
          11333.315667244884,
          11368.33387752757,
          11395.711941834143,
          11489.305041879783,
          11512.439309443098,
          11519.444525705538,
          11611.124965580646,
          11640.625584177973,
          11609.003723128142,
          11593.441385951866,
          11555.753584827593,
          11600.253761991347,
          11614.731208933721,
          11633.041847246666,
          11587.263939626053,
          11611.111847198128,
          11689.251492642356,
          11741.416740709,
          11809.1233365399,
          11822.749400457118,
          11834.247662730577,
          11951.348904241178,
          11848.298762241247,
          11923.031563746606,
          11955.820960840176,
          12026.72319465147,
          11858.092946626146,
          11766.964790654874,
          11688.825145210647,
          11809.335854336618,
          11790.812698226946,
          11523.60305296244,
          11463.56021619618,
          11591.948514021771,
          11598.762201899504,
          11539.998407428351,
          11727.575535318543,
          11561.502060045188,
          11346.246456888854,
          11015.800960554194,
          11117.362166138793,
          11043.054400226883,
          11298.340747624477,
          11348.161740735884,
          11354.122733750213,
          11540.849790453502,
          11577.258549282667,
          11775.696386056145,
          11802.097130865432,
          11914.941457250263,
          11895.565606277187,
          11936.446421705352,
          11842.762804820366,
          11968.596953570492,
          11940.065783440943,
          11956.459826068603,
          11887.049152349146,
          11888.113053171026,
          12001.597556622537,
          11754.617769032762,
          11730.557343663962,
          11702.026173534417,
          11505.078585014524,
          11633.891918433563,
          11684.566918246626,
          11804.438762144171,
          11903.870854246761,
          11966.042804495031,
          11983.713265741297,
          11988.610357933747,
          11953.054293967989,
          12157.02546448584,
          12136.011127536774,
          12166.336892394227,
          12201.149144071444,
          12174.239406020617,
          12222.505870804122,
          12204.779000513046,
          12253.686954201483,
          12143.913641163163,
          12149.037681373102,
          12126.826947938767,
          12237.029232085295,
          12126.399288668814,
          12241.085435958601,
          12325.873477660889,
          12304.302921293232,
          12377.983628520977,
          12479.214250866224,
          12382.25497386751,
          12436.074449969163,
          12437.140974467546,
          12484.981091819349,
          12464.478371788327,
          12457.857524133546,
          12344.025383545417,
          12370.722603799517,
          12366.451258452982,
          12404.679536936828,
          12424.755909536148,
          12387.166496280732,
          12144.33998859487,
          12195.5961327533,
          12169.326571769154,
          12316.476780266166,
          12622.731979245134,
          12720.334056987029,
          12775.433887222041,
          12787.607746194968,
          12747.883972104535,
          12754.077160489362,
          12672.06628036527,
          12509.755157196909,
          12561.011301355338,
          12606.9282638306,
          12611.200921015386,
          12678.900957655029,
          12718.197072475508,
          12761.338185210821,
          12827.97169735208,
          12789.101929963304,
          12868.54816630592,
          12891.614218280163,
          12897.594888868265,
          12977.681302277562,
          12956.325887383133,
          12980.886123125714,
          12914.040093187728,
          12873.888659827342,
          12973.411268769278,
          12906.565238831292,
          12904.00190688807,
          12959.10173712308,
          12905.709920291381,
          12521.075009468179,
          12517.230011553347,
          12667.5745461925,
          12743.431593079304,
          12885.074704596967,
          12885.932646813379,
          12750.288571619334,
          12604.787343804324,
          12558.93072588863,
          12528.073666539362,
          12684.716336623454,
          12757.78835090255,
          12613.574036412156,
          12632.001428329473,
          12439.142839639173,
          12458.429485611154,
          12475.572587880357,
          12702.503551474092,
          12678.07449955665,
          12805.360853251066,
          12922.574912851287,
          12995.217956022181,
          13066.147738436754,
          13028.003417600998,
          12843.71769188355,
          12954.076084781991,
          12896.00362906932,
          12965.217527051072,
          12896.217458704297,
          12809.431487345137,
          12895.360828326138,
          12947.645453673662,
          12992.646753049448,
          12873.718120854654,
          12961.145581118744,
          12971.004045577964,
          12929.21806175634,
          13065.718767328544,
          13065.075966585362,
          13103.432805217844,
          13134.289864567112,
          13079.647865881836,
          12855.932217842268,
          12797.432102859644,
          12733.78827009331,
          12740.216277525135,
          12536.857735470681,
          12732.50266860694,
          12509.429821310554,
          12361.357390522811,
          12494.215121270896,
          12272.429187299125,
          12341.21411417267,
          12012.4989324916,
          11912.640492957307,
          11975.855354615436,
          11816.211198612156,
          12060.283952636843,
          12153.285413631103,
          12021.92711400436,
          12152.856442522896,
          12117.713607606329,
          12121.710778758323,
          12338.7924607606,
          12368.453123624597,
          12220.795233724295,
          12188.34035538483,
          11942.887547519678,
          12023.057918577062,
          12057.016163552624,
          12133.317923606648,
          11535.378113106934,
          10860.062802944425,
          10840.719092008509,
          10670.923275696821,
          11791.576188089244,
          11274.881144174802,
          11476.056787378937
         ]
        },
        {
         "mode": "lines",
         "name": "PV (Logit)",
         "type": "scatter",
         "x": [
          "2024-01-02T00:00:00",
          "2024-01-03T00:00:00",
          "2024-01-04T00:00:00",
          "2024-01-05T00:00:00",
          "2024-01-08T00:00:00",
          "2024-01-09T00:00:00",
          "2024-01-10T00:00:00",
          "2024-01-11T00:00:00",
          "2024-01-12T00:00:00",
          "2024-01-16T00:00:00",
          "2024-01-17T00:00:00",
          "2024-01-18T00:00:00",
          "2024-01-19T00:00:00",
          "2024-01-22T00:00:00",
          "2024-01-23T00:00:00",
          "2024-01-24T00:00:00",
          "2024-01-25T00:00:00",
          "2024-01-26T00:00:00",
          "2024-01-29T00:00:00",
          "2024-01-30T00:00:00",
          "2024-01-31T00:00:00",
          "2024-02-01T00:00:00",
          "2024-02-02T00:00:00",
          "2024-02-05T00:00:00",
          "2024-02-06T00:00:00",
          "2024-02-07T00:00:00",
          "2024-02-08T00:00:00",
          "2024-02-09T00:00:00",
          "2024-02-12T00:00:00",
          "2024-02-13T00:00:00",
          "2024-02-14T00:00:00",
          "2024-02-15T00:00:00",
          "2024-02-16T00:00:00",
          "2024-02-20T00:00:00",
          "2024-02-21T00:00:00",
          "2024-02-22T00:00:00",
          "2024-02-23T00:00:00",
          "2024-02-26T00:00:00",
          "2024-02-27T00:00:00",
          "2024-02-28T00:00:00",
          "2024-02-29T00:00:00",
          "2024-03-01T00:00:00",
          "2024-03-04T00:00:00",
          "2024-03-05T00:00:00",
          "2024-03-06T00:00:00",
          "2024-03-07T00:00:00",
          "2024-03-08T00:00:00",
          "2024-03-11T00:00:00",
          "2024-03-12T00:00:00",
          "2024-03-13T00:00:00",
          "2024-03-14T00:00:00",
          "2024-03-15T00:00:00",
          "2024-03-18T00:00:00",
          "2024-03-19T00:00:00",
          "2024-03-20T00:00:00",
          "2024-03-21T00:00:00",
          "2024-03-22T00:00:00",
          "2024-03-25T00:00:00",
          "2024-03-26T00:00:00",
          "2024-03-27T00:00:00",
          "2024-03-28T00:00:00",
          "2024-04-01T00:00:00",
          "2024-04-02T00:00:00",
          "2024-04-03T00:00:00",
          "2024-04-04T00:00:00",
          "2024-04-05T00:00:00",
          "2024-04-08T00:00:00",
          "2024-04-09T00:00:00",
          "2024-04-10T00:00:00",
          "2024-04-11T00:00:00",
          "2024-04-12T00:00:00",
          "2024-04-15T00:00:00",
          "2024-04-16T00:00:00",
          "2024-04-17T00:00:00",
          "2024-04-18T00:00:00",
          "2024-04-19T00:00:00",
          "2024-04-22T00:00:00",
          "2024-04-23T00:00:00",
          "2024-04-24T00:00:00",
          "2024-04-25T00:00:00",
          "2024-04-26T00:00:00",
          "2024-04-29T00:00:00",
          "2024-04-30T00:00:00",
          "2024-05-01T00:00:00",
          "2024-05-02T00:00:00",
          "2024-05-03T00:00:00",
          "2024-05-06T00:00:00",
          "2024-05-07T00:00:00",
          "2024-05-08T00:00:00",
          "2024-05-09T00:00:00",
          "2024-05-10T00:00:00",
          "2024-05-13T00:00:00",
          "2024-05-14T00:00:00",
          "2024-05-15T00:00:00",
          "2024-05-16T00:00:00",
          "2024-05-17T00:00:00",
          "2024-05-20T00:00:00",
          "2024-05-21T00:00:00",
          "2024-05-22T00:00:00",
          "2024-05-23T00:00:00",
          "2024-05-24T00:00:00",
          "2024-05-28T00:00:00",
          "2024-05-29T00:00:00",
          "2024-05-30T00:00:00",
          "2024-05-31T00:00:00",
          "2024-06-03T00:00:00",
          "2024-06-04T00:00:00",
          "2024-06-05T00:00:00",
          "2024-06-06T00:00:00",
          "2024-06-07T00:00:00",
          "2024-06-10T00:00:00",
          "2024-06-11T00:00:00",
          "2024-06-12T00:00:00",
          "2024-06-13T00:00:00",
          "2024-06-14T00:00:00",
          "2024-06-17T00:00:00",
          "2024-06-18T00:00:00",
          "2024-06-20T00:00:00",
          "2024-06-21T00:00:00",
          "2024-06-24T00:00:00",
          "2024-06-25T00:00:00",
          "2024-06-26T00:00:00",
          "2024-06-27T00:00:00",
          "2024-06-28T00:00:00",
          "2024-07-01T00:00:00",
          "2024-07-02T00:00:00",
          "2024-07-03T00:00:00",
          "2024-07-05T00:00:00",
          "2024-07-08T00:00:00",
          "2024-07-09T00:00:00",
          "2024-07-10T00:00:00",
          "2024-07-11T00:00:00",
          "2024-07-12T00:00:00",
          "2024-07-15T00:00:00",
          "2024-07-16T00:00:00",
          "2024-07-17T00:00:00",
          "2024-07-18T00:00:00",
          "2024-07-19T00:00:00",
          "2024-07-22T00:00:00",
          "2024-07-23T00:00:00",
          "2024-07-24T00:00:00",
          "2024-07-25T00:00:00",
          "2024-07-26T00:00:00",
          "2024-07-29T00:00:00",
          "2024-07-30T00:00:00",
          "2024-07-31T00:00:00",
          "2024-08-01T00:00:00",
          "2024-08-02T00:00:00",
          "2024-08-05T00:00:00",
          "2024-08-06T00:00:00",
          "2024-08-07T00:00:00",
          "2024-08-08T00:00:00",
          "2024-08-09T00:00:00",
          "2024-08-12T00:00:00",
          "2024-08-13T00:00:00",
          "2024-08-14T00:00:00",
          "2024-08-15T00:00:00",
          "2024-08-16T00:00:00",
          "2024-08-19T00:00:00",
          "2024-08-20T00:00:00",
          "2024-08-21T00:00:00",
          "2024-08-22T00:00:00",
          "2024-08-23T00:00:00",
          "2024-08-26T00:00:00",
          "2024-08-27T00:00:00",
          "2024-08-28T00:00:00",
          "2024-08-29T00:00:00",
          "2024-08-30T00:00:00",
          "2024-09-03T00:00:00",
          "2024-09-04T00:00:00",
          "2024-09-05T00:00:00",
          "2024-09-06T00:00:00",
          "2024-09-09T00:00:00",
          "2024-09-10T00:00:00",
          "2024-09-11T00:00:00",
          "2024-09-12T00:00:00",
          "2024-09-13T00:00:00",
          "2024-09-16T00:00:00",
          "2024-09-17T00:00:00",
          "2024-09-18T00:00:00",
          "2024-09-19T00:00:00",
          "2024-09-20T00:00:00",
          "2024-09-23T00:00:00",
          "2024-09-24T00:00:00",
          "2024-09-25T00:00:00",
          "2024-09-26T00:00:00",
          "2024-09-27T00:00:00",
          "2024-09-30T00:00:00",
          "2024-10-01T00:00:00",
          "2024-10-02T00:00:00",
          "2024-10-03T00:00:00",
          "2024-10-04T00:00:00",
          "2024-10-07T00:00:00",
          "2024-10-08T00:00:00",
          "2024-10-09T00:00:00",
          "2024-10-10T00:00:00",
          "2024-10-11T00:00:00",
          "2024-10-14T00:00:00",
          "2024-10-15T00:00:00",
          "2024-10-16T00:00:00",
          "2024-10-17T00:00:00",
          "2024-10-18T00:00:00",
          "2024-10-21T00:00:00",
          "2024-10-22T00:00:00",
          "2024-10-23T00:00:00",
          "2024-10-24T00:00:00",
          "2024-10-25T00:00:00",
          "2024-10-28T00:00:00",
          "2024-10-29T00:00:00",
          "2024-10-30T00:00:00",
          "2024-10-31T00:00:00",
          "2024-11-01T00:00:00",
          "2024-11-04T00:00:00",
          "2024-11-05T00:00:00",
          "2024-11-06T00:00:00",
          "2024-11-07T00:00:00",
          "2024-11-08T00:00:00",
          "2024-11-11T00:00:00",
          "2024-11-12T00:00:00",
          "2024-11-13T00:00:00",
          "2024-11-14T00:00:00",
          "2024-11-15T00:00:00",
          "2024-11-18T00:00:00",
          "2024-11-19T00:00:00",
          "2024-11-20T00:00:00",
          "2024-11-21T00:00:00",
          "2024-11-22T00:00:00",
          "2024-11-25T00:00:00",
          "2024-11-26T00:00:00",
          "2024-11-27T00:00:00",
          "2024-11-29T00:00:00",
          "2024-12-02T00:00:00",
          "2024-12-03T00:00:00",
          "2024-12-04T00:00:00",
          "2024-12-05T00:00:00",
          "2024-12-06T00:00:00",
          "2024-12-09T00:00:00",
          "2024-12-10T00:00:00",
          "2024-12-11T00:00:00",
          "2024-12-12T00:00:00",
          "2024-12-13T00:00:00",
          "2024-12-16T00:00:00",
          "2024-12-17T00:00:00",
          "2024-12-18T00:00:00",
          "2024-12-19T00:00:00",
          "2024-12-20T00:00:00",
          "2024-12-23T00:00:00",
          "2024-12-24T00:00:00",
          "2024-12-26T00:00:00",
          "2024-12-27T00:00:00",
          "2024-12-30T00:00:00",
          "2024-12-31T00:00:00",
          "2025-01-02T00:00:00",
          "2025-01-03T00:00:00",
          "2025-01-06T00:00:00",
          "2025-01-07T00:00:00",
          "2025-01-08T00:00:00",
          "2025-01-10T00:00:00",
          "2025-01-13T00:00:00",
          "2025-01-14T00:00:00",
          "2025-01-15T00:00:00",
          "2025-01-16T00:00:00",
          "2025-01-17T00:00:00",
          "2025-01-21T00:00:00",
          "2025-01-22T00:00:00",
          "2025-01-23T00:00:00",
          "2025-01-24T00:00:00",
          "2025-01-27T00:00:00",
          "2025-01-28T00:00:00",
          "2025-01-29T00:00:00",
          "2025-01-30T00:00:00",
          "2025-01-31T00:00:00",
          "2025-02-03T00:00:00",
          "2025-02-04T00:00:00",
          "2025-02-05T00:00:00",
          "2025-02-06T00:00:00",
          "2025-02-07T00:00:00",
          "2025-02-10T00:00:00",
          "2025-02-11T00:00:00",
          "2025-02-12T00:00:00",
          "2025-02-13T00:00:00",
          "2025-02-14T00:00:00",
          "2025-02-18T00:00:00",
          "2025-02-19T00:00:00",
          "2025-02-20T00:00:00",
          "2025-02-21T00:00:00",
          "2025-02-24T00:00:00",
          "2025-02-25T00:00:00",
          "2025-02-26T00:00:00",
          "2025-02-27T00:00:00",
          "2025-02-28T00:00:00",
          "2025-03-03T00:00:00",
          "2025-03-04T00:00:00",
          "2025-03-05T00:00:00",
          "2025-03-06T00:00:00",
          "2025-03-07T00:00:00",
          "2025-03-10T00:00:00",
          "2025-03-11T00:00:00",
          "2025-03-12T00:00:00",
          "2025-03-13T00:00:00",
          "2025-03-14T00:00:00",
          "2025-03-17T00:00:00",
          "2025-03-18T00:00:00",
          "2025-03-19T00:00:00",
          "2025-03-20T00:00:00",
          "2025-03-21T00:00:00",
          "2025-03-24T00:00:00",
          "2025-03-25T00:00:00",
          "2025-03-26T00:00:00",
          "2025-03-27T00:00:00",
          "2025-03-28T00:00:00",
          "2025-03-31T00:00:00",
          "2025-04-01T00:00:00",
          "2025-04-02T00:00:00",
          "2025-04-03T00:00:00",
          "2025-04-04T00:00:00",
          "2025-04-07T00:00:00",
          "2025-04-08T00:00:00",
          "2025-04-09T00:00:00",
          "2025-04-10T00:00:00",
          "2025-04-11T00:00:00"
         ],
         "y": [
          10000,
          9918.333477416903,
          9886.384968642476,
          9899.927074911608,
          10041.25665708719,
          10026.02424723114,
          10082.72517605198,
          10078.282635813637,
          10085.264238987551,
          10048.238260261107,
          9992.383467112419,
          10081.24345474703,
          10206.917559230485,
          10228.499266223278,
          10197.320721177462,
          10208.46697080236,
          10263.990225149111,
          10250.951166945035,
          10332.132638035802,
          10324.14020001872,
          10155.678280417398,
          10288.597388696558,
          10396.90868141016,
          10359.051205790343,
          10389.128149279486,
          10475.77744425761,
          10480.403512762357,
          10540.975343350441,
          10536.34797080947,
          10391.230907690731,
          10485.662038835759,
          10558.010620563058,
          10505.432532028279,
          10447.595917420096,
          10457.058656279769,
          10673.47324792924,
          10680.833228377664,
          10641.715401747322,
          10661.485242921732,
          10647.395131521087,
          10685.671202768819,
          10785.991361501563,
          10774.423908176304,
          10666.74246495891,
          10720.79281039062,
          10827.212598561267,
          10762.225301318615,
          10752.971860272897,
          10868.645741507375,
          10976.057812959625,
          10954.359748228684,
          10879.140977586832,
          10943.79660720575,
          11004.614631929093,
          11106.397885333241,
          11143.10277243896,
          11121.976490393095,
          11091.249271404493,
          11070.76270009049,
          11163.800382344918,
          11161.666254583775,
          11142.248066141545,
          10865.020532027173,
          11593.493344981303,
          11734.413390494477,
          12443.780539426754,
          12461.294779430375,
          12475.708891660493,
          12350.789308018295,
          5787.556841928185,
          5707.67161712085,
          5636.164976131227,
          5625.8854648523975,
          5592.590400959891,
          5581.082279343794,
          5532.3688118061855,
          5583.317120856664,
          5649.572298662153,
          5646.890626970413,
          5625.438634673526,
          5678.734010745476,
          5698.844821887235,
          5608.567860292466,
          5590.356250065535,
          5642.645049652625,
          5712.587439706942,
          5771.579727904867,
          5777.947921226918,
          5778.507667532907,
          5811.802731425414,
          5819.2890361224145,
          5820.069435043781,
          5846.773581143315,
          5919.173882490678,
          5906.9962062247905,
          5915.487360860364,
          5922.303074979803,
          5936.826782339391,
          5943.667957127887,
          5900.254193770866,
          5939.29322772765,
          5943.443291994637,
          5901.8247694709025,
          4736.973618408889,
          4780.118182504743,
          4784.015407274579,
          4789.363726373609,
          4846.285842843679,
          4846.195079414595,
          4840.303300277217,
          4855.259096425291,
          4866.951891270961,
          4906.924217493496,
          4916.804545097875,
          4919.796376649187,
          4958.951832009959,
          4971.551140610314,
          4958.045878523353,
          4951.399418281178,
          4935.303476588738,
          4954.308890424618,
          4960.4920089639945,
          4968.312230835382,
          4948.761115888832,
          4958.94622932915,
          4992.318597560215,
          5014.597657792034,
          5043.514213976734,
          5049.333718531692,
          5054.244468259641,
          5104.256798489575,
          5060.245499672768,
          5092.162851698074,
          5106.166752376919,
          5136.448121606376,
          5064.428461163797,
          5025.5088786650285,
          4992.136510433964,
          5043.604977405817,
          5035.693992105345,
          4921.572426465225,
          4895.928956408382,
          4950.761833205261,
          4953.6718656167795,
          4928.574656938687,
          5008.686269271827,
          4937.758571318669,
          4845.825862749362,
          4704.697134543805,
          4748.072529088937,
          4716.336703921802,
          4201.114432131789,
          4219.6396030271235,
          4221.856106701577,
          4291.287694074317,
          4304.825731702132,
          4378.61179273285,
          4388.428504099131,
          4430.387933253291,
          4423.183320737516,
          4438.38422390807,
          4398.977689862415,
          4445.718608522824,
          4435.120745259494,
          4441.210289477704,
          4415.427791747872,
          4415.822976221023,
          4457.976636397779,
          4366.236339529539,
          4357.2991281583145,
          4346.701264894984,
          4273.545358435506,
          4321.392891076836,
          4340.216048923138,
          4384.742277780254,
          4421.676189404119,
          4444.769873418973,
          4451.333541548867,
          4453.152559598525,
          4439.945309339234,
          4515.710115514186,
          4507.904369428606,
          4519.168832395107,
          4532.099794619531,
          4522.104210035379,
          4540.032720911638,
          4533.4480997208975,
          4551.61489075421,
          4510.839747068878,
          4512.743064642402,
          4504.492918754707,
          4545.427403158561,
          4504.3340653166715,
          4546.934074417479,
          4578.428473989822,
          4576.087698083554,
          4603.490256366436,
          4641.138891038928,
          4605.078810469792,
          4625.0947873261375,
          4625.49143796681,
          4643.283634232525,
          4635.658476959386,
          4633.196120522151,
          4590.860860936627,
          4523.890989627553,
          4522.328987039212,
          4536.308814258757,
          4543.650610208379,
          4529.90441175435,
          4441.1043727149645,
          4459.848403775055,
          4450.241800018443,
          4504.053652701728,
          4616.04914233966,
          4651.741573105982,
          4671.891214603369,
          4676.34311387235,
          4661.816393854675,
          4664.081201661665,
          4634.090368181101,
          4574.734269824151,
          4593.47830088424,
          4610.269828708904,
          4649.364203234574,
          4686.784011594707,
          4701.309908064244,
          4688.200684644736,
          4712.680192413205,
          4698.400399225432,
          4727.586985632612,
          4736.06088383108,
          4738.258034595274,
          4731.0933515376255,
          4736.053257802811,
          4743.768714299645,
          4684.25110139422,
          4669.687154357989,
          4705.786538221278,
          4681.539781427792,
          4680.60999567588,
          4700.596106807836,
          4681.229535619069,
          4561.456398081064,
          4043.03046380577,
          4091.59133015174,
          4100.444216889207,
          4146.020612324188,
          4146.2966717336185,
          4102.65058161871,
          4055.832763059669,
          4041.077514258347,
          4031.1486619209886,
          4081.5514538199322,
          4105.063779850692,
          4058.6600504057974,
          4064.589418179918,
          4002.533457907645,
          4008.7393072003856,
          4014.2554300787374,
          4087.2748323099518,
          4079.414314997381,
          4120.371147470876,
          4158.087025593285,
          4181.46132191933,
          4204.28434364489,
          3888.0356018995453,
          3282.8809372963956,
          3311.08877189758,
          3296.245331515705,
          3313.9365476986836,
          3296.299986814843,
          3274.117312153613,
          3296.081030309708,
          3309.4450892204336,
          3320.947514874627,
          3290.5491092963302,
          3312.8957498549744,
          3315.4155938612494,
          3304.7350095456295,
          3339.624873602177,
          3339.4605723961795,
          3875.7551508984384,
          3884.8821032392693,
          3868.7200019786355,
          3802.549015481061,
          3785.245754164548,
          3766.4210754460964,
          3768.3223621763946,
          3708.1726343483638,
          3766.0408181000366,
          3700.059960275492,
          3656.2628503988253,
          3695.559730990186,
          3629.959518529401,
          3650.3048386143905,
          3264.3265001607942,
          3237.1905518232834,
          3254.368821663248,
          3210.986453684197,
          3277.3118005922406,
          3302.584405017294,
          3266.888553479874,
          3302.467834621393,
          3292.917974267305,
          3294.0041822070903,
          3352.9948627675526,
          3361.054974851092,
          3320.9298047538323,
          3312.110380917177,
          3245.41001242966,
          3267.195843025032,
          3276.4237979739264,
          3297.1583560998433,
          2743.2518459229914,
          2529.23814250034,
          2542.2156685478312,
          2502.3974995668045,
          2598.6611004093847,
          2400.886986342645,
          2443.725573957154
         ]
        }
       ],
       "layout": {
        "height": 360,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Portfolio"
        },
        "xaxis": {
         "autorange": true,
         "range": [
          "2024-01-02",
          "2025-04-11"
         ],
         "type": "date"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          1804.5868264412857,
          13730.59002446847
         ],
         "type": "linear"
        }
       }
      },
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABF4AAAFoCAYAAABuXz/oAAAAAXNSR0IArs4c6QAAIABJREFUeF7s3Qd0FFXfBvBnZlMhnd57bypFERAEFVFUQEB5xQIqomABe3vtBVQsiF1BVPAFBFSsiKCACFJEQKT3DiENSNuZ7/vfNSGBTTK7m9ndsM89hyOSuffO/u4SMs/eopmmaYKFAhSgAAUoQAEKUIACFKAABShAAQpQoNQFNAYvpW7KBilAAQpQgAIUoAAFKEABClCAAhSggBJg8MI3AgUoQAEKUIACFKAABShAAQpQgAIUsEmAwYtNsGyWAhSgAAUoQAEKUIACFKAABShAAQoweOF7gAIUoAAFKEABClCAAhSgAAUoQAEK2CTA4MUmWDZLAQpQgAIUoAAFKEABClCAAhSgAAUYvPA9QAEKUIACFKAABShAAQpQgAIUoAAFbBJg8GITLJulAAUoQAEKUIACFKAABShAAQpQgAIMXvgeoAAFKEABClCAAhSgAAUoQAEKUIACNgkweLEJls1SgAIUoAAFKEABClCAAhSgAAUoQAEGL3wPUIACFKAABShAAQpQgAIUoAAFKEABmwQYvNgEy2YpQAEKUIACFKAABShAAQpQgAIUoACDF74HKEABClCAAhSgAAUoQAEKUIACFKCATQIMXmyCZbMUoAAFKEABClCAAhSgAAUoQAEKUIDBC98DFKAABShAAQpQgAIUoAAFKEABClDAJgEGLzbBslkKUIACFKAABShAAQpQgAIUoAAFKMDghe8BClCAAhSgAAUoQAEKUIACFKAABShgkwCDF5tg2SwFKEABClCAAhSgAAUoQAEKUIACFGDwwvcABShAAQpQgAIUoAAFKEABClCAAhSwSYDBi02wbJYCFKAABShAAQpQgAIUoAAFKEABCjB44XuAAhSgAAUoQAEKUIACFKAABShAAQrYJMDgxSZYNksBClCAAhSgAAUoQAEKUIACFKAABRi88D1AAQpQgAIUoAAFKEABClCAAhSgAAVsEmDwYhMsm6UABShAAQpQgAIUoAAFKEABClCAAgxe+B6gAAUoQAEKUIACFKAABShAAQpQgAI2CTB4sQmWzVKAAhSgAAUoQAEKUIACFKAABShAAQYvfA9QgAIUoAAFKEABClCAAhSgAAUoQAGbBBi82ATLZilAAQpQgAIUoAAFKEABClCAAhSgAIMXvgcoQAEKUIACFKAABShAAQpQgAIUoIBNAgxebIJlsxSgAAUoQAEKUIACFKAABShAAQpQgMEL3wMUoAAFKEABClCAAhSgAAUoQAEKUMAmAQYvNsGyWQpQgAIUoAAFKEABClCAAhSgAAUowOCF7wEKUIACFKAABShAAQpQgAIUoAAFKGCTAIMXm2DZLAUoQAEKUIACFKAABShAAQpQgAIUYPDC9wAFKEABClCAAhSgAAUoQAEKUIACFLBJgMGLTbBslgIUoAAFKEABClCAAhSgAAUoQAEKMHjx83sg1+nEvIUrsHnbHuTkOnHu2c3QsV0LS3exe98hfD9/Gc5r2xwtm9RTdTKzspGTk4vo6EiEORyW2uFFFKAABShAAQpQgAIUoAAFKEABCvhHICSCl+lzFuDJlycVEq1SKRGXdG2PGwf0RLUqFUpNe+eeA5j+9S/o2rEN2rVpUqhd0zRx8+ixWLpqff6fX3NVd/x31A2W+l+yfB1uue8lPHLXYFzX7yJV5/GxH2Hmt7/inTH3osu5rSy1w4soQAEKUIACFKAABShAAQpQgAIU8I9ASAQv076aj6fGfYz2ZzVFo3o1kH7sBFat2QSZQSIBzNS3/qv+Wxpl2ap/MGTUi3hgxCAV6hQsy1dvwI13v4DLe5yH+26/FhUS45Bx/ATiY8tb6tpd8PLJjB/x2/J1GDmkL1o0qWupHV5EAQpQgAIUoAAFKEABClCAAhSggH8EQip4ef7hW3FVz05KVpb8PPDMu/hhwTLcel1v3HNr/1IRLy54+eKbX/Hflz7CBy/fb3l5UcGbche8lHTTMstG07SSLuPXKUABClCAAhSgAAUoQAEKUIACFLBBIGSDF7HcuHU3+g59TIUgEoZIWblmI976+EusXrcFUZHhaNu6CUbfNgC1a1TJ55/13UL8+MtyPH7P9dix+wDm/7YKe/YfRuf2rTD7+0VYu2EbalarhPp1qqs657RqhGqVK2D8RzPVLJvWzRsgIS5Gfe2NZ+5EeHgY9h1MxqvvTsOSFeuQnJKuZudIINSpfcv8ft0FL1//+Bu+/XkpHrnrOtSqXjn/WlleNePrX/LvRZY+3X1Lf5QvF2XD24hNUoACFKAABShAAQpQgAIUoAAFKOBOIKSDF9mPpdd1D6oNbj969UH8tHAF7n58vHLq2a09TmRm49ffV6v/n/XRs2hcv6b6/avvTccHU75RAcpff2/Jd7150GX4YcEfKlxJSohFlUpJ6mvn/3+wU7N6ZYz/8AsVqkgoExtTTn1t6luPq9Dl6lv+i+MnMlXQEhdbHr8sWa3+v+AsHXfBy5sfzcLbk7/EjPefQrNGdVSbYydMxcfTf1D30KlDK2zbsU8FMHVqVsEXHzyD6KgI/m2gAAUoQAEKUIACFKAABShAAQpQwA8CIR28vPb+DLz/2RwMvfYyjBzaF72uewAHDh3FnMkvoF7taopfApA7Hn5VbVwrG9gWDF7KRUfh/tuvUacMRUZEIDIiXM2iKWqPFwlDJBSZ+OpD6HB20/zhfeCZd/DNvN8x9vHhav8XKTKDps+Qx9Tv5894FTHlo2EleNmyfQ+uvOlRFcJMfPXB/IBn3LvT8OHUb3Hv8IHq9bJQgAIUoAAFKEABClCAAhSgAAUoYL9ASAUvA6+8EO3bNMWRo6n4feXfWPDbn5Dw5LvPxmDX3oMYPPI5XNfvYrVsp2CRP1+1dhOWzHkLcTHl8me8yGwVmfVSsBS3x4u74EX2mmnT42Y0qFMdX338fKG23po0GxMmzcZbL4xSpyRZCV5kJo7MyHnt6ZG4+IJ2+e1lHDuBcy+/XQUyMjuGhQIUoAAFKEABClCAAhSgAAUoQAH7BUIqeDmVU/ZRefr+IWr/Ftkr5aHn38MzDwxFv8suKHTp8298hs9mzsUXHzyNpg1r5wcvsyc+i0b1XMuP8oqnwYvMbLnk2vtwxSXn48VHhhVqa+6vy3HPf9/Eo3dfj//07WEpeMk7XrrgrJ28Ri8b/KDak2bdgsJHa9v/NmMPFKAABShAAQpQgAIUoAAFKECB0BQIqeBlyLW90LlDKzVrRfZckf/mFdmM9smXJ6nwQ0KQguWltz7HpGnfq/1YZIZL3h4vpRG8bNmxF1fe+IgKeyT0KVhk096Rj7yO+4ZfA7l3KzNe8pYt/fj5y6hRtWKh9mQjYVkKtXb+RJ50FJp/3/mqKUABClCAAhSgAAUoQAEKUMDPAiEVvBTcqPZU57xQ486h/TD8hisLfXn0kxPUprnzZ7yGyhUTLAUv7vZScbfUSDbwbXfpMHWK0aTXHirU79TZ8/Dsa59g3JN3oGe3DpaCFzk56Z3JX+Hj1x9GuzZN8ttzOg2c1/sOVKoQj28/HePntxm7owAFKEABClCAAhSgAAUoQAEKhKYAg5d/x/1wciq69rsbVSol4rvPxqqNcqXsP5SMHgNGqz+fN22cmilS3IyXfzbvVCcUydIgWSJUsBS1uW7/W5/A+k071B4vsteLFNn7ZcCtT6gZKt9PGauOirYy4yVvM+DeF3fEmEdvy+9ejr8e9cSbbmfWhOZbn6+aAhSgAAUoQAEKUIACFKAABShgvwCDlwLGb3z4Bd795Gu1nOjaq7ojJycXb308W510lDfrRC4vLniRI6C79rtHHQUtJyXJciaHw6HaKyp4WfzHWgy7/2V1/POIIX1RPjoKs75biKWr1qt6j4+6Qd2lleDFNE38Z8Sz6phrWTLV9bw26nhrOcFJirslSPa/zdgDBShAAQpQgAIUoAAFKEABClAgNAVCI3j5egGeesX9/i0Fh11mmbz36RxMmDgr/4/l1KP/jrqh0L4vecdQfznxOTSsV+O0d47MOpFjquUkJClyRLQcFT15+g8YM2HqacuA5BrZSPeRFz5QgU1ekX1d7hraDxH/zr75fcXfuPnesfmb7cp1cq9vffwlZn74DJo0qKWqpqYdw1PjJqnlUXmlZrVKePmJO9Cqab3QfKfzVVOAAhSgAAUoQAEKUIACFKAABQIgEBLBi6euMtNl554DCAsLgwQWDofuaRPq+oOHUyAzUCpVSICuayW2YRimmp2SmZWNOjWr5C93KrFiERfIEdJyTHaFxHi1Nw0LBShAAQpQgAIUoAAFKEABClCAAv4VYPDiX2/2RgEKUIACFKAABShAAQpQgAIUoEAICTB4CaHB5kulAAUoQAEKUIACFKAABShAAQpQwL8CDF78683eKEABClCAAhSgAAUoQAEKUIACFAghAQYvITTYfKkUoAAFKEABClCAAhSgAAUoQAEK+FeAwYt/vdkbBShAAQpQgAIUoAAFKEABClCAAiEkwOAlhAabL5UCFKAABShAAQpQgAIUoAAFKEAB/wowePGvN3ujAAUoQAEKUIACFKAABShAAQpQIIQEGLyE0GDzpVKAAhSgAAUoQAEKUIACFKAABSjgXwEGL/71Zm8UoAAFKEABClCAAhSgAAUoQAEKhJAAg5cQGmy+VApQgAIUoAAFKEABClCAAhSgAAX8K8Dgxb/e7I0CFKAABShAAQpQgAIUoAAFKECBEBJg8BJCg82XSgEKUIACFKAABShAAQpQgAIUoIB/BRi8+NebvVGAAhSgAAUoQAEKUIACFKAABSgQQgIMXkJosPlSKUABClCAAhSgAAUoQAEKUIACFPCvAIMX/3qzNwpQgAIUoAAFKEABClCAAhSgAAVCSIDBSwgNNl8qBShAAQpQgAIUoAAFKEABClCAAv4VYPDiX2/2RgEKUIACFKAABShAAQpQgAIUoEAICTB4CaHB5kulAAUoQAEKUIACFKAABShAAQpQwL8CDF78683eKEABClCAAhSgAAUoQAEKUIACFAghAQYvITTYfKkUoAAFKEABClCAAhSgAAUoQAEK+FeAwYt/vdkbBShAAQpQgAIUoAAFKEABClCAAiEkwOAlhAabL5UCFKAABShAAQpQgAIUoAAFKEAB/wowePGvN3ujAAUoQAEKUIACFKAABShAAQpQIIQEGLyE0GDzpVKAAhSgAAUoQAEKUIACFKAABSjgXwEGL/71Zm8UoAAFKEABClCAAhSgAAUoQAEKhJAAg5cQGmy+VApQgAIUoAAFKEABClCAAhSgAAX8K8Dgxb/e7I0CFKAABShAAQpQgAIUoAAFKECBEBJg8BJCg82XSgEKUIACFKAABShAAQpQgAIUoIB/BRi8+NebvVGAAhSgAAUoQAEKUIACFKAABSgQQgIMXkJosPlSKUABClCAAhSgAAUoQAEKUIACFPCvAIMX/3qzNwpQgAIUoAAFKEABClCAAhSgAAVCSIDBSwgNNl8qBShAAQpQgAIUoAAFKEABClCAAv4VYPDiX2/2RgEKUIACFKAABShAAQpQgAIUoEAICTB4CaHB5kulAAUoQAEKUIACFKAABShAAQpQwL8CDF78683eKEABClCAAhSgAAUoQAEKUIACFAghAQYvITTYfKkUoAAFKEABClCAAhSgAAUoQAEK+FeAwYt/vdkbBShAAQpQgAIUoAAFKEABClCAAiEkwOAlhAabL5UCFKAABShAAQpQgAIUoAAFKEAB/wowePGvN3ujAAUoQAEKUIACFKAABShAAQpQIIQEGLyE0GDzpVKAAhSgAAUoQAEKUIACFKAABSjgXwEGL/71Zm8UoAAFKEABClCAAhSgAAUoQAEKhJAAg5cQGmy+VApQgAIUoAAFKEABClCAAhSgAAX8K8Dgxb/e7I0CFKAABShAAQpQgAIUoAAFKECBEBJg8BJCg82XSgEKUIACFKAABShAAQpQgAIUoIB/BRi8+NebvVGAAhSgAAUoQAEKUIACFKAABSgQQgIMXkJosPlSKUABClCAAhSgAAUoQAEKUIACFPCvAIMX/3qzNwpQgAIUoAAFKEABClCAAhSgAAVCSIDBSwgNNl8qBShAAQpQgAIUoAAFKEABClCAAv4VYPDiX2/2RgEKUIACFKAABShAAQpQgAIUoEAICTB48XGw9x454WMLrB4ogfAwHQnlw3EoNStQt8B+S1HAoWuoGB+JA0czS7FVNhVIgeoVosHvsYEcAXv65rja4xqoVqsmRePg0RMwzEDdAfstTYHKCVFITs9CrpMDWpqu/morrlw4DNNExolcf3V5xvQj/zaxUMBOAQYvPuryocBHwABWZ/ASQHwbumbwYgNqgJvkA3qAB8Cm7jmuNsEGqFkGLwGCt6lbBi82wfqpWQYv3kMzePHejjWtCTB4seZU5FUMXnwEDGB1Bi8BxLehawYvNqAGuEk+oAd4AGzqnuNqE2yAmmXwEiB4m7pl8GITrJ+aZfDiPTSDF+/tWNOaAIMXa04MXnx0CsbqDF6CcVS8vycGL97bBWtNPqAH68j4dl8cV9/8gq02g5dgGxHf7ofBi29+ga7N4MX7EWDw4r0da1oTYPBizYnBi49OwVidwUswjor398TgxXu7YK3JB/RgHRnf7ovj6ptfsNVm8BJsI+Lb/TB48c0v0LUZvHg/AgxevLdjTWsCDF6sOTF48dEpGKszeAnGUfH+nhi8eG8XrDX5gB6sI+PbfXFcffMLttoMXoJtRHy7HwYvvvkFujaDF+9HgMGL93asaU2AwYs1JwYvPjoFY3UGL8E4Kt7fE4MX7+2CtSYf0IN1ZHy7L46rb37BVpvBS7CNiG/3w+DFN79A12bw4v0IMHjx3o41rQkweLHmxODFR6dgrM7gJRhHxft7YvDivV2w1uQDerCOjG/3xXH1zS/YajN4CbYR8e1+GLz45hfo2gxevB8BBi/e27GmNQEGL9acGLz46BSM1Rm8BOOoeH9PDF68twvWmnxAD9aR8e2+OK6++QVbbQYvwTYivt0Pgxff/E6tbTiBtHQN6elAeoaGtAwgLc1Eet6fpbu+HhcHdGhrok0bE1GRptc3weDFazowePHejjWtCTB4sebE4MVHp2CszuAlGEfF+3ti8OK9XbDW5AN6sI6Mb/fFcfXNL9hqM3gJthHx7X6CPXjJyQUWL3Fg6VKgTm0TLVuaaNnc+6DCNy33tVf/peOL2bpXTVetYuKO25xe1ZVKDF68pmPw4j2dqmmaJg4eTkFcbHlER0X42Jp/qi9fvQHxceXRqF7N0zo8nJyKFX9tRM9u7UvtZhi8+Ei598gJH1tg9UAJMHgJlLw9/TJ4scc1kK3yAT2Q+vb1zXG1zzYQLYdq8LJxk46lfwCVK5lIStJQqQKQVMFEXGzRIYCEBj/O1dGoIdC4keF2uPbu03DokAa59qzWBsLC/DuqwRq87NytYcd2HatWmzh8pHCoERNjosv5Jtq2NRARftJr3wFN/U+1Kq4x+WeDjgqJJipVthbUbN2mY+Uq4OAhDTdcZ0D6ObWcOKFh334NBw4A1aubyM3V8PGnp99ffDwQF2MiNhaIj9MQG+v6vePfS5NTgXk/y8wYDVf3MdCmtfv3R0nvBgYvJQkV/fVQmfGye98h9Bx0fz5EzWqVMKhvD9w08FJcf+fzqF+nGp66b0ghqG/nLcUTL0/E4i/HI6LgXzIAySnpeHPiLMz95Q/1eyl1albB4/fcgI7tWuDrH3/DQ8+/l99eyyb1MHJoX3Q5tzUG3fEMqlWugHFP3pH/9ZVrNqr7mD3xWbeBSMEb6z5gFO65tT+uvKRT/h/Lvb4w/lMsnD2+xDfDiEdeQ+tmDXDb9Vecdu2yVf9gyKgXsW7BpBLbsXoBgxerUkVcx+DFR8AAVmfwEkB8G7pm8GIDaoCb5AN6gAfApu45rjbBBqjZMzV4yckBsnM05GTLfwH5f/kFU8OKPwGZ1eCuOBxAlcomEhOBihUMVKygISnRRFS0hhkzXQ/pUqpXM1X4kusEDh3U1MP90RTX1/JK+XImOncy0amjZw/h27cXvrfwCBM1qlsLG4IleMnI0LBxi4YNG4Gt2zRkZZ60qVnTRJeOJuQV/bEC2LLV9Xqjo010PBc4t72Bw4eByZ/pyMrWUKeWiROZrgBFSqsWJho1NNGwgXlamCJByrLlOlasAlIKjIeMYb8+BuTre/dr2LvXxP4DGlJTC49Z3th1PM9Ar0s8G7f1/+iYOk1X4d19o7yb9cLgxftvhKEWvEx+4xFUTIrHir824PGxH+GFR25FVnYOxk74HIu+HI/IAgGLBBSVKybiidE3ngY8+skJ2LxtD154ZBjq16mOvfsP4eu5S1CtchKuuaq7Cl7GvjUV0959EseOZ+KLb3/F5Ok/4NtPx+D4iUz0v/UJfPDy/Sqkycl14uqbH0fXjmfh3uEDSxxMd8HLN/N+x4vjP2PwUqJeGbyAwUsZHLR/b5nBS9kdO7c/7OoaKsZH4sDRzDPrhYXwq+ED+pk5+BzXM2tcy3LwIiHIwYMamjU1EBHhmhHx9z/A+g2FH/SLGjF5wJeH/WPHNCQfBQ4fKfpBPK+N+HgT2dlQD/BFlYQE2ecD6sFeysjhTlS2OEtj2gwH1v59etu9exno0L7kICCQwYvMMNm02cTmLToOHCz8GmQ2SfOmQJPGhgq2CpY9ezX8ulDD+g2uACb831lCMmuoYJEg69jxwu1Wqmigfj2gQX0gJRVY8IuG4/+OjSz7adfWxMZNgMxwclfCwwG5TteB4yegZiu1O8fAlb1LtnbX3oeTHNixU0OL5ibk3sqXl+AOSEgAEhNKngHF4MX776+hFrx8P2UsalWvrMAkWElKiMO9tw1Ep6tGYvxzd6N7p7PV146mpqPzVXdi0msPof1ZTU8Dbt9rOIbfcCVuHnSZW/y84CVvBophmGjVfQhefGQYrrjkfDz/xqdYtGwNZn/0LKbMnocPp3yDH6a+hHLRUSUOppXgZcuOvXjutU+wdNV6NKhTHSOH9sMlXdvlv+68GS+yVGryjB/x8bTvceDQUTSuXxMbt+7mjJcSR8GPFzB48SN2KXfF4KWUQQPcHGe8BHgAbOieD+g2oAZBkxzXIBiEUrwFT4MXeRiW2SLJyWaBGSUacnJkmYZruUbD+hrq1/PuwdXKS5MZLF9+rWPN2uL34YiMMtXSlYgI+a+GyEggJgZISjTQvi0gIYq7IqFB8lHXkqEjR0wkJ2s4dNi1J0m/viZkw9XlK3Tk5BrQdR1xcSYSE4CERBOJBdr8Ya6m9jO5sJuJCy8oeQZE3vUSPIijFJlRs2ePK2zoc4WBc84u3rWk4EVm/ezarSPjGNC6ZemMUWaWho8m6flBU55pg/oGmjQBmjctfglX3vUyo+XXRRr+WuMa165dnGh7NtSSsKgoHR3PcyI7W8OyP4Bt23Ts2OU+/KpV08TlvQw1KymvfDZVVyGdBGDVa2ioXtVUv09MKPwekFlLp/6Zlfdk3jUStr31rqPIKp3Pd+LCriYk8ClYJMiTEJDBiyfaha+1K3g5cBD4fUXJf3+9v3P3NatW1nBu29O/x+UtNcoLXnKdTvQb+ji6nX8WRt82EHc9/gbCHGH5y39mzPkFr38wAwu+eB2OvLVxBbp8atzHmDN3CW6/8Uq0a90EDevVRLnoyPwrTg1e9h9KRo8Bo/HOmNFquVFq+jFcNPBeFcL878ufMf7Zu9C98zmWOCR4adaoDpo1rJN//YYtO/Hnus1qxovM4Ol13QNo0bgubhx4KZatWo8Jk2ZjxvtPqXoFlxrJEqX7n3kbI27qgws6tsHcX5bjgynfMHixNBJ+uojBi5+gbeiGwYsNqAFsksFLAPFt6poP6DbBBrhZjmuAB6CUu/ckePl1kQOLlxQ/2yPv9uTBUh68GzcEGjY0kVBEyFHUy5GlKqvX6GqpSlo6cOwYkJVV+EFblgVVq2Zi927Xn8vMBZlR0bQxUKOGtaU5pcxZqDlZMvTRZF3tIzPy9tMf3CRQ2bVXlr0AR45o2PXv67hxsKHs8so338l+NK4HMAkF2p0DnH22gZjyp7/GU4MXCRKk3V27gJ07NeTtmyJt9b3KwNltvAtfZHnVnn0aKlU08c0PuhoDGfOGDQ20aAY0beyaheRNOZqq4fAhDY0alnxvMrtk+w4d23eYkP11LugMdOro/4fkgq9TllUdOAQcPixL0GSJlOv3KW6WNd1zp1MtZZP3SU6OhkH9dBW6ZZw4ZbqPN5AhVseu4GX1WhPj3/f/eLRpoeHOYadvEpUXvNx+w1UIDw/DwqV/YcOWXWpPlRpVK2Lur8txz3/fxNJv3kZM+Wi130rb1o3VXiruigQnn874EZOm/aCWDkn5T98eGHFTXyTEx6ilRk+/OlnVT05Jw6zvFqJSUgI+nfAYwsNcIWPePjAyy0Zm21gtErxUr1JR7SmTV3bsPoAdu/er4GXxH2sx7P6X8dO0cWrpk5Qrb3xEBT7333FtoeBl6KgxqFwpUc3EkcI9XqyOgh+vY/DiR+xS7orBSymDBrg5Bi8BHgAbuucDug2oQdAkxzUIBqEUb8FK8CIzBWbMOjmjoVkzA1UquQ820lI1rN+onbYU5/r/GJYepCUokOUiq1af/kmvbGiqZpYkmKhSScM55xiQ5ScyWyAry/XnwVZefMmhlr7cPdKJCkmue506XcOp+7jIfcv997rEVEunTi1fztGxYmVhExmH9ucADRucvL5g8LLgVwd+XlD0kijpQ2aGSBHXojYMdmf6wUcOyIa5eUXGYciNhgqZWNwLSEgkM3o2bT45jvXqyka8wOyvTv5Zxw5At65ONQOGxbqAXcFLsM546XJuK7W8qG6tqujbqwsqVUhQWCcys9Hu0mEqgGjXpgkuuuZezPr/ZUCy9Ka4IkuIdu87qJb0yD4x1/W7SIUteaGKnA4UHxeDJg1qqf4K7iEjy3xaXjiPCoqGAAAgAElEQVQErz9zJy7q0tbyoJW01Gjmt7/i1femF9rvRTYJTs84jnFPjigUvHTpcyfuvqU/+vfuqvpn8GJ5GPx3IYMX/1mXdk8MXkpbNLDtMXgJrL8dvfMB3Q7VwLfJcQ38GJTmHVgJXsa84lD7oMhpMgP6GmpmSUlFHsr/2QBs2KirJTuy7GfEbUb+zBdZLiSzAORrhw+bOHBYw4nj8v+y14brgV722mhQ30TVqlChRVkss7+Wk3V0XNzdRJfOTkycrGPbdh3lok01K6dWTU39t2Z1s8QH7bR0Dav+dJ3UU3AjX1nqJLNgul3gRF7wsnI1MGOm69NoWZ5UpbLMCHLNCpIH+rk/a1i4qPCSmM6dnLikR8nO69br+N90XbUjmxBnZAA3DnbtacJiTSAzU8Nr4/X897rUatnCxNp1rve+2MpYtD2HptZEETLHSZ+61Midj4QTBw4lo2O7lvhizi/46uPni2SUoObU46MfG/MhpB/ZF+bUpUZFNSR7xUjY06OLtWVG0k5Jwcv831Zh5COv47evJqhjo6UMHvkcmjWqjUfvvr5Q8CLLjmTJkpy4JIXBi9W/OX68jsGLH7FLuSsGL6UMGuDmGLwEeABs6J4P6DagBkGTHNfSGQTZNyQpCMKEkoKX9et1TJ2uq9DltpudhY77tSrxyRTZdFVXoYu8ZglcJERwVyRgadrEQKfz4XYpjdU+g+U62WhWTueRoKV8rOsEJFlaMuwWQ/2Zt0VmT6xapWHN37JEpXAr5cu7NgyWctmlBs7r4P7hXfY9SU7VUC4KapmOtCMzMK7pb6JcuaLvbdzrDrVs5poBsqyIwYC3Y/jnah0zv3TNdJHNeK/p70ROZgRmzXHmb7Asp1n1ufLkhsTTZ+pqVpS7o7G9vY8zpZ5dM16CzcdK8JIXOlSplIgbBvRUR027K9nZOegxcDTuuXUAzmvbHLEx5bB63RYMf/AVjBjSF3fceFVAgxfZGPiSa+/HoD7dcct1vbH8z39w52Nv4K0XRqFrxzaFgpcps+apjXXldKZKFeLVEdmydw2Pkw6idzCDlyAaDA9vhcHLSbDwrz92q6cd2Qd963poKUeQc+1I5J7v/huvh/S2XM7gxRbWgDbKB/SA8tvWOcfVO1qZobBxk4bNm4Gt210Py107O9Gju6lO49m9x4RhAE6nBqf6L9QmrrK5qmHIn5lw5srvob7evauJunWsPbjLSTCpqa6TVU592C8pePn4U10d92tlY9eiZGR5zYR3daSlnQxbZFmN7A9SVTY5raihUiWz0Gao3ikHZ63nxjryj1MW/9tuNXzawLXgq5TNjv/+W8fqNa59YgrOhDmrjYF+V1kLRmQ5mQQxsr+KHIfsbhPfI0d0tV+JbD5cu6aJW4YGdi+V4Bxtz+5KlmzJhryyFE2W0uVtrrt2vYFvf9DU16KiTNw61MTCxYCENW1aG7i6j7Vx9exuyvbVDF5Ojp/TaaDb1XcjOSUd86aPQ9VKrv1RTi2yMe9Tr3yM7+cvy9/fRa65cUBPjBo2QO0h4+8ZL7JJ7gvjP81fXvTLktW47+m38+9PTmC6c2g/9VLufPR1tGpWH8MGX4HDyam49b6X1ElGUjq1b6n2iGHwEkR/rxm8BNFgeHgrDF5cYFryQUQ/ep0lvZzBo5HTqZela/19EYMXf4vb3x8f0O03DkQPHFfr6jKrY9FiDZu2yEOx+xN4ZElBcUcTF9fbwP5OVK0iD9vA0WQgNc2EbEorJ9bI6S9S5MF8796TgUfNGia6dDq5j0hxwYs8xL/6hkMtE3pgtDP/mF/rAievlBkV8hApe4DIccKnnuriTZtlpY5saJv17/IpCZzs3ItGlhrt2p+NI0dNZR12+t6cRbLJprD/+0JTx0EXV+T+Bw00UK2qteCvrIxTIO5TQqxtOzSc9+9R4aeeapS3t49sJC1hbF4ZfqtTBZUZx7SAzgyT7y8H9rs2bW7SyFQnfAWqhErwYoev7NFyNDUD2Tk5auNcd6cfedqv7MMi+8a4LRoQH+taOmSlSJAkpynJnjanLosqWF9ex/6DyUhMiEVUpJe7exdzQ5opPbB4LcDgxWu6gFdk8OIaAsfapYic8BiMWg3h7HgxEBENMyISZmQ0EFkO0AB99xaET39bXZ9154twNre+8ZW/BprBi7+k/dcPH9D9Z+3PnjiuRWtL6PH9XE3NUJGZDfLptOxlor5XO1yboDZrCjRtYmL7dg2zvtSQla2pZQOtWpqIjLD2I92RZK3Eo5SLe09I2DP6bkP1V1zw8sNPGhb/5kDH8wz0uoSfsPvz75m3fZV0nLSVdpct11VwFx5uIjwCiAiT/2qIijRRtTJUEMdij4C746Q/nOSALC2TEK1uHUMFYzVrmkhKMPHXWt2n06l8eRW/LHJg3s8nQ13ZP+jWoc6AhaoMXnwZzdKv++TLk7B7/yG3DYeHheHtF0eVfqc2t8jgxUdgBi8+AgawOoMXF37491MR/uVHyOl5LXL63FzkiIRPewvh82ch+5oRyO3WJ4Aj575rBi9BNyQ+3xAf0H0mDMoGyvK4ygyUY8eBhDhAPohLSQFSU10zRuT3KamyoSvUkcSnlpQUObZWQ6NGpjpJ59Qip/B8+72crlN47xJZ7tGiOdCk0eltyrKOvXtc+zt4Whb95sD8XzQkxBuIjwfi4mQpkYaYcibKlwfKx5iIKQeUKw/1wJxXZL8ReXCTjVi7dys6eNm1S8P7E12br94z0hkU+9F4ahSK15dG8BKKbsHymt0FL7LZ9Dvv6bjsUhP16xl4dbxrs+uCpWsXJ3pc6Pn3EW9e96YtOuZ8c3JZm+zblJ0tmyxrkJO2Bg0ITEjL4MWb0WQdTwQYvHii5eZaBi8+AgawOoMXF37Eh88ibPkvyB7yMHI7dC9yRMJnvIvweTOQc/VtyLmofwBHzn3XDF6Cbkh8vqGy/IDu84s/gxsIlnGVZSuRkUBsjKlmjRzLAGQvk/QME8ePa8jN0bBxi4l9+zXUqmEiJ0dTnxpbKVf1NgqdJiLLZD75TFftS5ElFg0aGGjcUD6BNvHt9zp+X+ZaniF7Y8geGVJaNYfalDaYiryWd953qE1yu19oYOcOB3IN1zIiNbshHGqmw8o/dbUE6srLDbRrG5gHqWByKyv3wuClrIyU+/t0F7zIlfI9Lm9G3Oq/dHz9jY4unU01k+7Hn1zfl85pY6CPxT193PV+8JBrKaCUzCwNpuE6XSmvyIbKsu/MP/+4vtfJJs4S9sjpY7Is8e33dMhpTVIaNTTQ+zI5/t3a97/dezTIMkhfCoMXX/RY14oAgxcrSsVcw+DFR8AAVmfw4sKPevoW6Pt2IPOx92DUqFfkiITP/hDhP3yuZsXI7JhgKwxegm1EfL+fYHlA9/2VsIWCAsEwrtt3avhoUuGjcD0dJVkukZQgs0RMdcqM7DkigY0ss5BSq6YJ/d+tLmSPFNnLQPYmSUuH2z1ZZBnAtQMMNHYzs8XTe7P7+in/09WGviUVOQ1HTsVhKTsCDF7Kzli5u9OigpdTr5UQOG/m3YZNOqZN19X3qAb1DbX/TkQJ21vI97pduzXs3G1i507Z3FtTe8jITLjzzwMmfaqrvaFkSVNYmAnTOBlcS0jbubOJTh0Ln3ImwfbMWa4NmqW0amFiwNXFb8Ase8PM/lJXge/NQ3zbrJnBS9l+75eFu2fw4uMoMXjxETCA1Rm8AFpuDqLvulyNwvE3v0f+U4KbcZGTj8K//RQ5V9yInMsGB3Dk3HfN4CXohsTnG/L3A7osBZFNRX391MznF36GN+DvcT2VMzcXePNtB5KPnpy9Ip/KykNI+fIaypWX3wPxcRqqVzcR7gCOn3D9atHMLPQJrruhKnjEa8GvdzzXQK+erhBizx4Nm7fp6oQiediQ/Vyuv86AHP1aFops6DnhHQdaNjfR44JwJKdlIzvbNStIlgzk5Lps5cGKpWwJMHgpW+N16t1aDV5Orbdnr2tWnixLqlbFxPWDDbeb7sqslUmf6JDj7IsqERGydMj912V2S/cLzWI39JU+5MhxKSOGO1VgXbDs2KVh1y5Z8mhi6zZXACzB9+MP5/o0eAxefOJjZQsCDF4sIBV3CYMXHwEDWJ3BC6Dv2oyo52+HWaM+Tjz2brGjEf7Npwif8zFyLh+MnN43BnDk3HfN4CXohsTnGyqNB3Q5xlY+wSuqSNiSkgZs2gQsXOxaPnHTDU6GL27AZEPW9f/o+cGEK6gAypVzHVssMzkksJCNXvOKLEuZNkNHo4Ymzu0AVKxgoDTG1d14ygP/jl06MmTJ0DENx08Yas+AY8cAXXMdhZyUCOzZB/y1Rlc/zMsP9XYV+UQ4KxvIyoI6xrlGEdPg5b7lIaWgm133VJrt5n1iXtJx0qXZJ9uyX4DBi/3GdvbgbfAi9yQzTSZ/qqkT1OT744B+BhKTTKxYqavv861bGpjzrZ4/q69SRQP168H1q66JDZs0zJjlCkJkJuAtNxnq6PrUFFcIE59gfelQ3vLLvFPUdu4y1ff33btPD3Tk323ZhPzuEU5UqOB9eM3gxc53JtsWAQYvPr4PGLz4CBjA6gxeAMfvPyLy45fg7NADWUMeKnY0wn6YiojZHyG35yBk9xkawJFj8BJ0+DbdkK8P6L/9ruP7H3W1WV//vgbWrNGxfJWW/2Ce8+9pMafefmSkiaE3huZRp7LOfv8+DTv3mJBPQPfv19QGqk0am/hwog7ZXLa4Istlul1gonZNE4eTga/mFF6OIhs79uoegSo1Mkv1XbP2b03tkyJBi9VyyxAnatfy/od0q/2c6dcxeDmzRpjBS9keT1+CF3nlsi+TLCXM28+q4OyV66418Nnnru/ptw9zuj0OfPlKHfPmaxh2s2F5fxZ34vK9fOw498tBZYZi3domatd2nfD20zwN69br6N/PUOGQt4XBi7dyrGdVgMGLVakirmPw4iNgAKszeAHyN8ztewtyLrmm2NEInzsd4TPfQ85FA5Bz9bAAjhyDl6DDt+mGvAle5IfGAwc0bNupYf6Ckw/hRU19liUessFflcoaelxoQI6/lb0r5Ae7m280UDnINjYtTWo5jWfvfg17/g1Zdu/VkPXvxoan9iMbMMr6fdnLJDbW9VXDADLSgYzjGooKseS6Lp2dakbM8hW62uBRSny8iQ5tgbZtDbXMxtsis3DmfKtBZjZJkSnyFSpCTWOPOuXI2lwncOigBtkAsnZtE1f38f4HdG/v90ysx+DlzBpVBi9lezx9DV7yXv3P8zUsWOgKPmRmy6HDJ0P0kk4ekn9HSuPI8LxZLxUqGKhVE6hdS36Z+Rv45t2rnNAmGwTL0saeF3v/7wmDl7L93i8Ld8/gxcdRYvDiI2AAqzN4ASLfeAiO9SuQNfI5OFt0KHY0wn6eiYjpbyO3e19kD7gjgCPH4CXo8G26IXfBi5wws/ZvYO1aXZ2CUFyR6ce9LzOwcDHyf2i8sJuJlk0NlIuRZTHuf0DLOy5XAoHB/zEKLTuSHz43btKwYZOJ7dt1tTwkNga4pr/h1XG5BU+BsImxULNr12lYtVrCFlmKc7qf/LAsJ/jUqqWhZnUTaWnA93NdRxzXqS37kBTeDPHUe5Zp4It/dy33kdKqpYkO7VwBh4QzK1fpWPqHjsNHTtaU45LP62CiejXPfmD+a62OGTNdDwMyS6lXTxPnnMUwxR/vo4J9MHjxt7i9/TF4sdfX7tZLK3iR+9y5y3Xymyw7kn1d8vZTufMOQ4Uxdhf5IMU0ZTlr8f82SPD+8ac66tY1MPQG7++LwYtvI7pyzSakZxxH145tfGuomNqZWdlw6DrCZYdmN+XnRStRMSkerZs3sO0efGmYwYsvegAYvPgIGMDqDF6A6AcGQEtPQeYLn8NIqFDsaIT9+jUipr6B3G5XIfuakQEcOfddc4+XoBsSn28oL3iRsGWdhC1/n76hnxyPefIIWyAq0vVDWlwccPZZrod5+eFt3gL5NMza+nLZfPXTqSd/yJRP0ZxODf9s1CB7wrgr57Y3cHkvz37gk80J33zHgRsHO1WoYXeR9ftvvOlQM1fyiswQqVXLRM0asgeJ65PNU0t6uoZFSzRcdKGhNjD0tci4zluchd+WaJBNEvNKk0YGataUgMdQRywXV9as0zD9C9ensXLsaJ8rZCaO/Ya+vvYzsT6DlzNrVBm8lO3xLM3gpaCE7On01ruyZ5qJfj4cOW2Hrvwb/8JLDjXL5tEHrO3b9fk0Hdt3aLi6r6n+DZESKsHL7n2H0HPQ/flDUbNaJQzq2wM3DbwU19/5POrXqYan7htSaKi+nbcUT7w8EYu/HI8I+VTrlLJr70Fc+p8H8OErD+C8ts2R18f3U8aiVvXKpTbsg0c+h9bN6uOBEYPwy5LVWLN+K0YO7Zvf/vzfVuGBZ97FN5+8iMoVE0qt39JqiMGLj5IMXnwEDGD1UA9eIt57CmGrFsGoUhOZT04scSTCF3+H8E/HIafzZci5blSJ1/v7AgYv/hPftUuOkHR9EpYox+nGmx5vaCcbj6akujY8LWqpSaQWjQ8+y8KmzSenOMfFmWjWRPYcARo28Czo8ERIZmfIJoGymeypRfYpadlcNooF0jJMzJjpgOxtcv8oZ4kn3hRs670PHeoIzsR4EyNHOFHEBzie3Hax134yRVeWTRobKoSSzV7t7tPdDRWcySSh2qLfNKxZW9j5tlucbk/4kWOgJbDJO8pYjiqWI4tZAifA4CVw9nb0zODFDlX/tWlX8CKvQILy+FjXxrnBVl593aE2Bx51l9PS3jLPvehQS18v6OzERd1dryfUgpfJbzyiZoes+GsDHh/7EV545FZkZedg7ITPsejL8YgsELCMeOQ1VK6YiCdGuz9cY/iDr6Bx/VoYfdtAZWlX8LJt5z5ER0eiaqUkfDbzJ3w/fxk+Gf9IobfjM69OxtHUDIx7Mvhm5zN48fE7B4MXHwEDWD2UgxeZuSIzWMyoaGQ9NAFGlVoljkTYkrmImDwWueddguwbTyblJVb00wUMXuyDlpNptm2XfTSAHTt05BRxYqPsiyLLbuJiTcTEQs1AiI3VEFvehK5rWL9BjtEFUlL1QnuCyBG6ElycWvI295MlQXIijnwq5e/jduUB/9vvNVSqZKJFC6BZ49OPE5bZMRs36bi4u6n2M5Eim/rK5rTuSt06BrJzNCz5/WTYIOGBhAh2FDntYdWfOr75Tlch110jjBKnbttxH3ltultCJrNqJMxbt06Wkmlq5o1MZ1c/7O/UsHqNBlkmlfnvHjQy8+bSSwy0b2uPmZ2v/0xrm8HLmTWiDF7K9njaGbwEs8zU6TrWr9dxTX8nWjQvPhiSwEWCFymyEfwtQ13/boda8FJwNooEK0kJcbj3toHodNVIjH/ubnTvdLZyOZqajs5X3YlJrz2E9mc1Pe1tsHbDNlxz21P47esJiI8tr75eXPDidBr46PNvMXX2PKRnnECPLufg4ZHXIT7OVXfh0r/w0lufY8uOvTinVWNkZ+fgxUeHoV7tahg7YSoa1quBtq2bYPDIZ5Gcko6WTeqpeh+/8TCiIiNw8HAKLux/D76e/ALq164WVG9bBi8+DgeDFx8BA1g9lIOX6Lt6Q8vJQtZdY+Bsdo6lUXD88TMiP3oBuef2QPZNxZ+AZKnBUr6IwYvvoMlHNTUDY+9eIDkFgOl66JVpvAWLBCpyLK8UWX8tM1fS0qyfJiP15IOUpCQTcpSu9FtUkf1Belx4etjh+6stvRZkv5R3P3So/V6G3GBi6TLkH7dZUi+yPEkCESnyw5/8EFia5fdlEhydDHgGXu1Eyxal24en91vcpsky02j8Ww6kpGrqGPBDh7VC7y1ZjtSmtalOsnAX1nl6L7zedwEGL74bBlMLDF6CaTQ8v5dQDV5+XeTATz9r6sMP+RCkuCKbrI9/5+SJSY8/nKuW0doVvBh7dyJ70VzPB9PHGo7qtRHe+eLTWjk1FMl1OtFv6OPodv5ZasbKXY+/gTBHWP6MkRlzfsHrH8zAgi9eh8Nx+izgWd8thOytImFNXikueJk+Z4GaVXP/HdeiWuUkvP7BF6hetQLeeOYubN25D1fc8DCuuao7+vTshN37DuP+Z97GjPefQrNGdSABUetmDXB9/0vw6nvTsHTlejw+6gbVrYQ0efc3dNQY1UbPbu19VCzd6gxefPRk8OIjYACrh2rwoh3Yjegnh8CMS8SJMdMsj0DY8l8Q8eGzyG3XFdk3P2a5nr8uZPDivbRssvrFLK3Qkp6CrdWqaUJ+yYkC1aqbammMuyJHDcumqseOaUhPB9Iz5L8m0jKAMF1DqxYm4uJNJCYWXl4ky01k3xH5wUd+SSgTFg7Urx5VZvbRko398k7WybPpc4WRH1AV9JKNeZctd6BDO9cJDHk/MMqJQSNvd5ZaoCAzld55/+Q+KK1bAm1aB36GSEmnVW3brmPi5JM/3MnSrlYtgZbNzFI5KcP7vyms6U6AwcuZ9b5g8FK2xzNUg5fNW3TIxvgS2N84uPh/5/KuzRvpG64z5HMmdO0Qacvg5yxfhGNj/f+BZXjbTij/4Jgig5fbb7hKbVIrM0w2bNmF2ROfRY2qFTH31+W4579vYuk3byOmfLTa96Vt68a459b+bn3GTJiKmHJRGDHk5F4rxQUvg+54Bk0b1s5ftvTTwhW4+/Hx+O2rCfhs1k+YOusnLJw9XvWVk5OLsy6+5bTg5bbrryhyqZHUk5kx5U+5J1sG18NGGbx4CHbq5QxefAQMYPVQDV4cqxYh8r2n4Gx6DrLuPv0bclFD4vhzESLffQrOszoj67YnAjhy7rtm8OL5kMheLZu2uI75zTimqWUojRubqFhBQ0KCgQpJ8PvSnoKvoqQHdM9fsX01ZAnMr4uB35c6IJvzljTdOTNLQ5jj5KyNCe84cOCg78dh5r1CWQ4mbcoGvpdcZKLz+dY2HLRP6GTLVsb1l4UOdVJRy+ammknEErwCDF6Cd2y8uTMGL96oBU+dUA1eZPPfMS871D5rD99f/L93K1bq+HLOyXBf/o3JyNDwweulsHu8m7dCsM546XJuK7W8qG6tqujbqwsqVXBtRnsiMxvtLh2GFx8ZhnZtmuCia+7FrI+eReP6Nd2+0WUWSucOrTCoT4/8rxcXvHTpc6eaWSN9Stl34IjqY+aHz+CTGT8iJzcXYx69TX3N2+DlgynfYPP2Peo1BFNh8OLjaDB48REwgNVDNXgJ/+YThM+ZjJwe/ZDT/3bLI+D4awki3/4vnK3OQ9Ydz1iu568LGby4pOWHjw8najh85PTpoMWNhZyq07+vgfgiZrP4axwL9mPlAT0Q91VcnxJgyQyeRh5u/FtwdspVVxhoe3bJM1MOHtSwbLmGP1frkH1c3JWaNUwMuzl4Qhe5x7I4rsH2Pgum+2HwEkyj4fu9MHjx3TCQLYRq8CLmL7/mUEtTR9/tVJv+F1Xmzdcg4X716ib2FtiLza7gJZDvB3d9W9n4Vk4wOnAoGR3btcQXc37BVx8/X+TLePHNKYiLLY87brwq/5ri+ug79DF06tAK9w2/Rl2/ZPk63HLfS5g/4zUsWPInpn01X81wkVJc8DJl1jx8O+93fPrmo6fd28vv/E9tDnzn0H5Bxc/gxcfhYPDiI2AAq4dq8BL5/tNwrFyI7MGjkdupl+URcKz7A5FvPgJni/bIGln0N2DLDZbyhf4MXtZvkGONgegoqE/lo6M16G62Kdm9V8Pf/wAHDmioUsVEnVoGunYBoqJMFZDs36+p2RG5uSZyc12/z3ECzn9/X6eOgboeHDMsJwV9OFmHrF+W4nAAYWEmwhyu3+f9v8OhwREmS3pMVK0K1K0NNGta8oN+KQ9Zic2F2gP63HkaFi52LQ0quFGvOyiZHSMzWgoWeV8VXK4VEQF17KfspRNMJdTGNZjs7bgXBi92qAauTQYvgbMvjZ5DOXiZ+j8d8vPZoIFGsT/TzPxSVx9YyIb2eXugtW5l4K5b7FlqVBrjWpptWAlelq36B0NGvYgqlRJxw4Ce6qjposrMb3/FomVrMO7JEfmX5PXx3kv3oXqVCvl/nhgfi0+/mIuZ3/2K154aiSqVkvDsa5Ox72Aypr/3JHbtPYRe1z2A6/pdpDby/e7nZfhhwTK3S41WrtmI2x4Yh+8+G6P2dkmIi4GmuX7+HXb/y7j68gvQs1uH0qTzuS0GLz4SMnjxETCA1c+U4EXfvRVa9gmYDtkYIwzI/28YTNkoQ/0Kgxnu+gcl6skh0A/sRqacZlSnseURcGz4E5Gv3Q9n07ORdfdYy/X8daG/ghc5vUZOsfG2yHHIZ7cxIJueZmWVvCGtbITa50qn2vdk6zYd838puk5qqmx0q6lPem6+Kbhmr3jjFYoP6At+deDnBa4xbnuOgat6uw/EPvtcx4aNujpSu+sFEuoFV7hS3HiH4rh68/4vK3UYvJSVkbJ2nwxerDkF61WhHLwsWOjAz/M1dO3iVJvyF1UmfaKrn6fy9oLZfwBo19ZEvWpRwTqspXpfVoIXOXmo29V3q1OD5k0fp45vLqqsWb8V197+NJbMeQtxMeXUZXl9nFpH9omRUOWRFz5Qe8lIqVOzCsY/exca1K2h/n/a1wvUrBeHrqNbp7Pw5kez8k8ouvPR19GqWX0MG3wFZFPgkY+8hoVL16h6y79/D9FRETh0JAXdrr4HX016Lr/NUgX0oTEGLz7gSVUGLz4CBrB6MAYvevJBhM2ZBMdfv8NZtymM9t1hJlZSSmZ0eSA+CUac65uflnUCYV+8h/CFcywrZj76DqKeG66uP/HGnPwwxkoD+uY1iHplNJyNWiNr9CtWqvj1GruCF1nCcfSohhPHNRw7buKL2a49PGSKaniBI5BlZkl4hGtjWPklv4+O0lCtqonICCDjuJx2o6tTgvKKnGCjFZHhGAawa7frWplV07ypiVWrSw58ZK3yrUMNJJCtaqcAACAASURBVCaUnQfxot4oofqA/tdaDTNmumazSLBy7UBDvaeW/qGr91yVyqY6RUnKA6OdZW4PlFAdV79+Q/RjZwxe/Ijth64YvPgB2cYuQjl42bRZxydTXB9IyIa5RZXX33TgSLKGu0YYqFjh5HV2nWpk43AHRdOmaeLW+19WxzoXtQGvuxtNTT+GzMxsNaumYJFAJUymaANYuWYTrr/zufxQpah2IsLDVegi5fk3PsX+Q8nqlKRgKwxefBwRBi8+AgawejAFL9qxdOTMnIK432ZYEnHGJEEzsqEfz7B0fd5F6UkNEZu8GTlJNXDg3o8tLUGQ9bJyQk3t7L8ROfYuOOs1R9YDr3vUrz8u9jV4kZNUjhyRY5RNHD2qIyVFAhdATvw5tZzXwVBTVL0pixY7sHoN1EyGmiUcHXzosI7vf0Sh04a6dXGiUcO8iUyaWkokD+NqGVF44TDIm/sLpjqh/IAuGx9/+rmujvKW8K5aNRMrVxUO3nx5HwZynEN5XAPpblffDF7skg1MuwxeAuNeWr2GcvAie6yNfcWBmPImHri36L3NnnouTJ2k+PgjuYU+QGPw4v27cMfuA7hs8IOY9NpDaomQL6V9r+E4u2VDtUfLz4tXqX1aht9wpaUm5YSm4Q+Ow0/TxqmjqoOtMHjxcUQYvPgIGMDqdgYvjq3roB3YC6NOQxjV6xX5KrWcbITNnw3926lwZLlClD+juuGPcpcjVwtDhJmNJOdexOceQEXnHiQ5DyAxdz/Km2nq2hRHBUxKfA67w5sUK1klZwfuP3xT/jVrIrtgSpWncfNNTlSsaOKrOTpSU08PGNJSgaP//nm32v+g99LbcaxyY7xf5x1cP8hQu8cHS7EavMjeGCkpGjIzZed2IDXNxD8bNBwpYjNaOeknNhaIjTURFwNUqQp0PNe70MVbK1lS8uM8DRd1N9GsiX/79vaeS6NeqD+gy9+9Tz49uVGy7N9SvpyplpNJKYuzXeS+Q31cS+PvRjC1weAlmEbD93th8OK7YSBbCOXgRdzHvOLAsWMa7h/lVD+3nVrkw7QXX3J/+hGDF9/eub+v+Bvpx47j4gva+dTQ4j/WYvfegwgLC1PHTrdoUtdye9/9vFSdziSnMQVjYfDi46gwePERMIDVPQ1eZOaH7M9RXJFPpHMW/4IL1z2df1luXEUY194Oo1YjaHu3Q9+7HeauLTB27kLU4a35162LOh/rmtyERt0bqKUpUpwGkJoOHEvXkJZuqiN/MzKAzLRsRKXsQXS1JFw2IBYJFpaVaC8/hOgtK1S7c2Ouxw+xQ1VwEhOL/M1Yi3tt1XO2YPThW7AnrCFerfQ+6tczcNP1wRMCFBW8yLG9W7dq2LgJ2LBJU/8guyu1a5lo1cJE3L8hi7gUtyt+AN+6IdM1H9ABOaZ6yjQNaakarrvGQKXKJub/6kB2loGeFwdP8OnJm5Lj6olW8F/L4CX4x8iTO2Tw4olW8F0b6sHLZ1N1bNik47pBBpo0Ov1nVDl18O33HGrJ7ojhhWfFMHgJvvfzmXZHDF58HFEGLz4CBrD64cM6tm8LQ44zN/8kkLwTQWQWSME9MuToudULkhFVvSLO7WCqb9hqH4/IvD09TPy6SIPx/WxclfamelXbwlugknMPYoyUYl/lP5Ht8GPMzajWqTEu72VfkOH4ezkixz+s7iV72OP4ZGM3tfu7FFnjeuXlQFS063XJaSiyR0lkhOvBbstWHT9/thN37x2C/eF18WbNj9QD4bntDVvvuTg4OcEnNQ1qxo5aaqNrqBgfiQNHM1U1eW1LlgLbtxdenhERYUL2VomK0tTpQjKDoGFDQI5TZgkuAT6gnxyPrEwNkVFnxnuU4xpcf898vRsGL74KBld9Bi/BNR6e3k2oBy/ywcT8BRoa1DdQ69/l3PLzXrloICYGyMkF5PQjCWUknClYGLx4+m7j9Z4KMHjxVOyU6xm8+AgYoOrr/tawZNp2NDq+BDmIQo4egWwt6t/fR+FIZC1c2L+yWmIy6ysN7bZPwsUZn2BveAMsLtcP+8PqIluLRpYWjWw9StW9KP0TdD82Rb2iNW3vxj81rsS+fRpiN/+G3mlvIww5OBBWGwfD6uBQWB1kVqiN6IZ1Ub1RrDoyuKTZNKVBFTHxBZiR5eC8fDCM+AqYOFmHPMpdN9As8aEubfM+VH3lBuRWqoWtwybivY9cG1/JZq5tWhtodzZQoYI9D4ayKe2efUBaGtSSqNQ019HLUtqdY+DK3kah4OXUk4dk5krTJiaaNIb6x5ilbAjwAb1sjJOnd8lx9VQsuK9n8BLc4+Pp3TF48VQsuK4P9eDlnw06pvyv6IMIkpJMJCdr6NDOQO/LGLwE17v3zL8bBi8+jjGDFx8Bfaz+zXc6Nm3WkJ6hQddNJCVCLbtJSjSRkKAhIQE4fhw4mmwiOUWW6wBGrobETb/gmpQXEYEst3eQjUj8L/FhpOlJGJD6Eirn7rJ8p9k3PYTcc3vkXy9THn/4UTY/1VC3jol6dYE6dVwzLQJdsrNds1usFO3IAUQ/NhhGhWrIfHYy5B+3ufMA2QA2r9SoYaLt2SZaNS85yHHX5+IlDvyzwfUVCaJaNAOWrwQ2byn+NJ8BVztxViuoGS9/bcjCO+871MZpzZoZ6NbFVJuTspQ9AT6gl70xs3LHHFcrSmXnGgYvZWesrNwpgxcrSsF7TagHL3IS5Y6dOnJzgJy8X7nyLGBiwa+uDwylXNzdRJfOXGoUvO/kM/POGLz4OK4MXnwELFBdNoz0ZE8NWUKSPH48mmYtQ6yRDAMOHHFUx1FHVRwJq4ajDvlVBeXNVCTl7kUF5z7EOQ8jzMxG3Zy/Vc+Ojj2QmVit0IvQ9u1A2KqFhf7MWb0Ocq8cCi3zOBxL50JOIUJ2JrTsLEB+ZWUCuo7sYU/A2bxt6aEEUUt6yhFEPXwtjMRKyHzeNbNHyp49Glb+qeGvNRqysk/unyL7pZx9lqmO9bNSFi5yYO7P7vdfkR3qu3Q2USEJSIw3kZDkWl606DcHfvxJU0vFBg0woSMMU6Y7If/wSugyaIC1vq3cH6/xvwAf0P1v7o8eOa7+UPZfHwxe/Gftj54YvPhD2b4+Qj14KU4272dGuaZ/XwOtW3HGi33vRLbsToDBi4/vCwYv7gFlP4Jly3Vs3Oz+67Ikpc8VJ7/hyUyHpd8fgplUCee2Azp3KvoYuLwWv3x5LQZtGeX1CDqvuwtxl/fHodTTZ72E/zwT4dPfhhkegdwrbkLOxQO87udMqahlpCL6/v4w4hKROWaa25e1Zp2GVas0bN56coaK7Cov/7i5W4okmwVv2w5s3aZhxUpXHdnnplJFYNduDes3yIwcEwOvNtXxgO5K3kZqBb/Wvq2BKy5n6FLW33t8QC/rI+j+/jmuZ9a4Mng5s8aTwUvZHk8GL8WPn8yUj4vV0LatATm1smDhHi9l+71fFu6ewYuPo8Tg5SSgbMAqG1odOQo4M47h/GNfoUnWMrfChxw1sfOi0bigi4kZszQ0W/MRemR8hqN6ZSwp3wc/xwzKr5d3hGq5ckC5cibkvzLB5PLfbkH13G3I6dEfRuvz8q/X0o9CO7wfOLQXevJBmOViYVaqBiRWhlGxGszESjCq1UZJpxo5Nq2GWbG6muHBAmjHMhB9X1+Y5eNw4uUviiWRE6BWrdaxchVwNOXkLBZZitSyOZCSYmLbdg0HDxWe4TJooIFmTT0LTOTUoj9Xa9iyFdi3T8dllxpo3syzNji+wSnAB/TgHBdf74rj6qtgcNVn8BJc4+Hr3TB48VUwsPUZvHjvz+DFezvWtCbA4MWaU5FXhUrw8t0POjIyNCQmGoiP15CYAMTHA7ExJvbsldkKGsJXzMf5x2aignMv4oyjJcr+Vu4q/BlzMfonjyl2D5UsLQrHtTgccyQgQ4/HcT0ekeZxtMj8DVnx1eB8cXKJfbm7oKTgxatGz+BKWtYJRN9zJcyoaJx49SvLr3THTtcsmDV/62q9bcEinzY0aiSb3ppoUA/qeGtvS1HHSXvbHusFXoAP6IEfAzvugONqh2rg2mTwEjh7O3pm8GKHqv/aZPDivTWDF+/tWNOaAIMXa05nbPBy4KCGPfs07NsLHD7iOmpNjlHu3s31ACx7ZUyboaPx8ncQZxzB0bBqSHFUxhFHDaTqFZHmSELV3O24OH0SGmevLOSU0/kyGO0uBLRT9u2QfVI+eBFhOcfzr3cmVobz6lvV/zsWfwct5TBwLB16WvEBTvbI55Hbor1Xo8jgxXO2crdfrJZfnXjjG48rS+iy9m9dLR+qVV1DgwYGqlfzPmg59QYYvHg8JEFfgQ/oQT9EXt0gx9UrtqCtxOAlaIfGqxtj8OIVW9BUYvDi/VAwePHejjWtCTB4seZ0RgQvsqxj/34JWoA9uzXs3a8hMXMXauesR63sf1DRuQvH9EQkO6ri2KU3omsX4ONPdHRd+wzOzpxfopSzfAKc/YfBaNAcRqUaxV7v+HsFIsc/pK7J6dIbuf2GqZkU7oqWeQI4lgZN/UqHdjwNyEhTgU7uBVeUeF9FXcDgxXM6CV6kHH97rueVba7B4MVm4AA0zwf0AKD7oUuOqx+Q/dgFgxc/YvuhKwYvfkC2sQsGL97jMnjx3o41rQmEXPCS63RC13To+umnp6RnHId8PTE+tpDeTwtXoE3zBqhUIeE01WBaapSTfgKZh9OQfTgVUeV07M2ujq1HyqulQGFb/8F5qdNhQEeaXgHVcreiTs56RJknZ50UfHFLoq/Awkaj0HPjk2iT+SucEeVgdO+jTu5BRgq0wwegH9kHTfZQqd0YzrYXIPe8njCjy1l75wEIX/QNjEo14WzSxnKd0ryQwYvnmgxePDdjDe8F+IDuvV0w1+S4BvPoeH5vDF48NwvmGgxegnl0Sr43Bi8lGxV1BYMX7+1Y05pASAUvJzKzcc1tT2LY4CvQ++KO+ULHT2TiwWffxc+LV6k/a928AcY/excqJsWr/2/fazhee3okOrVvGVTBy97pPyF2yUxE5aSgnDMV4Wb2afd3QiuHE3oskpwH3L4jzPIxcNZrDrNmQ1eoYppw/DgdujMb+8LqolrudhhRMci+ZwyMOo2tvavKyFUMXjwfqOg7L4eWm80ZL57TsYYXAnxA9wKtDFThuJaBQfLgFhm8eIBVBi5l8FIGBqmYW2Tw4v34MXjx3o41rQmETPDy8jv/w8TPv1MqYx69rVDw8sGUbzD96wX4ZPyjiI6KwO0PvYp6tavhmQeGBm3wsuej2Wj0xwRrowzADItAbsdLgNgEFbCY1evBWbshzApVT2sjfOEchE95Xf25ER2D7NEvw6jZwHJfZeVCBi+ej5Rsriub7J54Yw7M8EjPG7CxBpca2YgboKb5gB4geJu75bjaDOzn5hm8+Bnc5u4YvNgMbHPzDF68B2bw4r0da1oTCJngJSU1A5nZ2fjPHc9g9LCBhYKX/rc+gZ7d2uPW63ortR8WLMPoJ9/C2vkToWlaoRkvR46m4eHn38P57VvipoGXwpOlRkf+2ICoykk4tmE7wn/6HDXS/zptlOTUnqzwOGSHxSAnvDxyI2PhjIwBomMQfUEXJJ3TCHvenoJGf01UdTe2HoLYbhcgsnIioiqUP609eUjWDu2FmVARZoxrBo+VEvb2U3BsWYPcUS/DWaOulSpl7hoGL54PWfS9faEdz8CJcV96tKzM8548r8HgxXOzYK/BB/RgHyHv7o/j6p1bsNZi8BKsI+PdfTF48c4tWGoxePF+JBi8eG/HmtYEQiZ4yePoOeh+3Dm0X6HgRZYSPfvgzSp8kfL3xu0YMOxJ/Pb1BMTHls8PXlo2rYeb7n5BzYYZ+/hwhDkc+POzBUg8pxnKVXMfahxesQnHf/wB1XfMQ7SRbm1Uirkq3ZGEWGeyumJL9wdQ+9pLfG7TXQPaiWPqZCGjWh1b2g+GRsPCdMRGheFoxulLtILh/oLxHsLuvRpaeipyx82EGRMXVLco+zYlxEQgOS3Lf/d1+lZR/us7BHqqFB+FQ6mZIfBKg/slmqapPoQorcJxLS3J4GinQlwUjqZlwgiO2+Fd+CiQGBOJtOPZcBr/njpYeocP+nhnrG5FoHxUmPq7eCIz18rlvKaAQKWEKHpQwFaBkA9e5AfKlhcOwVsvjELXjq5NXrds34Mrb3oUP/3vFVSrUkEFL889dAsmT/8BSYmxeOWJEQgPc6hrUwZ2Vv/dWeUCRHa/Akkt6iJjXzLS/lyH8ivmoGLmVvX1bC0KR8o3QPnM/Qg3srGv2RWoe9NAxNRIyh/gnPRMHD+ajqzkY8hKSUdOShpy09LgzMiAsXMLau76Se3jcjSiOrThT6P6eWfWniu2vtPdNC6PEQ6Hhlwnf6qwan98RD/g6GGUe2s2kHDyvWu1vp3XyXiGOTTk+HM8+daxc0gREa4jO4ePc7YiW2g812kgzKFbuNLaJRxXa05l5SqZPZrjNAB+PywrQ1bsfYaHuX4uMvPGs/Qy1zPCJ9hfhMz+lcHz549CwW5i9f4iwkrv3zmrffK60BII+eBFhjsvWLmkazs1+u5mvMifyya83302BrVrVMl/l/w1/D7UTv69yHfN3pgWON7+clS+vAvCyvuWpGanHMfhHxej0mWdER7j/ujl0Hr7+vZqudTIc7/oxwZDO3IAmc99BiOpsucN2FiDS41sxA1Q01ySEiB4m7vluNoM7OfmudTIz+A2d8elRjYD29w8lxp5D8ylRt7bsaY1AQYvAGSPl0sv7IBb/nO5UnO3x8sVl5yPfQeOYMfu/Zgy4XEkxMeoa2WPl/RtB5Ey+yvU3PK9+oQgI6oq0mq0QVzvyxDXuIa1keBVfhdg8OI5edR/b4R+aC8yn5kMo2I1zxuwsQaDFxtxA9Q0H9ADBG9ztxxXm4H93DyDFz+D29wdgxebgW1unsGL98AMXry3Y01rAiETvOQ6nTANE71veBjDb7gSvS/qiPDwMKX0/mdzMGPOL+pUo3LRkRj+4Di3pxqd3bIRbr53rKrz4SsPqGs92VzX2pDwKn8JMHjxXDrqyaHQD+xC5hMfwqha2/MGbKzB4MVG3AA1zQf0AMHb3C3H1WZgPzfP4MXP4DZ3x+DFZmCbm2fw4j0wgxfv7VjTmkDIBC9ySpHMZClY5kx2bZR77Hgm7nv6bfz6+2r15ZZN6mH8c3ejcsUE9f+yFOmNZ+5Ex3YtIKcj/WfEM6hdozImPD8KB1L8uJGntTHlVRYFGLxYhCpwWdSzw6Dv2YYTj70Ls0Z9zxuwsQaDFxtxA9Q0H9ADBG9ztxxXm4H93DyDFz+D29wdgxebgW1unsGL98AMXry3Y01rAiETvFjhSE0/hpycXFRMsn7sMme8WJENzmsYvHg+LlEv3AF95yZkPjQBRp3g2tyZwYvn4xnsNfiAHuwj5N39cVy9cwvWWgxegnVkvLsvBi/euQVLLQYv3o8Egxfv7VjTmgCDF2tORV7F4MVHwABWZ/DiOX7UmDuhb/8HmQ+8AaNeM88bsLEGgxcbcQPUNB/QAwRvc7ccV5uB/dw8gxc/g9vcHYMXm4Ftbp7Bi/fADF68t2NNawIMXqw5MXjx0SkYqzN48XxUIl8ZBcfmtci891UYDVt63oCNNRi82IgboKb5gB4geJu75bjaDOzn5hm8+Bnc5u4YvNgMbHPzDF68B2bw4r0da1oTYPBizYnBi49OwVidwYvnoxI17j7om1Yj856XYDQ5y/MGbKzB4MVG3AA1zQf0AMHb3C3H1WZgPzfP4MXP4DZ3x+DFZmCbm2fw4j0wgxfv7VjTmgCDF2tODF58dArG6gxePB+VyDcegmP9CmTd9SKczdp63oCNNRi82IgboKb5gB4geJu75bjaDOzn5hm8+Bnc5u4YvNgMbHPzDF68B2bw4r0da1oTYPBizYnBi49OwVidwYvnoxI54VE41i5D1h3PwtnqXM8bsLEGgxcbcQPUNB/QAwRvc7ccV5uB/dw8gxc/g9vcHYMXm4Ftbp7Bi/fADF68t2NNawIMXqw5MXjx0SkYqzN48XxUIt/+Lxx/LUHW8KfgbHO+5w3YWIPBi424AWqaD+gBgre5W46rzcB+bp7Bi5/Bbe6OwYvNwDY3z+DFe2AGL97bsaY1AQYv1pwYvPjoFIzVGbx4PiqR7z8Nx8qFyLr1cTjPucDzBmysweDFRtwANc0H9ADB29wtx9VmYD83z+DFz+A2d8fgxWZgm5tn8OI9MIMX7+1Y05oAgxdrTgxefHQKxuoMXjwflYgPn0fY8vnIHvIwcjt097wBG2sweLERN0BN8wE9QPA2d8txtRnYz80zePEzuM3dMXixGdjm5hm8eA/M4MV7O9a0JsDgxZoTgxcfnYKxOoMXz0clYtJYhC2di6wb74fzvEs8b8DGGgxebMQNUNN8QA8QvM3dclxtBvZz8wxe/Axuc3cMXmwGtrl5Bi/eAzN48d6ONa0JMHix5sTgxUenYKzO4MXzUYn4dBzCFn+H7MGjkdupl+cN2FiDwYuNuAFqmg/oAYK3uVuOq83Afm6ewYufwW3ujsGLzcA2N8/gxXtgBi/e27GmNQEGL9acGLz46BSM1Rm8eD4q4VNeR/jCOcgedDdyL+jteQM21mDwYiNugJrmA3qA4G3uluNqM7Cfm2fw4mdwm7tj8GIzsM3NM3jxHpjBi/d2rGlNgMGLNScGLz46BWN1Bi+ej0rE/95E2IIvkT1wBHIv7ON5AzbWYPBiI26AmuYDeoDgbe6W42ozsJ+bZ/DiZ3Cbu2PwYjOwzc0zePEemMGL93asaU2AwYs1JwYvPjoFY3UGL56PSviMtxE+byZyrr4NORf197wBG2sweLERN0BN8wE9QPA2d8txtRnYz80zePEzuM3dMXixGdjm5hm8eA/M4MV7O9a0JsDgxZoTgxcfnYKxOoMXz0clfOb7CJ87DTl9bkZOz2s9b8DGGgxebMQNUNN8QA8QvM3dclxtBvZz8wxe/Axuc3cMXmwGtrl5Bi/eAzN48d6ONa0JMHix5sTgxUenYKzO4MXzUQn/aiLCv5vyf+2dB3hUxfqHf2c3ySYBEiBUBaRYECvWq+K1ix17771QFFFsKIiKHRS59t57vXbsvaDYBem9hA7JJrt7/v9vwuaGkHJ2TmbPbPI7z8NDIOf7Zs77bZt3Z+ag/NDTUH7QyaknMBhB8WIQbkCpOUAPCLzhZllXw4DTnJ7iJc3ADTdH8WIYsOH0FC/6gCle9Nkx0hsBihdvnChefHKyMZziJfWqZL/1BLL/+yTKDz4F5YecmnoCgxEULwbhBpSaA/SAwBtulnU1DDjN6Sle0gzccHMUL4YBG05P8aIPmOJFnx0jvRGgePHGieLFJycbwyleUq9K1jvPIOeNRxE74ASU9Tsz9QQGIyheDMINKDUH6AGBN9ws62oYcJrTU7ykGbjh5iheDAM2nJ7iRR8wxYs+O0Z6I0Dx4o0TxYtPTjaGU7ykXhXZ30X2eSnf71iUH3lO6gkMRlC8GIQbUGoO0AMCb7hZ1tUw4DSnp3hJM3DDzVG8GAZsOD3Fiz5gihd9doz0RoDixRsnihefnGwMp3hJvSpZ419Bzkv3Irb3kSg75oLUExiMoHgxCDeg1BygBwTecLOsq2HAaU5P8ZJm4Iabo3gxDNhweooXfcAUL/rsGOmNAMWLN04ULz452RhO8ZJ6VbI+eR05z9+D2B6Hoez4AaknMBhB8WIQbkCpOUAPCLzhZllXw4DTnJ7iJc3ADTdH8WIYsOH0FC/6gCle9Nkx0hsBihdvnChefHKyMZziJfWqZH3+FnKeuQuxPgeh7KRLUk9gMILixSDcgFJzgB4QeMPNsq6GAac5PcVLmoEbbo7ixTBgw+kpXvQBU7zos2OkNwIUL944Ubz45GRjOMVL6lXJ+vId5Dx1J2K79EXZqUNST2AwguLFINyAUnOAHhB4w82yroYBpzk9xUuagRtujuLFMGDD6Sle9AFTvOizY6Q3AhQv3jhRvPjkZGM4xUvqVQl/+wEij92K+E77IHrGFaknMBhB8WIQbkCpOUAPCLzhZllXw4DTnJ7iJc3ADTdH8WIYsOH0FC/6gCle9Nkx0hsBihdvnChefHKyMZziJfWqZH3/MXIeuQmxHfZA2VnXpJ7AYATFi0G4AaXmAD0g8IabZV0NA05zeoqXNAM33BzFi2HAhtNTvOgDpnjRZ8dIbwQoXrxxonjxycnGcIqX1KsSnvA5Ig9ej/i2fRA977rUExiMoHgxCDeg1BygBwTecLOsq2HAaU5P8ZJm4Iabo3gxDNhweooXfcAUL/rsGOmNAMWLN04ULz452RhO8ZJ6VcK/fI3IvdcivtW/EL1wZOoJDEZQvBiEG1BqDtADAm+4WdbVMOA0p6d4STNww81RvBgGbDg9xYs+YIoXfXaM9EaA4sUbJ4oXn5xsDKd4Sb0q4d++Q2Tc1YhvsROi/W9MPYHBCIoXg3ADSs0BekDgDTfLuhoGnOb0FC9pBm64OYoXw4ANp6d40QdM8aLPjpHeCFC8eONE8eKTk43hFC+pVyX854+I3H0F4j23Q3TQLaknMBhB8WIQbkCpOUAPCLzhZllXw4DTnJ7iJc3ADTdH8WIYsOH0FC/6gCle9Nkx0hsBihdvnChefHKyMZziJfWqhCZNRO7oIUhsujVKL7kj9QQGIyheDMINKDUH6AGBN9ws62oYcJrTU7ykGbjh5iheDAM2nJ7iRR8wxYs+O0Z6I0Dx4o0TxYtPTjaGU7ykXpXwlN8Ruf1ixLv3QvSyu1JPYDCC4sUg3IBSc4AeEHjDzbKuhgGnOT3FS5qBG26O4sUwYMPpKV70AVO86LNjpDcCFC/eOFG8+ORkYzjFS+pVCU3/C7m3DEBio01ResW41BMYjKB4MQg3oNQcoAcE3nCzrKthwGlOT/GSZuCGm6N4MQzYcHqKF33AFC/67BjpjQDFuXEJxAAAIABJREFUizdOFC8+OdkYTvGSelVCMycjd9SFSHTugdKr7ks9gcEIiheDcANKzQF6QOANN8u6Ggac5vQUL2kGbrg5ihfDgA2np3jRB0zxos+Okd4IULx440Tx4pOTjeEUL6lXJTRnGnJvOBeJjl1Reu2DqScwGEHxYhBuQKk5QA8IvOFmWVfDgNOcnuIlzcANN0fxYhiw4fQUL/qAKV702THSGwGKF2+cKF58crIxnOIl9aqEFsxC7vAzkWjXCaUjHk09gcEIiheDcANKzQF6QOANN8u6Ggac5vQUL2kGbrg5ihfDgA2np3jRB0zxos+Okd4IULx440Tx4pOTjeEUL6lXxVk0D3nXngq3TQeUjHwy9QQGIyheDMINKDUH6AGBN9ws62oYcJrTU7ykGbjh5iheDAM2nJ7iRR8wxYs+O0Z6I0Dx4o0TxYtPTjaGU7ykXpXQkoXIvfokJFq2QemoZ1NPYDCC4sUg3IBSc4AeEHjDzbKuhgGnOT3FS5qBG26O4sUwYMPpKV70AVO86LNjpDcCFC/eOFG8+ORkYzjFS+pVcZYXI++K4+EWtELJLS+knsBgBMWLQbgBpeYAPSDwhptlXQ0DTnN6ipc0AzfcHMWLYcCG01O86AOmeNFnx0hvBChevHGiePHJycZwipfUq+KsWo68y46G26wFSm5/JfUEBiMoXgzCDSg1B+gBgTfcLOtqGHCa01O8pBm44eYoXgwDNpye4kUfMMWLPjtGeiNA8eKNE8WLT042hlO8pF4Vp2Q18gYfDjc3HyWjX089gcEIiheDcANKzQF6QOANN8u6Ggac5vQUL2kGbrg5ihfDgA2np3jRB0zxos+Okd4IULx440Tx4pOTjeEUL6lXxYmWIu/iQ+Hm5KDkrv+mnsBgBMWLQbgBpeYAPSDwhptlXQ0DTnN6ipc0AzfcHMWLYcCG01O86AOmeNFnx0hvBChevHGiePHJycZwiheNqsRiyB9wIBAKY824dzUSmAuheDHHNqjMHKAHRd5su6yrWb7pzk7xkm7iZtujeDHL13R2ihd9whQv+uwY6Y0AxYs3ThQvPjnZGE7xoleV/Av2U4Fr7v1AL4GhKIoXQ2ADTMsBeoDwDTbNuhqEG0BqipcAoBtskuLFINw0pKZ40YdM8aLPjpHeCFC8eONE8eKTk43hFC96Vcm/6AAgEcease8AWVl6SQxEUbwYgBpwSg7QAy6AoeZZV0NgA0pL8RIQeEPNUrwYApumtBQv+qApXvTZMdIbAYoXb5woXnxysjGc4kWvKnmDDoZTVoaSMW/CjeTqJTEQRfFiAGrAKTlAD7gAhppnXQ2BDSgtxUtA4A01S/FiCGya0lK86IOmeNFnx0hvBChevHGiePHJycZwihe9quRd0g9O6RqsufNVIK+5XhIDURQvBqAGnJID9IALYKh51tUQ2IDSUrwEBN5QsxQvhsCmKS3Fiz5oihd9doz0RoDixRsnihefnGwMp3jRq0rekKPgrF6BkltfhNuipV4SA1EULwagBpySA/SAC2CoedbVENiA0lK8BATeULMUL4bApiktxYs+aIoXfXaM9EaA4sUbJ4oXn5xsDKd40atK3hXHwVm+BCWjnoXbso1eEgNRFC8GoAackgP0gAtgqHnW1RDYgNJSvAQE3lCzFC+GwKYpLcWLPmiKF312jPRGgOLFGyeKF5+cbAyneNGrSu5VJyK0dBFKbnwabut2ekkMRFG8GIAacEoO0AMugKHmWVdDYANKS/ESEHhDzVK8GAKbprQUL/qgKV702THSGwGKF2+cKF58crIxnOJFryp5w06Bs3g+SkY8DrfdBnpJDERRvBiAGnBKDtADLoCh5llXQ2ADSkvxEhB4Q81SvBgCm6a0FC/6oCle9Nkx0hsBihdvnChefHKyMZziRa8qudedgdDC2Si97mEkOnTRS2IgiuLFANSAU3KAHnABDDXPuhoCG1BaipeAwBtqluLFENg0paV40QdN8aLPjpHeCFC8eONE8eKTk43hFC96Vcm9/hyE5k1H6TUPILFhN70kBqIoXgxADTglB+gBF8BQ86yrIbABpaV4CQi8oWYpXgyBTVNaihd90BQv+uwY6Y0AxYs3ThQvPjnZGE7xoleV3JvOR2jWFJRe+R8kumyil8RAFMWLAagBp+QAPeACGGqedTUENqC0FC8BgTfULMWLIbBpSkvxog+a4kWfHSO9EaB48caJ4sUnJxvDKV70qpJ780UIzZiE0qFjkejaUy+JgSiKFwNQA07JAXrABTDUPOtqCGxAaSleAgJvqFmKF0Ng05SW4kUfNMWLPjtGeiNA8eKNE8WLT042hlO86FUlctsghKf+geiloxHfeEu9JAaiKF4MQA04JQfoARfAUPOsqyGwAaWleAkIvKFmKV4MgU1TWooXfdAUL/rsGOmNAMWLN04ULz452RhO8aJXlcidQxCePBHRwbcjvsk2ekkMRNkoXkKL5yE0ewpQshrOmlVAIoF47z5ItOmI8C9fq5lDdR1uj16I9drRAK3MSMkBembUKdVesq6pErP7fIoXu+uTau8oXlIlZtf5FC/69aB40WfHSG8EKF68caJ48cnJxnCKF72qRO4eivCfExAddCviPXvrJTEQlS7xkv35Wwi/9wJCxfMMXMX6KRMFrRE7/GzEdtkvLe3Z1AgH6DZVo+H6wro2HEsbMlG82FCFhusDxUvDsQwiE8WLPnWKF312jPRGgOLFGyeKF5+cbAyneNGrSs49VyHr9+9R1v8mxLawZzaGrnhxZDbKquVwVi4HVi1TP4dWLoe7Un5eBqxcDqc8WgFr9XKE586oFZyb3xxuTi4QyQVycuFG8gDH+d/5rovwP7+qfyc6dVf8nHB2zfnKowhN+Q3hqX8ivuXOiF50g17BMjiKA/QMLl4dXWddG1ddKV4aVz0pXjK7nhQv+vWjeNFnx0hvBChevHGiePHJycZwihe9qkTuvVYtkynvdyZiex1eIRcsOGoSL87KZQgVL4BTPB+hxfPhFs+v+Hn5EkAEy/LilHueKGiF2DEXILbDXinHSoBTVgpn6SIk2neuNz40dxpyR56rJE3p1ffXe35jO4ED9MZW0YrrYV0bV10pXhpXPSleMrueFC/69aN40WfHSG8EKF68caJ48cnJxnCKF72qZL//ArJffbAyON5tcyS6bg63y8ZIbLQZEh276CWuJcopL0P46/fgLJ4HpywKREuB8mjFz2WliO/ZD7Ft+6CqeAnNmYrsZ8ao2SL1HW5WDtzmBUDzQrgtCuHK381bAgUtK/6vWSES8nMz+f8C9ft0Hc7qVcgbcgTcZgUouf3ldDVrTTscoFtTigbtCOvaoDgDT0bxEngJGrQDFC8NijPtyShe9JFTvOizY6Q3AhQv3jhRvPjkZGM4xYt+VUIzJyH72bsRnv73eklkqY0ImHi3zYCumyPeZWO4RR3qbSxrwqfIeucZhGZPVee62RG4bdqrJUCy/KeuI7bzPnD7HIiCRClW/PEbst977n9iaKNN4W6wEdyO3ZDYsBuQla2WASVarJUtkfx6+xbkCXkDD1FLndbc+0GQ3QikbQ7QA8FuvFHW1TjitDZA8ZJW3MYbo3gxjthoAxQv+ngpXvTZMdIbAYoXb5woXnxysjGc4sV/VdRde2b+A8z4C+EZkxCa8Tec0pL1ZUx+84rZMN16wu28MZxVKwCZwSJ/VixVM1hqkjjJRPHuWyCx2bbr7pciv4zHkPXJ63Ci67dZ3ucgxA86GYlWbf1faIAZcq87A6GFs1E68gl1N6SmdHCA3jirzbo2rrpSvDSuelK8ZHY9KV7060fxos+Okd4IULx440Tx4pOTjeEUL2aqElo0B6FZ/8CZ/re6XbL8qUmMVG/dzc2r2Ddmz8PVr5zVK9VeKBBp07pdrZ11iuch+8OXEZr2J8KL56Fsp/0Q3/eoOmPMXLmZrJHRQxCeJLfvvgPxTbY204ilWTlAt7QwPrvFuvoEaFk4xYtlBfHZHYoXnwADDqd40S8AxYs+O0Z6I0Dx4o0TxYtPTjaGU7ykryoyYyM0awqcaX/CmTcDaNESblF7tQTJbdMRbut2vmdz6N7VKH0U9FrKeexmZH07HtEzr0R8x731kmRoFAfoGVq4errNujauulK8NK56Urxkdj0pXvTrR/Giz46R3ghQvHjjRPHik5ON4RQvNlZFv0+NVbxkv/oQst9/HuVHnI3y/Y/TB5SBkRygZ2DRPHSZdfUAKYNOoXjJoGJ56CrFiwdIFp9C8aJfHIoXfXaM9EaA4sUDpw8//xHb9OqBtkUt1zt7bvH6e0t4SMlTLCBA8WJBERqwC41VvMgeNjnP34PYnv1Qdlz/BiRmfyoO0O2vkU4PWVcdavbGULzYWxudnlG86FCzJ4biRb8WFC/67BjpjQDFC4Dxn0/AwGF3r0dswvsPIpKTjR0PPB9jru+P3XbckuLF2+MqI86ieMmIMnnuZGMVL+Gfv0Tk/uGIb7sboucN98yjMZzIAXpjqOL618C6Nq66Urw0rnpSvGR2PSle9OtH8aLPjpHeCFC8AJAZLVfe9CBeenDEOtS6bNgOjuNQvHh7LGXcWRQvGVeyOjvcWMWL3Lo7d9RFiHftiejQsY2raPVcTToH6M7KZXBWLIGb20ztP8TDHIF01tXcVTBzkgDFS+N6LFC8ZHY9KV7060fxos+Okd4IULysFS8j7ngMn79W86Cm6oyX4qUrcOVND2DXHbfE6cceAC418vZAs/Esihcbq6Lfp8YqXuR223lDj0WiZRuUjnpWH1AGRvoZoDurVyE88QuEfv0G7sZbIr759nAWz0do+t9wli0Eli9FaMUSYIX8vXQdOuV9j0d8175ItOuUgdTs77Kfutp/dU2vhxQvjavmFC+ZXU+KF/36Ubzos2OkNwIUL2vFy6BhY9Gv726IRHKwwzaboe+eOyIrHFYUk+Jly57dcPqgUejWpSNuHXa++j3Fi7cHmo1nUbzYWBX9PjVW8SJE8i/YT4FZc+8H+oAyMLKDuwKLps2Bs2wxnOWLgaWL4Cyah9CSBXAWzYVTstroVcU36IrE9nsgvvUuQFYOQvNnwJkzreJ26fNnIrRgthJicmeu8lMGa4marB8+RnybXeFmR4xei03JKV5sqob/vlC8+GdoUwaKF5uqkXpfKF5SZ5aMoHjRZ8dIbwQoXgD8+tc0vPfJdyhs0QxzFxTjhTc+xolH7IOrB51SKV5uvOJsPPHie2jdqgXuuO4iZGdVSJloedwbaZ5lHQFZRpYVclAeT1jXN3YodQIOAJFpZbHGV8/SgcfCLV6AvHteBlq1SR1OQ0SsWgFES+BGoxV/l5aqv5P/50ZL4ERL4ZaXwcmJwM3JhRPJhZObB+TmAk4I7tJiNcMkvmwJsHIZ3OVLgUgenPYbAKVrgCWLkVheDHfxQnWe38PZpBfCvbZHYt4sJH7/EaFtdkZ4g43gFLQEWhUhVFgEp1VroHW7yqbcRfNQ9tQ4JH74PLXmWxQi98o74Wy0sYpLfPsxEvNnw8nOgZudA0fESna2+jdyIkCsDGUvPAx3znSgqD0iZw9BaOudUmszTWfH4i6ywvIMa5gjkh3me2fDoLQiS05WGGUxfhayohgN0Al5H43FEnAbIBdTpJ+AfAklRzzBCqZKX96beJCASQIULzXQfeXtzzDs1kcwcfzDalaLzHiRY01JKd55+hZ02fB/6/8XL4+arA9zGyQgA4nmeVlYtqrcYCtMnS4CoZCDwmbZWLqyLF1Npq2d0M0DEZryO+JXjYPbrWeDt+v8+g2cX7+HM+sfoLQEKCsBRKyUlcIRIRLQ4RS2QqJlW6CgNVwRTkXt4BZ1gNO2I9w2HeAWtDbWM5lN4/zxI5wJXwC/fgM0LwA6doXbqRvcDboCLYsq2w698QScSRPhRvIBES9LFsFZPC/lviV23Avu8f3hihiy6JCP7w2nXYA2hRHwvdOiAvvsSuuCCJatjILjPJ8gLQlv1TwHK0rKEY9z4G5JSVLqRrPcLCRcFyVRytCUwKHivYkHCZgkQPFSA93Pv/0V5w+9Az++9wByIzlKvBy6/66Yt6AYM2bPxzPjhqFlYXMVyaVGJh+eZnNzqZFZvunO3piXGuU8dAOyfvwUZedeh1jvPnWizfrqXWS9/QxCxakP/OtKnMjLB3LygJxcIBIBIvlwQyHvZc7KgtuiJdwWrdQsl+qH/A6FRXBbFsEtLEKidTtkypIUp7wM2fcNR9Yf31dellxPokOXOvnEt9sdsT0PR/b4l5H12iNwYmVq6VJ87yMR790HiTYdvfPNoDMzpa4ZhDTQrnKpUaD4G7xxLjVqcKRpTcilRvq4udRInx0jvRGgeAHwzKvjsVmPzui1aVcsX7kKl11/n1pK9MjooYpico+X3ltugrMuvVX938N3XI78vAjFi7fHmZVnUbxYWRbtTjVm8ZL90n1qcO42L4SzanlKjFyRHLI0MpQFNytb/S3/dsNZcLKy1d+y9CXRtScSm24Dt1lBhRiR5UKRPLjNWqTUXkOenGkD9NDC2QjNmqJmCsV26ZsSCmfJQuQ8dQfCf06ojIt33xyJHfZEbPu9gNw8hCZ+BScURnyz3nBlBk6GHplW1wzFnLZuN2bx4pRHZc0GEI+pP048BjcRV38jHq/4k4jBicXhyt/hLCSKZDZeq7Txb+iGKF4ammh681G86POmeNFnx0hvBCheANx5/wt4+Nm3K4lt3asHbht2Pjp1bFspXu4eOQC77LAFli1fhRMvGgm51fS4my7BgmVcauTtoWbfWRQv9tXET48atXgZ/zJEvng5EoVFiPc9FrE+B2f8hq1NcYAenvYnwt+NV3+cNatqLXms9+4oO/daLw8J685pinW1rggN2CEd8RKaPRXOmpXr98IB3PwWQPNCyGuZziGyJDTlD4Sm/gFn4Ww4sm+UCGcRyrkRNXPPlX2Wqm5o7boI/fE9nDWrVb+c1St0mq6MkX2dZDmkSBi06Yj4tn2UpAnN+AvOP7/DCYfh5jcDcpvDzWsGlJdVLO2UZZ7RKBzZR0vO6d4Lic23R7xrwy8xre0CKV58lT7wYIoX/RJQvOizY6Q3AhQvazmVRsuwqHgZWjTLr1xG5AUhlxp5oWTnORQvdtZFt1eNWbxkTfgc4U9fR2Lb3RDv/W8kquwvossrE+Ka+gA9/Os3CH/9PrJ+qtjoN9FlEzVYlL14nLJSlIx5vWJfmQw7mnpddcrlFM9HaPECOMXzID+rPYRWr6wYmHfeGM6qlXBWLYO7ejlCchewFcuAWE37lzkV+yN16o54l03gdt5YzWzzc3gRL6FFcxD+6Us4k35G+J/flFjwcrj5zSuWKLZuh9ge/dQdwORQezAtmoOQYrEAWFjxs1yz+r8lC72kz5hzYoefjbK+x6WlvxQvacFsrBGKF320FC/67BjpjQDFizdOtZ5F8eITYIDhFC8BwjfQdGMWLwZwZURKDtAryqQGmSWr1b43ckRuuxjhqb+jbMBNiPXaMSNqWbWTmVJXmTnhLJ4PZ+WymhnHytWdvNRMBfW3bExdpm4vnujcA4mOG60TF/77Z4RmTlYSQTaJTogAaV5YeU5o5iSE//oZocm/qLuFOYkEnGWL4BQvMFrj2I57I3bwKUi07wQnugaQOxTJshoRN4k4EIup5TTytxOTpTYxuBt0g0gROeoTL+GJXyHnkVFKFiYPYaBmg1Q75JqxapmSSM7q9Wd8ySwYyVPfreQTbTdEfNOt1b5RtR6y71RecyCvOdxmInhaqbo0xDI+Z9UKhBaLJJunhJmrZNACuK3aAaksQyqPIvuDF9UllPc5GOUnXWz0sSDJKV6MIzbaAMWLPl6KF312jPRGgOLFG6daz6J48QkwwHCKlwDhG2ia4sUA1IBTZsoAPd2Ysl9/BNnvPouy/Y9F7Ihz0t287/ZsqGv2R68g/NbjCJWYu2uXLDdJbNgdkNuJy+yMZcXrsZPbrrut28KRWSpyR7FaDhEOInRcubNX6/ZAaO1tT1ctQ2jRPLgtCpU4cFq0QkL93LLGTaxFnoTmTIUzYxJCc6YgNH+WVj1l4+eyi25EokPnWsWLXG/Wqw8g67uPKsTBvkcj0WtHJLpsqkSHl0MxW7kU4e8/QtZnb1XOlHFz8+C27rB2OU9HoE17tRm1sFHyRDYDbyRH+O+JiIwZoq6m9ObntJdgecVB8eKVlJ3nUbzo14XiRZ8dI70RoHjxxonixScnG8MpXmysin6fKF702dkaacMA3UY2cveknLFXId6tF6KX3+Wri7KPjLNyqdq0WWZ2qNkdq1fAWbYEkP9bs7Jij4luPRH+40eE/vkNQA23mZXZGTKjISZ7VZQDMltEfi4vg9z1SWbruO07I7FBVxT26IGlBR2RkNtzr501oXsRzuqVCE+aCMz4C6GF8xBasQSQWRvRqJqJIrNQknJFLVmR9qKlajmOlyNR1LHiVuZOajfUdhbNXa8NuWOV23YD1azMkFHLhlb/b5+ThCz/6b07Et23ANbeMUxumS5yw9QRWl6MrJfuR9YPH6fchCt7pLQo9LSsp+zsaxDbfo+U26gaILNxnAVzKsRKgJt++7oIzeDInZciPPkXlJ19NWLb76mZxVsYxYs3TraeRfGiXxmKF312jPRGgOLFGyeKF5+cbAyneLGxKvp9onjRZ2drJMVLzZWRAWjexf3UL0vuehMya8LLIcszst58AuHJPwMrl0MG3UEfIkPiW+4It1V7NTPEbdUWiY02q1E2hJYsRGjeDDizJqsZGyIt1OyNOjYhru36RMDEDjkF5XsdaQyBWm4ybzrguura4t02X68tJROKF1TcQayGpTfGOucjsTyOsp8fi6xvx9eZRa4p1ucgdXv05DI5H8026dDsNx9H9ttPIbbHYSg7foBRFhQvRvEaT07xoo+Y4kWfHSO9EaB48caJ4sUnJxvDKV5srIp+nyhe9NnZGknxUntlckddBNkTJDrwFsQ3367WE9W+Id9/rJaUyN4h1Tc1dbNygIKWFRs25xdUbGRa2Pp/S1lkdsbcaQhP/hWxXfsiseXO2g8XESXOvOnIL56F6IzpSprUdsh+Fm73zeHMmYbQrH/Utda2FCfRqQfim20Ld4OuFXtohNcuw6mjpwnZoySDb8mtXYQGDAzNnaY2e263WQ8sXFqCRA0ToRqwuSadSmZ1RUYPgTxuS4c9YJQFxYtRvMaTU7zoI6Z40WfHSG8EKF68caJ48cnJxnCKFxurot8nihd9drZGUrzUXpnsl+5H9viXlHRJbLptxe1oqx3O0gXI+vqDdf43tm0fxPc9CrKERW0mmuvvjjY6j52qdQ0tnI3QwrnA4rlqI1vZkDQ0aWKNm6cm8vLhdtoEsiQHG2ykBqHys9cZPzp9ZUz9BOrbXLf+DDyjPgKyXC9v4MHqtJI7XvW9RK+u9jJFvMhrh3oNk9tx86gkQPGi/2CgeNFnx0hvBChevHGiePHJycZwihcbq6LfJ4oXfXa2RlK81F4ZuVNM5L7r6i2dDEpi/z4UbgfZX6VbxS2pAz7qq6ss0cl+63GgdA3cDbtDZrS4HTdqMrdRD7g8KTdP8ZIyMq2A5N3MoheORHyrf9WbQ+4K5ZSsBGQpXiiknkdejqDFi1oCKXtPrVkJxOOVXXaWLkLo128qZu+tnS2Xzttse2FnwzkUL/pVoHjRZ8dIbwQoXrxxonjxycnGcIoXG6ui3yeKF312tkbWN0C3td/p6Jcs28kddgoSnTeuGFDl1nAXl+wIYn0OXOeWxenoW31tsK71Ecqs31O8pKdeybuZxXbeB27njYHiRXBKV1bcdrtkTYWoKKkQFjUty5NbbLvtO1UsJ2zVFpD9lGTT65ZFcAvbVt5pqrp4kdugO8uXqFt8y95Qcpep0KrlcJ0QEjvsqb1pcnj6Xwh9Ox6hJQvgyN2rFs1O+S5jsvl16Q1PpKcAGdIKxYt+oShe9Nkx0hsBihdvnChefHKyMZzixcaq6PeJ4kWfna2RHKDbWhl//WJd/fGzLZriJT0VCf85AZG7h3puTJbmOfkt4OY1h5uTg/DUP+uMlbtUiZDJbtsO5S2KkHATCP/81Xr7QtWWRDasViK488ZwO2+ihE5tR+i78cj+8p0af+02K4Ar/ZZbjuc1q/g5vwWQ31yJo0TniuWGudecilDxvHr3ufIMrJGcSPGiX0iKF312jPRGgOLFGyeKF5+cbAyneLGxKvp9onjRZ2drJAfotlbGX79YV3/8bIumeElPReR27XmDDlWNyWbScpt3NBMp0RyubIyd3wxIipYabrctS3icaX/BWbYYjvy8dFHFz+pPca2CJd5jS7gFrYCCVmtv411xa3U3VoasiV8htGC2NoCY3D59m13htu0It3WHlJYT5rz3PLJeewix3v9G2bnDtPvQ2AIpXvQrSvGiz46R3ghQvHjjRPHik5ON4RQvNlZFv08UL/rsbI3kAN3WyvjrF+vqj59t0RQv6atI1oRPEd9su7UCpGHblTueOUsWoVVsBVbNnYfE8qWI994NskTJ6xGaORnhyRMRmvQLULK69rBwGLH9j6/zjmz1temsXIa8y49Rp5Xc+qJaQpVph1M8H6HiBet02+8d1yhe9B8FFC/67BjpjQDFizdOFC8+OdkYTvFiY1X0+0Txos/O1kgO0G2tjL9+sa7++NkWTfFiW0X89SfozXVT6X3OQzcg68dP1T4zZWdfk0po4OeG5s1E5I5BFXv0VDlkBlNcpNQmW1XcsSmSBzc33/OdrChe9EtL8aLPjpHeCFC8eONE8eKTk43hFC82VkW/TxQv+uxsjeQA3dbK+OsX6+qPn23RFC+2VcRffzJJvMgyp9zhZ6gLjl52N+LdN/d38WmKdooXIHLrAIRWLEWiXSe4ha1Vy86KJXUu3ZJ9eJBbIWJEyCRaFiG+1xFwO3RB+MOX4KxZgcjkLRY3AAAgAElEQVTGm8Pt1hOrNtwsTVfTeJqheGk8tbT1SihefFZmbnGJzwwMD4oAxUtQ5M20S/FihmuQWTlAD5K+ubZZV3Nsg8hM8RIEdXNtZpJ4EQrZbz6O7LefQmLD7ii95n5zYBoosyyRitw2CKFFcyH755QNHAU3J7cye/i3bxH+9A2E5E5PsvyrdA1QugZOeVnKPUhudpzosQUS3TZXd6YKzfwH8a13QaLtBinna+wBFC+NvcLBXx/Fi88aULz4BBhgOMVLgPANNE3xYgBqwCk5QA+4AIaaZ10NgQ0oLcVLQOANNZtp4kUw5F57mhIZ5Uedi/J9K/Z9sfFw1qxCzh2XIDx3OhJdNkX0ktvh5uZ57qrEKxEjQqZkDUITPkPWF/9VGyPHu28BhMMIx8vgzp4Kp6xuURPv2RuIJxCaOxVl51yH+GbbeO5HYz2R4qWxVtae66J48VkLihefAAMMp3gJEL6BpileDEANOCUH6AEXwFDzrKshsAGlpXgJCLyhZjNRvIQnTURk9BDIUpzoiEeRaNXWEB39tHJXqpy7Lle39ZYNdKOD76y4ZbbPwymPwlm1ovKak3u8rJk5E868GQjNnQ5n0VyEJ34Bt1U7dXvx0PS/IXHJQ7iVDbpZzcBpygfFS1OufnquneLFJ2eKF58AAwyneAkQvoGmKV4MQA04JQfoARfAUPOsqyGwAaWleAkIvKFmM1G8CIqcJ25H1tfvIb7NroieP8IQHf20kbuHIvznBCTad0J0yBi4zQv1k9UR6WVzXWfFUmR99Q5QXo7Q7CkI//I13Egeyi6+FfGuPY30KxOSUrxkQpUyu48ULz7rR/HiE2CA4RQvAcI30DTFiwGoAafkAD3gAhhqnnU1BDagtBQvAYE31GymihenZDVyh50CZ/VKRAeMQrzXDoYIpZg2kUDOQyOR9dMXcIs6IHrZGCQKi1JM4v10L+JlnWyJBCIPjEB44ldI5OWjbMgYNSOnKR4UL02x6um9ZooXn7wpXnwCDDCc4iVA+AaapngxADXglBygB1wAQ82zrobABpSW4iUg8IaazVTxIjiyvv0QOY/dopbdyJIjdReggI+cJ+9A1lfvqjsQRYeMhlvU0WiPUhYva3uTc89VyPr9e3Xb6rLBoxHfsKvRfsqdncLzZ8KZO13dqSlR1BFuUTsk2nc22m5dySleAkPfZBqmePFZaooXnwADDKd4CRC+gaYpXgxADTglB+gBF8BQ86yrIbABpaV4CQi8oWYzWbwIksiYIQj/PRHxTbaBW9ASzuoVQE4u3Ehuxd2DcvLUQF/+D5GIWmKD5O/CWQgtWQAsng9H/ixdgNCieUB5VO1/4nbqAZSsUhvbVt5taO2/Ubpazbap6ZBlRSJd0iEVdMWL3DVJ5Ivsl1PR3zFqWVRNR2jmZDjLi+GURYGyUiBaWvFzIoFEt55ItOmAsOwjI1KlyuEsWwxn/gyEZk+D7HlTG6tEx42AkIP4zvshtkvfGs+T5VKhBbKPzUw482cBORGUH36Wr2cFxYsvfAz2QIDixQOkuk6hePEJMMBwipcA4RtomuLFANSAU3KAHnABDDXPuhoCG1BaipeAwBtqNtPFi9zdKHL9OXBiqd9+uaGQunnNoP6I4GlWiNhxA4zPIEn2XVe8SLzcHSlnzOUIT/8LbrMCyG2oXZFRU34Hmhcivv0eCE3/C+Ffv/GNSuSOElGhUEWuRALO0oUILVm4Tu5EyzZwq9362kkkEJry2zrnSX9Lbn/ZV78oXnzhY7AHAhQvHiBRvPiEZGk4xYulhdHsFsWLJjiLwzhAt7g4PrrGuvqAZ2EoxYuFRfHRpUwXL3Lp2Z+9BcyZAjRvWTsJuRuQmrFRApRW/O3EY3DXDvRlPxb5GY6jcoQWzgZWrYCbmw/k5lf8nde8Qq6oPxX/p2bQBHj4ES9KvqxZhcidlyI0Z2qdVxHffDu4kfyKWUMyi0jNIMpFaNofCM38B7HefYCC1uvmaNYCiQ17INGpO9xmLWrNL/Is/MPHyBr/SsWMpRoOmb2UaNNeiS2RQTJjp3T4I75mFVG8BPjAbSJNU7z4LDRnvPgEGGA4xUuA8A00TfFiAGrAKTlAD7gAhppnXQ2BDSgtxUtA4A012xjEiyE0GZHWr3hJXmRoxiSEpv1ZIUhkM+CS1Qj//AXc9p0Q63OwsbsyVYWsbpU9czIge/WI0MrOUWKrurTJGXc1sn77DmWnXo7YLvtp14niRRsdAz0SoHjxCKq20yhefAIMMJziJUD4BpqmeDEANeCUHKAHXABDzbOuhsAGlJbiJSDwhpqleDEENk1pG0q8pKm7DdJM1jtPI+eNxxDb7UCUnTxYOyfFizY6BnokQPHiERTFi09QFoZTvFhYFB9donjxAc/SUA7QLS2Mz26xrj4BWhZO8WJZQXx2h+LFJ8CAw5uieAn9/TNyx1wG2ZS39NqHtCtA8aKNjoEeCVC8eARF8eITlIXhFC8WFsVHlyhefMCzNJQDdEsL47NbrKtPgJaFU7xYVhCf3aF48Qkw4PCmKF5kf5e8QYcArouS0W9U7LujcVC8aEBjSEoEKF5SwrX+yVxq5BNggOEULwHCN9A0xYsBqAGn5AA94AIYap51NQQ2oLQULwGBN9QsxYshsGlK2xTFi6DNvekChGb9g+hFNyK+5U5atCletLAxKAUCFC8pwKrpVIoXnwADDKd4CRC+gaYpXgxADTglB+gBF8BQ86yrIbABpaV4CQi8oWYpXgyBTVPapipecp4bi6xP30D5QSej/NDTtGhTvGhhY1AKBCheUoBF8eITlmXhFC+WFcRndyhefAK0MJwDdAuL0gBdYl0bAKJFKSheLCpGA3SF4qUBIAaYoqmKl6zvP0LOI6OQ6LIJSq/8j1YFKF60sDEoBQIULynAonjxCcuycIoXywriszsULz4BWhjOAbqFRWmALrGuDQDRohQULxYVowG6QvHSABADTNFUxYuzagUi156CUMkalJ1+BWI771NvFcJTf0e8+xaV51G81IuMJ/gkQPHiEyCXGvkEGGA4xUuA8A00TfFiAGrAKTlAD7gAhppnXQ2BDSgtxUtA4A01S/FiCGya0jZV8SJ4sz9/C9nP3IVEQStEhz1YQTxaAqcsCidaCsBFvGtPOCWrkfPg9Qj98zuiIx5FolVbdSrFS5oepE24GYoXn8WnePEJMMBwipcA4RtomuLFANSAU3KAHnABDDXPuhoCG1BaipeAwBtqluLFENg0pW3K4kUQ5466CKGZk2qlnShoDScRh7NquTontu1uKDtvOMVLmh6fTb0ZihefjwCKF58AAwyneAkQvoGmKV4MQA04JQfoARfAUPOsqyGwAaWleAkIvKFmKV4MgU1T2qYuXkS6iHyp74j37I3QtL/gREtQftjpcNttiHb7H1hfGH9PAr4IULz4wgdQvPgEGGA4xUuA8A00TfFiAGrAKTlAD7gAhppnXQ2BDSgtxUtA4A01S/FiCGya0jZ18VIf5tDMyQjNnYbYv/ZH9mdvIfvZuypDWr7wRX3h/D0J+CJA8eILH8WLT3yBhlO8BIq/wRuneGlwpIEn5AA98BIY6QDragRrYEkpXgJDb6RhihcjWNOWlOIlNdSRW/ojNGc64lv/C22G3phaMM8mgRQJULykCKz66Zzx4hNggOEULwHCN9A0xYsBqAGn5AA94AIYap51NQQ2oLQULwGBN9QsxYshsGlKS/GSGmhnxVK4Ba1UEDfXTY0dz06dAMVL6szWiaB48QkwwHCKlwDhG2ia4sUA1IBTcoAecAEMNc+6GgIbUFqKl4DAG2qW4sUQ2DSlpXjRB03xos+Okd4IULx441TrWRQvPgEGGE7xEiB8A01TvBiAGnBKDtADLoCh5llXQ2ADSkvxEhB4Q81SvBgCm6a0FC/6oCle9Nkx0hsBihdvnChefHKyMZzixcaq6PeJ4kWfna2RHKDbWhl//WJd/fGzLZrixbaK+OsPxYs/fkFHU7zoV4DiRZ8dI70RoHjxxonixScnG8MpXmysin6fKF702dkayQG6rZXx1y/W1R8/26IpXmyriL/+ULz44xd0NMWLfgUoXvTZMdIbAYoXb5woXnxysjGc4sXGquj3ieJFn52tkRyg21oZf/1iXf3xsy2a4sW2ivjrD8WLP35BR1O86FeA4kWfHSO9EaB48caJ4sUnJxvDKV5srIp+nyhe9NnZGskBuq2V8dcv1tUfP9uiKV5sq4i//lC8+OMXdDTFi34FKF702THSGwGKF2+cKF58crIxnOLFxqro94niRZ+drZEcoNtaGX/9Yl398bMtmuLFtor46w/Fiz9+QUdTvOhXgOJFnx0jvRGgePHGiWeRAAmQAAmQAAmQAAmQAAmQAAmQAAmQQMoEKF5SRsYAEiABEiABEiABEiABEiABEiABEiABEvBGgOLFGyeeRQIkQAIkQAIkQAIkQAIkQAIkQAIkQAIpE6B4SRkZAxoTgfJYHIuLl6F1qwJEcrJrvLTFS5YjPy8X+XmRdX6fSLhYsmwFsrOzUNiiWWPCktHX4qUutdVULnz5ytWIRsvRrk3LjOZga+ff++Q77LBNTxS1Kqixi17qt3LVGsTicbQqbLFeDtbPX+WTbAtbNEco5PhLVkd0fXWqq8YlpWVYumwFOrQrMtpHYxffCBPXVxN5Xi8sXoo2rQuRFQ6vQ8DL+3AjRGbtJfG5aW1pPHeMz0fPqHgiCaSVAMVLWnGzsfoIzJ63CH1PuAxbbtYNz99/XeXpf06egaPPuQ677LAFHrr9svrSePr9g0+/hTEPvlR5bt89d8R1g09HYUGFRJk5ZwHOH3onZsxeoP595EH/xrWDT0N2Vhhf//A7Bg4bizUlpep3O27bE0MuOE71u/ox+oEX8dAz/8XXb/0HBc3zPfWtMZyUzlomedVXl7pqKjLm1IE3Vda7x0Yb4JyTDsGh++/KmtbygBw8fBze++R79dvrBp+GYw/bq96H7hZ7no4n7r4K22+96Xrn1lc/eb4NveF+fPTlTyp26149MPaGgWowl0r9Pv16Ii68cjT+M+oS7LHLNvX2uSmc8Ob7X+HVdz7Htz/9WeU1cSfcOfzCBr38+upUV42lIwOuvquy/q1btsDhB+yOS88/dr0+zpm/GIefcQ1OOHxvDD5v/d836EVZlkxqecVND6D3lpvgqXuuruydvIeedkzfGl/T/FxCfTWR59uQ6++tfL+s+lpR3/twsl9lZeU469LbUFIaxUsPjvDT3YyNffa18bhhzJOq/wfuvTNuv/aCBr0Wk8/NJctWYvfDB6zX34fvvBz/2q5Xg16HjcmSz0n5THHxOUdXdvHpVz7ATXc/rf5PftcQh8nn4y3jnsUTL763Tjerv840xDUwBwk0VgIUL421shl6XcnBunT/0dFXYKfePdWVDL3xfrz1wdcNKl5efOsTdN6gHbbptTFmzV2IswbfgrNOOBinH3eAavPcy25H82Z5uPGKczB/YTGOPW8Err3kVPWh9ZsJf2DR4mX49y7boLS0DNePfhzyjd69N1+yDnkZyFxzy8Pq/5qqeElHLZPQ66tLXTVduHgZXnv3cxzWdzc0y8vFky+9j0effxefvXo38nJzKuvalGta/WVFvlWLx+M46uxrcdYJB/kWL/XVTwTmi29+gifHXq1qcsEVo9GtS0eMvPxMeK3f31Nm4eT+N6pBIMVLRUV/+m2yYnLZBcerx38ikcDvf0+HDIqrDtwb4m2lvjrVVWNp/55HXsX+e+6ILhu2wzc//oGLrhqD5+69Fltt3r2yezJb5qSLbsCUGXPV47IpipfrRz+x3mPclHipqybyGvHvIwai/5lH4KQj98UnX/2MQcPG4r1nb0Onjm1R3/uwFNV1XfU++tq7X2DzTTZqsuJFZgZFo2W4/d7nsWLVmgaXoiafm8VLV6jHwX23XKqeu8mjXZtW67y/NsRrjI05kuJF+vbVm+PULGmp595HXwyRUg0pXkw+H2++5xn1efnyC0+oxByJZKND29Y2YmefSMA6AhQv1pWkaXcoKV7kA9r0WfPxwG1DIN9c7n/8EBxzyJ6YPX+RmvGybPkqXHDlaPwzbY4CtsVmXXHlgJOwWY/O6t8nXDgS5558CD7/9lfIbJkbhp4FmcFQ1zHs1kcwZ94iPDJ6qFpusuuhF6lBh9h8OW6860nMX7gEY28ctF6a5JvqxPEPV06j/v7nv3DhlWNw/WVnqG/7mqp4qa+WAlPE2lff/6Y+gEidLjrjCMgMpMdeeBdTps9VA+vk8Z/HX1cfPi8595h6nyxV67J6TWlKNU0+Fp8cexW226pidkZTr2ltwA86eShOP/YAJV5kIDVz9sLKWQjzFi7BxcPGQr7ZFJFZ14yX6vmrP69k4CiPi+Q3g7JsafDw/+C3jx+F46y7LKam+i0qXobjzh+BweceixF3Pq6+MeaMF+Dl/36Ga297BD9/+LCa0VfTMXf+Yowa+zS+mfAnttmih3o9llokX29322FLjP/iR0yaOlvJ6WsvOW295Zk15a1ep1RqLPn2PuYSHN9vb5x78qEqvSxB63/VGHRoW6QGp506tmmS4uXxF9/Dbjtuic++mYiXHxqplmRVFS/xeAKPPPc2ZBbFylUl2Gf37XBl/5PUjE95Tu2yQy9V4+Qh36Ifst8u6LvnTvW+7latSXJ22U/vP4ictct55fVC3hdOOnK/9XJVfR9O/lIE4Nvjv8Eh++2Kdz76tsmKlySPm+5+CouXrFDipa7PQvL5SGY+Sd2efXW8CvcqyOXchnxuJsXLW0+MUrK8qR3yXibPybzciHrPOfvEg/H2+G/x+AvvquXq8n/yvvbDxL9x/Z2PQ9435dhr121x9cWnKFEj9bz65odwxYAT1RdDIsq8iPGGfD6KeFm2YhVuvurcplZCXi8JNAgBipcGwcgkDUUg+UYvb86HnHolXrh/OP774ddIuK5apjPht8lKvIgYkZkH2225ifow98izb2PqzHmVH8hkcCeHfLDboEOR+rDYsV3tRl6+eeh7whAcvM8uasA4ZfocHHb61fjk5TFoW1Sx14e80b3+3pc1fuiTDzfyppicAi3Lk+RD7pjr+6N9m1bod8bVTVa81FdLYSvTbTfu1glFLQvwydc/Q5ZnffXGOMycuxDHnz8C7zx9C7ps2B4iT3Y66Hzcd8tg7L7z1vU+7KrWJdWaJme2fP7aWMiSBta0dtxVxYuIsb/+mYG7Rw5UAbK868CThlZ+y5eKeKn+vNrxwPOVRE0O+P+YNB3HnDu8MnfVHlavn3zzfvqgUepxI9++Sy6Klwpi8iF/32MHY89dt8VRB++Bnj06Y4MObSpxyutjv9OvwrZbbIxTjt4f02bOx2Uj78X7z92ODTu0UTJNllmedeLBELklSzivGngSjjhw93qfo9XrlEqN5Tkpj72qM5dk2v4/02bj/lsvxdAbH2jS4kXeK3fr1x93Dr9IPWeqihcRpLeOew6XXXi8em+866GX1XulPG8ffvZtvPDGx3j3mVuV0JTZT8eeN3yd98PaClu9Ji+8+Qkee/4dvP3ULZUhInG6du643hKx6u/DEvD+pz9g5OjH8eKDI/DZ1xMh+ZrqUqMkwKripa7PQr/+ORXHX3A99t6tt5Lis+YuUl8gJWdc1PfkbMjnZlK8SF8KC5pj0+6d0O+APk1mf7ykeBlw5pHqi7hPX7kLJ100Un3J9Njz71aKl9/+nobJU2ermV2yrO662x5Vr8syay9Zz/ZtW+Gog/6N3NyIEml1HQ39fBTx8v6n36vlYbLH2t59tqtx2XB9jy3+ngSaKgGKl6ZaeUuvOyle5IPBuEdfVTJD9hyQaclvvPdlpXiR7stA6pc/p2D6zHn49a9pSsT8/slj6spkICBTWnffeStPV3rd7Y+qbx/+++TNalPV5NT7qh9Q5APffU+8jo9eHL1OzuS38vIhV/agWb5itfqQetqxB+DEI/ZR19CUxYuXWsq3r39PmYm//pmpvsUZ+8grao8fGczJYKHPTlupqbjyzfy4x17FB8/dgXA4VGdtq9cllZpOnjYbJ154g9oPQQbprGndTyMT4qV6/WS5wZZ7nbHOIDsp0z58/g50bF9U2cnq9ZNlgPJhVw6RLfLtP8XLujWV11mZoj7h10nqFxt1aq+mk8uHflkCdtbgW/H4XVeiWX6u+v3w2x9TAyd5jZPX2+qzA1euLqn3W9HqdUqlxiJhT+5/A5o3y8djY65Qrwcye0MGMSLskzM3mvKMFxEU9z3xBt54/0u88fhNOP786yv3eJFZoT037qL2ZpLjw89/VEuARHhHy8qx19EXV9ZUZNbiJcuUwKnrqKkmsnTs3Y+/W0eWyHOxeX4ehg+p+IIkeVR/H5b39TMvuUXNQt2qZzclgyhegKripa7PQsmBetUZgbLPyvWXn4m9du1dZy0b+rm5anUJ7nroJcjSIlkKKJ/XZG+u5++7rnImlKcPaxl6UlK8yGvT4WdcjQ07tsXUGXOVkDxt0KhK8SKXJ/J6wq+TsXDxUiUeC1rkY9xNF1eKl+/evq/ydTidz0dpS65j+uz56mYUIonGfz5BzbzyMhMuQ0vHbpNAgxKgeGlQnEzml0BV8SKD3QNPulxNW5dpjf957LVK8SIy44xLbkaL5vlqY1v5oChvCFXFS9WBQF39krzjHnsNz913nfpwJ0dyQCffSsiHAzlqmvHy5fe/qb1gqm4WmFz+cOoxfSGLH5YsX6n6dly/vXHMIXuobzKawuG1lvJhXTYxFumyd5/e6NiuSO0t8ex/hqnNU+UDmnzw/+L1sWr2y+EH7q4GD3UdNdXFa01ladspA25Uj6ubrjhHDehY07ofsQ0tXmqqn/RAZMmNV5yN/ffYQXWophkvNdVPZJ4MJI8+ZA+1f48cMu1bpMJh++9WOYOmKTwv67tGGSBNmjoLT7z4Pj747Ac1U+/Dz36ALAFJLrtM5thrt97qG9fq4uW51z/Co8+9o4R5bUdNdfJaY5Hug4bdrZZ+ykbNLQubq2ZkY3YRRht33VD9e/wXE9R7RNXlafVdf2P4fXKQJ+JF6rnX0ZfgmotPUe9hyc11ZQAu36InZyXNW1CMfY+7FK88PFIt2R047G60LizAlQNPQp9+A9TsTVm6VNtRW028znip6X145Ogn8PWPv2PPXbateL5PnqFm38j76AWn9VO1bYpHVfFS12ehmsSLvFb3P+NIHLTPzml9blZvbNrMeWpWc/J9vrHXsepzMvmlgiyhlps2yP5ayaVGspROxKQsb958ky5q6Wbu/++hIl8k1lTPdD4fa2pLZqUuW75S9Y8HCZBA/QQoXupnxDPSSKDqYF3WtMoH+J17b67WBFcVL7Kzuuzd8vAdl6uB8cQ/puDEC0emJF7kW/A77ntefYP2+F1XoNemXSuvtKY9XuRDoHwDkdzjJTkYl6UPVafUywBfPvAnD7lTwNOvfIjzTjkUB+/zL/RYOyhII9ZAmvJaS/nGRD7kV51dJAO55AeyNSVR7HHkIBx+wG545tXx+PL1eyoHWjVdWG118VLT5IdYmT477JJTK/frYU3rfgjJgFf22Djq4H/j/iffxM+//1O50XSqS41qq5/0QGY/HbDXTmp9vBzV93iprX6yke5TL3+wzkXI0grZ++CQfXfxtGwtkCdRmhqV51h+XmSd1mQDxQNOvFzNJpHfV+xTNW69WwFLUHXxIpJG4iW2pqO2OnmpsezbMvCau1FSElXLiZLSRWKff/0jtQw1echmrK1bFuDQ/XZR4rupHFUHeXLNIhllL4ncSA4uOLWf+jLjiDOvwW47bYUh5x+nsMgdxc4echs+fmmMmvX5+be/KCEu728yA7GuWYZ11SS5x8vPHzyk9rKQQ14vTj1mf7UUuK73YemDvM8nD3mf/+WPKWq528lH7Yf8tRK1qdQ1eZ2yP5V8MSUzDer6LKQjXkw9N6vXKLlsWGYzyWe8xn5UfU6Wl8dw7xOv47xTDlMzR6qKl8NOuwoH7L0zLjytn0Ii+zB999OfKYkXU8/Hmmoky0p//GUSZC88HiRAAvUToHipnxHPSCOB6oP1qk1XFS+yDOnjr35Wg7tYLK5mrFRfalTfjBe5S4LEiKnvvtH/NnuT9bNZ4bD6EFrQvJn6hr36XY1kr5erRj2IK/qfqNa4Jo9Whc3X+zDIpUYVO/jXVku5M8lZl96qvmmVnfH/O/4btQ696jdhyVsYyoyFEUPOqPURWV9d6qqp3O3myLOGKTk24KwjEQpVLGWSAamsZa56NNWaVmUga8fbFhWqmUqnDLgJyeU+3/30l7rTzMsPXa+kqCw1kCUCSbFW1x4v9dVPZkK99Nan6q5GUhcZGCbvapRK/eQ6uNTof9WUfXnkMX3asX3VbJEFi5eqfbPkVuFSV5m6t++xlyrBfPE5R6nA73/+G+WxGPbdfXslXmTZiDx3ZENzeW2VvbJk09vqR311qqvGIoBk1ptsoDt6RH+1WbMc8lytaQ8v2SS2qS81Ej4yG2X/4y9Vm5fL7FERL7Ks7JV3PsOYEf3Rvm1r3DDmCbXXz4sPDFf7ugjjvY6q/44r9dVEfr/jgedh6EUn4MQa7mpU3/tw1cdPU15qJDOS8vNz1TIdWfaX3CS3rs9CqYoXk89NEXCl0Sj+tf0WagPvMQ++rD5/ffjCHU1in5fqMrTq47qqeJGfN+neCYPPPUZtbixLOlu1bO5ZvJh+Psr+e4ftvyu6dOqgloefcfEt6osQ+WKRBwmQQP0EKF7qZ8Qz0kggKV5qugNQVfEiHxBlg77kt2Gyl4t84E9lqZF86ybtVT9kza1MV5epsDKwS55z+AF9MPzS09W3dnKrTvl2tfpRffaL/L6pDtK91lK+8Rw8fJxa1iCHbL730Zc/rXOL2OSMJhkUVJ2ZVJ1/fXWpq6bJKb7VcyaXulG8rEvmuPNGqDXesvGwLMdoWQoAAAocSURBVKtL3mlINsi8+Nqx6raxcsgyDxnAVxUvVe8UVTVrffWTb0ll5oXcqUUO2QNIZqDJN/Sp1E9iKV7+R15mO8g3l1LP5CGbX147+LTK5UWyR5LcUUOEmxwy20AG8XI3HBEv8jiQgb0csu/L0P4n1jg7pr461VXjBYuWqrsYVT+kbdkEu/pB8TKiEolIC5kpkRQvMgvsqlEPVb7uynve2BsGrjMjU4ScDOxlXzP5QqKmw0tN5PVc3q+Thyx7OuHwfSpeH+p5H67aZlMWL/L8FCkpR7++u+Gai09V8rmuz0KyR46Iyqp7vMhSI9ng9cC9119qZPK5Ke/v8niTx50c8py9bdgF+Nf2vWp8XDW2//QqXmSZ7RU33q9eS+U1Vpb9yZI6+ZKxpnpW52T6+Zh830+2K5+LZXawzKbjQQIkUD8Bipf6GfEMiwnILU5bFrbwdNtS3cuQNzL5ZjW5qaRuHsbVTUCWZMkMieqzSyRKBgAy7VxmwTTEwZr6pyjfiMutTGUph2xWW/2Qu1jIB8e83Ib/QCbLSWS6dnL/Jf9XwwxCQPbKkg/8LZrlVc4mqU4myb6oVUHlLbyTS426d9kAkUh2g3wIZ43T85gUzqWlZbWKlYbqhWygPn/RErQralm55KihcjeFPLLxtCwvysuLqOUp1Y90fBZKtqn73JT3jOIlK1QakeUys4rH+gSEk8xw6tCuSM0OMnH4eT7KrKuly1eibVErI+/vJq6XOUnAFgIUL7ZUgv0gARKokYBMk//3EQPVEqO6NgQkPhIggWAIVN/jJZhesFUSIAESIAESIAESsJcAxYu9tWHPSIAE1t5a8YvvflX7R+TU8E0fIZEACQRLQPbmkTvecAZSsHVg6yRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYSoHixtzbsGQmQAAmQAAmQAAmQAAmQAAmQAAmQQIYToHjJ8AKy+yRAAiRAAiRAAiRAAiRAAiRAAiRAAvYS+D+0phhbIdKEYwAAAABJRU5ErkJggg==",
      "text/html": [
       "<div>                            <div id=\"d1ed3b0a-9101-4ec0-a577-b8802861a60d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d1ed3b0a-9101-4ec0-a577-b8802861a60d\")) {                    Plotly.newPlot(                        \"d1ed3b0a-9101-4ec0-a577-b8802861a60d\",                        [{\"mode\":\"lines\",\"name\":\"PV SPY_Hold\",\"x\":[\"2024-01-02T00:00:00\",\"2024-01-03T00:00:00\",\"2024-01-04T00:00:00\",\"2024-01-05T00:00:00\",\"2024-01-08T00:00:00\",\"2024-01-09T00:00:00\",\"2024-01-10T00:00:00\",\"2024-01-11T00:00:00\",\"2024-01-12T00:00:00\",\"2024-01-16T00:00:00\",\"2024-01-17T00:00:00\",\"2024-01-18T00:00:00\",\"2024-01-19T00:00:00\",\"2024-01-22T00:00:00\",\"2024-01-23T00:00:00\",\"2024-01-24T00:00:00\",\"2024-01-25T00:00:00\",\"2024-01-26T00:00:00\",\"2024-01-29T00:00:00\",\"2024-01-30T00:00:00\",\"2024-01-31T00:00:00\",\"2024-02-01T00:00:00\",\"2024-02-02T00:00:00\",\"2024-02-05T00:00:00\",\"2024-02-06T00:00:00\",\"2024-02-07T00:00:00\",\"2024-02-08T00:00:00\",\"2024-02-09T00:00:00\",\"2024-02-12T00:00:00\",\"2024-02-13T00:00:00\",\"2024-02-14T00:00:00\",\"2024-02-15T00:00:00\",\"2024-02-16T00:00:00\",\"2024-02-20T00:00:00\",\"2024-02-21T00:00:00\",\"2024-02-22T00:00:00\",\"2024-02-23T00:00:00\",\"2024-02-26T00:00:00\",\"2024-02-27T00:00:00\",\"2024-02-28T00:00:00\",\"2024-02-29T00:00:00\",\"2024-03-01T00:00:00\",\"2024-03-04T00:00:00\",\"2024-03-05T00:00:00\",\"2024-03-06T00:00:00\",\"2024-03-07T00:00:00\",\"2024-03-08T00:00:00\",\"2024-03-11T00:00:00\",\"2024-03-12T00:00:00\",\"2024-03-13T00:00:00\",\"2024-03-14T00:00:00\",\"2024-03-15T00:00:00\",\"2024-03-18T00:00:00\",\"2024-03-19T00:00:00\",\"2024-03-20T00:00:00\",\"2024-03-21T00:00:00\",\"2024-03-22T00:00:00\",\"2024-03-25T00:00:00\",\"2024-03-26T00:00:00\",\"2024-03-27T00:00:00\",\"2024-03-28T00:00:00\",\"2024-04-01T00:00:00\",\"2024-04-02T00:00:00\",\"2024-04-03T00:00:00\",\"2024-04-04T00:00:00\",\"2024-04-05T00:00:00\",\"2024-04-08T00:00:00\",\"2024-04-09T00:00:00\",\"2024-04-10T00:00:00\",\"2024-04-11T00:00:00\",\"2024-04-12T00:00:00\",\"2024-04-15T00:00:00\",\"2024-04-16T00:00:00\",\"2024-04-17T00:00:00\",\"2024-04-18T00:00:00\",\"2024-04-19T00:00:00\",\"2024-04-22T00:00:00\",\"2024-04-23T00:00:00\",\"2024-04-24T00:00:00\",\"2024-04-25T00:00:00\",\"2024-04-26T00:00:00\",\"2024-04-29T00:00:00\",\"2024-04-30T00:00:00\",\"2024-05-01T00:00:00\",\"2024-05-02T00:00:00\",\"2024-05-03T00:00:00\",\"2024-05-06T00:00:00\",\"2024-05-07T00:00:00\",\"2024-05-08T00:00:00\",\"2024-05-09T00:00:00\",\"2024-05-10T00:00:00\",\"2024-05-13T00:00:00\",\"2024-05-14T00:00:00\",\"2024-05-15T00:00:00\",\"2024-05-16T00:00:00\",\"2024-05-17T00:00:00\",\"2024-05-20T00:00:00\",\"2024-05-21T00:00:00\",\"2024-05-22T00:00:00\",\"2024-05-23T00:00:00\",\"2024-05-24T00:00:00\",\"2024-05-28T00:00:00\",\"2024-05-29T00:00:00\",\"2024-05-30T00:00:00\",\"2024-05-31T00:00:00\",\"2024-06-03T00:00:00\",\"2024-06-04T00:00:00\",\"2024-06-05T00:00:00\",\"2024-06-06T00:00:00\",\"2024-06-07T00:00:00\",\"2024-06-10T00:00:00\",\"2024-06-11T00:00:00\",\"2024-06-12T00:00:00\",\"2024-06-13T00:00:00\",\"2024-06-14T00:00:00\",\"2024-06-17T00:00:00\",\"2024-06-18T00:00:00\",\"2024-06-20T00:00:00\",\"2024-06-21T00:00:00\",\"2024-06-24T00:00:00\",\"2024-06-25T00:00:00\",\"2024-06-26T00:00:00\",\"2024-06-27T00:00:00\",\"2024-06-28T00:00:00\",\"2024-07-01T00:00:00\",\"2024-07-02T00:00:00\",\"2024-07-03T00:00:00\",\"2024-07-05T00:00:00\",\"2024-07-08T00:00:00\",\"2024-07-09T00:00:00\",\"2024-07-10T00:00:00\",\"2024-07-11T00:00:00\",\"2024-07-12T00:00:00\",\"2024-07-15T00:00:00\",\"2024-07-16T00:00:00\",\"2024-07-17T00:00:00\",\"2024-07-18T00:00:00\",\"2024-07-19T00:00:00\",\"2024-07-22T00:00:00\",\"2024-07-23T00:00:00\",\"2024-07-24T00:00:00\",\"2024-07-25T00:00:00\",\"2024-07-26T00:00:00\",\"2024-07-29T00:00:00\",\"2024-07-30T00:00:00\",\"2024-07-31T00:00:00\",\"2024-08-01T00:00:00\",\"2024-08-02T00:00:00\",\"2024-08-05T00:00:00\",\"2024-08-06T00:00:00\",\"2024-08-07T00:00:00\",\"2024-08-08T00:00:00\",\"2024-08-09T00:00:00\",\"2024-08-12T00:00:00\",\"2024-08-13T00:00:00\",\"2024-08-14T00:00:00\",\"2024-08-15T00:00:00\",\"2024-08-16T00:00:00\",\"2024-08-19T00:00:00\",\"2024-08-20T00:00:00\",\"2024-08-21T00:00:00\",\"2024-08-22T00:00:00\",\"2024-08-23T00:00:00\",\"2024-08-26T00:00:00\",\"2024-08-27T00:00:00\",\"2024-08-28T00:00:00\",\"2024-08-29T00:00:00\",\"2024-08-30T00:00:00\",\"2024-09-03T00:00:00\",\"2024-09-04T00:00:00\",\"2024-09-05T00:00:00\",\"2024-09-06T00:00:00\",\"2024-09-09T00:00:00\",\"2024-09-10T00:00:00\",\"2024-09-11T00:00:00\",\"2024-09-12T00:00:00\",\"2024-09-13T00:00:00\",\"2024-09-16T00:00:00\",\"2024-09-17T00:00:00\",\"2024-09-18T00:00:00\",\"2024-09-19T00:00:00\",\"2024-09-20T00:00:00\",\"2024-09-23T00:00:00\",\"2024-09-24T00:00:00\",\"2024-09-25T00:00:00\",\"2024-09-26T00:00:00\",\"2024-09-27T00:00:00\",\"2024-09-30T00:00:00\",\"2024-10-01T00:00:00\",\"2024-10-02T00:00:00\",\"2024-10-03T00:00:00\",\"2024-10-04T00:00:00\",\"2024-10-07T00:00:00\",\"2024-10-08T00:00:00\",\"2024-10-09T00:00:00\",\"2024-10-10T00:00:00\",\"2024-10-11T00:00:00\",\"2024-10-14T00:00:00\",\"2024-10-15T00:00:00\",\"2024-10-16T00:00:00\",\"2024-10-17T00:00:00\",\"2024-10-18T00:00:00\",\"2024-10-21T00:00:00\",\"2024-10-22T00:00:00\",\"2024-10-23T00:00:00\",\"2024-10-24T00:00:00\",\"2024-10-25T00:00:00\",\"2024-10-28T00:00:00\",\"2024-10-29T00:00:00\",\"2024-10-30T00:00:00\",\"2024-10-31T00:00:00\",\"2024-11-01T00:00:00\",\"2024-11-04T00:00:00\",\"2024-11-05T00:00:00\",\"2024-11-06T00:00:00\",\"2024-11-07T00:00:00\",\"2024-11-08T00:00:00\",\"2024-11-11T00:00:00\",\"2024-11-12T00:00:00\",\"2024-11-13T00:00:00\",\"2024-11-14T00:00:00\",\"2024-11-15T00:00:00\",\"2024-11-18T00:00:00\",\"2024-11-19T00:00:00\",\"2024-11-20T00:00:00\",\"2024-11-21T00:00:00\",\"2024-11-22T00:00:00\",\"2024-11-25T00:00:00\",\"2024-11-26T00:00:00\",\"2024-11-27T00:00:00\",\"2024-11-29T00:00:00\",\"2024-12-02T00:00:00\",\"2024-12-03T00:00:00\",\"2024-12-04T00:00:00\",\"2024-12-05T00:00:00\",\"2024-12-06T00:00:00\",\"2024-12-09T00:00:00\",\"2024-12-10T00:00:00\",\"2024-12-11T00:00:00\",\"2024-12-12T00:00:00\",\"2024-12-13T00:00:00\",\"2024-12-16T00:00:00\",\"2024-12-17T00:00:00\",\"2024-12-18T00:00:00\",\"2024-12-19T00:00:00\",\"2024-12-20T00:00:00\",\"2024-12-23T00:00:00\",\"2024-12-24T00:00:00\",\"2024-12-26T00:00:00\",\"2024-12-27T00:00:00\",\"2024-12-30T00:00:00\",\"2024-12-31T00:00:00\",\"2025-01-02T00:00:00\",\"2025-01-03T00:00:00\",\"2025-01-06T00:00:00\",\"2025-01-07T00:00:00\",\"2025-01-08T00:00:00\",\"2025-01-10T00:00:00\",\"2025-01-13T00:00:00\",\"2025-01-14T00:00:00\",\"2025-01-15T00:00:00\",\"2025-01-16T00:00:00\",\"2025-01-17T00:00:00\",\"2025-01-21T00:00:00\",\"2025-01-22T00:00:00\",\"2025-01-23T00:00:00\",\"2025-01-24T00:00:00\",\"2025-01-27T00:00:00\",\"2025-01-28T00:00:00\",\"2025-01-29T00:00:00\",\"2025-01-30T00:00:00\",\"2025-01-31T00:00:00\",\"2025-02-03T00:00:00\",\"2025-02-04T00:00:00\",\"2025-02-05T00:00:00\",\"2025-02-06T00:00:00\",\"2025-02-07T00:00:00\",\"2025-02-10T00:00:00\",\"2025-02-11T00:00:00\",\"2025-02-12T00:00:00\",\"2025-02-13T00:00:00\",\"2025-02-14T00:00:00\",\"2025-02-18T00:00:00\",\"2025-02-19T00:00:00\",\"2025-02-20T00:00:00\",\"2025-02-21T00:00:00\",\"2025-02-24T00:00:00\",\"2025-02-25T00:00:00\",\"2025-02-26T00:00:00\",\"2025-02-27T00:00:00\",\"2025-02-28T00:00:00\",\"2025-03-03T00:00:00\",\"2025-03-04T00:00:00\",\"2025-03-05T00:00:00\",\"2025-03-06T00:00:00\",\"2025-03-07T00:00:00\",\"2025-03-10T00:00:00\",\"2025-03-11T00:00:00\",\"2025-03-12T00:00:00\",\"2025-03-13T00:00:00\",\"2025-03-14T00:00:00\",\"2025-03-17T00:00:00\",\"2025-03-18T00:00:00\",\"2025-03-19T00:00:00\",\"2025-03-20T00:00:00\",\"2025-03-21T00:00:00\",\"2025-03-24T00:00:00\",\"2025-03-25T00:00:00\",\"2025-03-26T00:00:00\",\"2025-03-27T00:00:00\",\"2025-03-28T00:00:00\",\"2025-03-31T00:00:00\",\"2025-04-01T00:00:00\",\"2025-04-02T00:00:00\",\"2025-04-03T00:00:00\",\"2025-04-04T00:00:00\",\"2025-04-07T00:00:00\",\"2025-04-08T00:00:00\",\"2025-04-09T00:00:00\",\"2025-04-10T00:00:00\",\"2025-04-11T00:00:00\"],\"y\":[10000.0,9918.333477416903,9886.384968642476,9899.927074911608,10041.25665708719,10026.02424723114,10082.72517605198,10078.282635813637,10085.264238987551,10048.238260261107,9992.383467112419,10081.24345474703,10206.917559230485,10228.499266223278,10258.331123979084,10269.544061432865,10325.39951050068,10312.282439825,10393.949618327226,10385.909361684435,10216.439537178221,10350.153898304467,10459.113215707797,10421.029239431607,10451.286132780862,10538.453849071177,10543.107595267993,10604.041826126077,10599.386768091008,10453.401471961231,10548.397583016738,10621.17902512315,10568.286362746108,10510.103712620325,10519.62306689156,10737.332463497125,10744.736478587985,10705.384610641822,10725.272734452064,10711.098322145763,10749.603398500654,10850.523771099448,10838.887109890466,10730.561410362556,10784.935138125422,10891.991634145108,10826.615518967808,10817.306714735923,10933.672670906622,10916.534160071296,10894.953764916754,10820.142909035438,10884.447908280472,10944.936114133081,11046.167392397458,11082.673227257223,11061.66151398466,11031.100930080207,11010.72545835957,11103.258593098084,11101.136038807332,11081.823156070323,11011.364323587999,11023.458160427594,10888.905534658708,11002.66158862826,11008.815421865545,11021.549435771818,10911.190386954251,10993.534473994194,10841.791519779053,10705.963787229815,10686.437730776954,10623.19335275817,10601.33353605608,10508.801713155817,10605.578644637588,10731.431159123234,10726.337291193075,10685.588971428304,10786.824185207433,10825.024915087999,10653.542730704148,10618.949556014913,10718.272765542639,10851.129184452473,10963.185751967343,10975.282212483437,10976.345457386193,11039.589835404977,11053.810162050077,11055.29253927415,11106.017388940767,11243.542640187306,11220.410996300494,11236.540047601371,11249.486579304368,11277.074537731165,11244.603917332683,11162.471036251214,11236.327529804645,11244.17888173923,11165.442349890618,11091.374650378713,11192.395378603738,11201.520525480428,11214.043333428226,11347.32347609326,11347.110958296533,11333.315667244884,11368.33387752757,11395.711941834143,11489.305041879783,11512.439309443098,11519.444525705538,11611.124965580646,11640.625584177973,11609.003723128142,11593.441385951866,11555.753584827593,11600.253761991347,11614.731208933721,11633.041847246666,11587.263939626053,11611.111847198128,11689.251492642356,11741.416740709,11809.1233365399,11822.749400457118,11834.247662730577,11951.348904241178,11848.298762241247,11923.031563746606,11955.820960840176,12026.72319465147,11858.092946626146,11766.964790654874,11688.825145210647,11809.335854336618,11790.812698226946,11523.60305296244,11463.56021619618,11591.948514021771,11598.762201899504,11539.998407428351,11727.575535318543,11561.502060045188,11346.246456888854,11015.800960554194,11117.362166138793,11043.054400226883,11298.340747624477,11348.161740735884,11354.122733750213,11540.849790453502,11577.258549282667,11775.696386056145,11802.097130865432,11914.941457250263,11895.565606277187,11936.446421705352,11842.762804820366,11968.596953570492,11940.065783440943,11956.459826068603,11887.049152349146,11888.113053171026,12001.597556622537,11754.617769032762,11730.557343663962,11702.026173534417,11505.078585014524,11633.891918433563,11684.566918246626,11804.438762144171,11903.870854246761,11966.042804495031,11983.713265741297,11988.610357933747,11953.054293967989,12157.02546448584,12136.011127536774,12166.336892394227,12201.149144071444,12174.239406020617,12222.505870804122,12204.779000513046,12253.686954201483,12143.913641163163,12149.037681373102,12126.826947938767,12237.029232085295,12126.399288668814,12241.085435958601,12325.873477660889,12304.302921293232,12377.983628520977,12479.214250866224,12382.25497386751,12436.074449969163,12437.140974467546,12484.981091819349,12464.478371788327,12457.857524133546,12344.025383545417,12370.722603799517,12366.451258452982,12404.679536936828,12424.755909536148,12387.166496280732,12144.33998859487,12195.5961327533,12169.326571769154,12316.476780266166,12622.731979245134,12720.334056987029,12775.433887222041,12787.607746194968,12747.883972104535,12754.077160489362,12672.06628036527,12509.755157196909,12561.011301355338,12606.9282638306,12611.200921015386,12678.900957655029,12718.197072475508,12761.338185210821,12827.97169735208,12789.101929963304,12868.54816630592,12891.614218280163,12897.594888868265,12977.681302277562,12956.325887383133,12980.886123125714,12914.040093187728,12873.888659827342,12973.411268769278,12906.565238831292,12904.00190688807,12959.10173712308,12905.709920291381,12521.075009468179,12517.230011553347,12667.5745461925,12743.431593079304,12885.074704596967,12885.932646813379,12750.288571619334,12604.787343804324,12558.93072588863,12528.073666539362,12684.716336623454,12757.78835090255,12613.574036412156,12632.001428329473,12439.142839639173,12458.429485611154,12475.572587880357,12702.503551474092,12678.07449955665,12805.360853251066,12922.574912851287,12995.217956022181,13066.147738436754,13028.003417600998,12843.71769188355,12954.076084781991,12896.00362906932,12965.217527051072,12896.217458704297,12809.431487345137,12895.360828326138,12947.645453673662,12992.646753049448,12873.718120854654,12961.145581118744,12971.004045577964,12929.21806175634,13065.718767328544,13065.075966585362,13103.432805217844,13134.289864567112,13079.647865881836,12855.932217842268,12797.432102859644,12733.78827009331,12740.216277525135,12536.857735470681,12732.50266860694,12509.429821310554,12361.357390522811,12494.215121270896,12272.429187299125,12341.21411417267,12012.4989324916,11912.640492957307,11975.855354615436,11816.211198612156,12060.283952636843,12153.285413631103,12021.92711400436,12152.856442522896,12117.713607606329,12121.710778758323,12338.7924607606,12368.453123624597,12220.795233724295,12188.34035538483,11942.887547519678,12023.057918577062,12057.016163552624,12133.317923606648,11535.378113106934,10860.062802944425,10840.719092008509,10670.923275696821,11791.576188089244,11274.881144174802,11476.056787378937],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"PV (Logit)\",\"x\":[\"2024-01-02T00:00:00\",\"2024-01-03T00:00:00\",\"2024-01-04T00:00:00\",\"2024-01-05T00:00:00\",\"2024-01-08T00:00:00\",\"2024-01-09T00:00:00\",\"2024-01-10T00:00:00\",\"2024-01-11T00:00:00\",\"2024-01-12T00:00:00\",\"2024-01-16T00:00:00\",\"2024-01-17T00:00:00\",\"2024-01-18T00:00:00\",\"2024-01-19T00:00:00\",\"2024-01-22T00:00:00\",\"2024-01-23T00:00:00\",\"2024-01-24T00:00:00\",\"2024-01-25T00:00:00\",\"2024-01-26T00:00:00\",\"2024-01-29T00:00:00\",\"2024-01-30T00:00:00\",\"2024-01-31T00:00:00\",\"2024-02-01T00:00:00\",\"2024-02-02T00:00:00\",\"2024-02-05T00:00:00\",\"2024-02-06T00:00:00\",\"2024-02-07T00:00:00\",\"2024-02-08T00:00:00\",\"2024-02-09T00:00:00\",\"2024-02-12T00:00:00\",\"2024-02-13T00:00:00\",\"2024-02-14T00:00:00\",\"2024-02-15T00:00:00\",\"2024-02-16T00:00:00\",\"2024-02-20T00:00:00\",\"2024-02-21T00:00:00\",\"2024-02-22T00:00:00\",\"2024-02-23T00:00:00\",\"2024-02-26T00:00:00\",\"2024-02-27T00:00:00\",\"2024-02-28T00:00:00\",\"2024-02-29T00:00:00\",\"2024-03-01T00:00:00\",\"2024-03-04T00:00:00\",\"2024-03-05T00:00:00\",\"2024-03-06T00:00:00\",\"2024-03-07T00:00:00\",\"2024-03-08T00:00:00\",\"2024-03-11T00:00:00\",\"2024-03-12T00:00:00\",\"2024-03-13T00:00:00\",\"2024-03-14T00:00:00\",\"2024-03-15T00:00:00\",\"2024-03-18T00:00:00\",\"2024-03-19T00:00:00\",\"2024-03-20T00:00:00\",\"2024-03-21T00:00:00\",\"2024-03-22T00:00:00\",\"2024-03-25T00:00:00\",\"2024-03-26T00:00:00\",\"2024-03-27T00:00:00\",\"2024-03-28T00:00:00\",\"2024-04-01T00:00:00\",\"2024-04-02T00:00:00\",\"2024-04-03T00:00:00\",\"2024-04-04T00:00:00\",\"2024-04-05T00:00:00\",\"2024-04-08T00:00:00\",\"2024-04-09T00:00:00\",\"2024-04-10T00:00:00\",\"2024-04-11T00:00:00\",\"2024-04-12T00:00:00\",\"2024-04-15T00:00:00\",\"2024-04-16T00:00:00\",\"2024-04-17T00:00:00\",\"2024-04-18T00:00:00\",\"2024-04-19T00:00:00\",\"2024-04-22T00:00:00\",\"2024-04-23T00:00:00\",\"2024-04-24T00:00:00\",\"2024-04-25T00:00:00\",\"2024-04-26T00:00:00\",\"2024-04-29T00:00:00\",\"2024-04-30T00:00:00\",\"2024-05-01T00:00:00\",\"2024-05-02T00:00:00\",\"2024-05-03T00:00:00\",\"2024-05-06T00:00:00\",\"2024-05-07T00:00:00\",\"2024-05-08T00:00:00\",\"2024-05-09T00:00:00\",\"2024-05-10T00:00:00\",\"2024-05-13T00:00:00\",\"2024-05-14T00:00:00\",\"2024-05-15T00:00:00\",\"2024-05-16T00:00:00\",\"2024-05-17T00:00:00\",\"2024-05-20T00:00:00\",\"2024-05-21T00:00:00\",\"2024-05-22T00:00:00\",\"2024-05-23T00:00:00\",\"2024-05-24T00:00:00\",\"2024-05-28T00:00:00\",\"2024-05-29T00:00:00\",\"2024-05-30T00:00:00\",\"2024-05-31T00:00:00\",\"2024-06-03T00:00:00\",\"2024-06-04T00:00:00\",\"2024-06-05T00:00:00\",\"2024-06-06T00:00:00\",\"2024-06-07T00:00:00\",\"2024-06-10T00:00:00\",\"2024-06-11T00:00:00\",\"2024-06-12T00:00:00\",\"2024-06-13T00:00:00\",\"2024-06-14T00:00:00\",\"2024-06-17T00:00:00\",\"2024-06-18T00:00:00\",\"2024-06-20T00:00:00\",\"2024-06-21T00:00:00\",\"2024-06-24T00:00:00\",\"2024-06-25T00:00:00\",\"2024-06-26T00:00:00\",\"2024-06-27T00:00:00\",\"2024-06-28T00:00:00\",\"2024-07-01T00:00:00\",\"2024-07-02T00:00:00\",\"2024-07-03T00:00:00\",\"2024-07-05T00:00:00\",\"2024-07-08T00:00:00\",\"2024-07-09T00:00:00\",\"2024-07-10T00:00:00\",\"2024-07-11T00:00:00\",\"2024-07-12T00:00:00\",\"2024-07-15T00:00:00\",\"2024-07-16T00:00:00\",\"2024-07-17T00:00:00\",\"2024-07-18T00:00:00\",\"2024-07-19T00:00:00\",\"2024-07-22T00:00:00\",\"2024-07-23T00:00:00\",\"2024-07-24T00:00:00\",\"2024-07-25T00:00:00\",\"2024-07-26T00:00:00\",\"2024-07-29T00:00:00\",\"2024-07-30T00:00:00\",\"2024-07-31T00:00:00\",\"2024-08-01T00:00:00\",\"2024-08-02T00:00:00\",\"2024-08-05T00:00:00\",\"2024-08-06T00:00:00\",\"2024-08-07T00:00:00\",\"2024-08-08T00:00:00\",\"2024-08-09T00:00:00\",\"2024-08-12T00:00:00\",\"2024-08-13T00:00:00\",\"2024-08-14T00:00:00\",\"2024-08-15T00:00:00\",\"2024-08-16T00:00:00\",\"2024-08-19T00:00:00\",\"2024-08-20T00:00:00\",\"2024-08-21T00:00:00\",\"2024-08-22T00:00:00\",\"2024-08-23T00:00:00\",\"2024-08-26T00:00:00\",\"2024-08-27T00:00:00\",\"2024-08-28T00:00:00\",\"2024-08-29T00:00:00\",\"2024-08-30T00:00:00\",\"2024-09-03T00:00:00\",\"2024-09-04T00:00:00\",\"2024-09-05T00:00:00\",\"2024-09-06T00:00:00\",\"2024-09-09T00:00:00\",\"2024-09-10T00:00:00\",\"2024-09-11T00:00:00\",\"2024-09-12T00:00:00\",\"2024-09-13T00:00:00\",\"2024-09-16T00:00:00\",\"2024-09-17T00:00:00\",\"2024-09-18T00:00:00\",\"2024-09-19T00:00:00\",\"2024-09-20T00:00:00\",\"2024-09-23T00:00:00\",\"2024-09-24T00:00:00\",\"2024-09-25T00:00:00\",\"2024-09-26T00:00:00\",\"2024-09-27T00:00:00\",\"2024-09-30T00:00:00\",\"2024-10-01T00:00:00\",\"2024-10-02T00:00:00\",\"2024-10-03T00:00:00\",\"2024-10-04T00:00:00\",\"2024-10-07T00:00:00\",\"2024-10-08T00:00:00\",\"2024-10-09T00:00:00\",\"2024-10-10T00:00:00\",\"2024-10-11T00:00:00\",\"2024-10-14T00:00:00\",\"2024-10-15T00:00:00\",\"2024-10-16T00:00:00\",\"2024-10-17T00:00:00\",\"2024-10-18T00:00:00\",\"2024-10-21T00:00:00\",\"2024-10-22T00:00:00\",\"2024-10-23T00:00:00\",\"2024-10-24T00:00:00\",\"2024-10-25T00:00:00\",\"2024-10-28T00:00:00\",\"2024-10-29T00:00:00\",\"2024-10-30T00:00:00\",\"2024-10-31T00:00:00\",\"2024-11-01T00:00:00\",\"2024-11-04T00:00:00\",\"2024-11-05T00:00:00\",\"2024-11-06T00:00:00\",\"2024-11-07T00:00:00\",\"2024-11-08T00:00:00\",\"2024-11-11T00:00:00\",\"2024-11-12T00:00:00\",\"2024-11-13T00:00:00\",\"2024-11-14T00:00:00\",\"2024-11-15T00:00:00\",\"2024-11-18T00:00:00\",\"2024-11-19T00:00:00\",\"2024-11-20T00:00:00\",\"2024-11-21T00:00:00\",\"2024-11-22T00:00:00\",\"2024-11-25T00:00:00\",\"2024-11-26T00:00:00\",\"2024-11-27T00:00:00\",\"2024-11-29T00:00:00\",\"2024-12-02T00:00:00\",\"2024-12-03T00:00:00\",\"2024-12-04T00:00:00\",\"2024-12-05T00:00:00\",\"2024-12-06T00:00:00\",\"2024-12-09T00:00:00\",\"2024-12-10T00:00:00\",\"2024-12-11T00:00:00\",\"2024-12-12T00:00:00\",\"2024-12-13T00:00:00\",\"2024-12-16T00:00:00\",\"2024-12-17T00:00:00\",\"2024-12-18T00:00:00\",\"2024-12-19T00:00:00\",\"2024-12-20T00:00:00\",\"2024-12-23T00:00:00\",\"2024-12-24T00:00:00\",\"2024-12-26T00:00:00\",\"2024-12-27T00:00:00\",\"2024-12-30T00:00:00\",\"2024-12-31T00:00:00\",\"2025-01-02T00:00:00\",\"2025-01-03T00:00:00\",\"2025-01-06T00:00:00\",\"2025-01-07T00:00:00\",\"2025-01-08T00:00:00\",\"2025-01-10T00:00:00\",\"2025-01-13T00:00:00\",\"2025-01-14T00:00:00\",\"2025-01-15T00:00:00\",\"2025-01-16T00:00:00\",\"2025-01-17T00:00:00\",\"2025-01-21T00:00:00\",\"2025-01-22T00:00:00\",\"2025-01-23T00:00:00\",\"2025-01-24T00:00:00\",\"2025-01-27T00:00:00\",\"2025-01-28T00:00:00\",\"2025-01-29T00:00:00\",\"2025-01-30T00:00:00\",\"2025-01-31T00:00:00\",\"2025-02-03T00:00:00\",\"2025-02-04T00:00:00\",\"2025-02-05T00:00:00\",\"2025-02-06T00:00:00\",\"2025-02-07T00:00:00\",\"2025-02-10T00:00:00\",\"2025-02-11T00:00:00\",\"2025-02-12T00:00:00\",\"2025-02-13T00:00:00\",\"2025-02-14T00:00:00\",\"2025-02-18T00:00:00\",\"2025-02-19T00:00:00\",\"2025-02-20T00:00:00\",\"2025-02-21T00:00:00\",\"2025-02-24T00:00:00\",\"2025-02-25T00:00:00\",\"2025-02-26T00:00:00\",\"2025-02-27T00:00:00\",\"2025-02-28T00:00:00\",\"2025-03-03T00:00:00\",\"2025-03-04T00:00:00\",\"2025-03-05T00:00:00\",\"2025-03-06T00:00:00\",\"2025-03-07T00:00:00\",\"2025-03-10T00:00:00\",\"2025-03-11T00:00:00\",\"2025-03-12T00:00:00\",\"2025-03-13T00:00:00\",\"2025-03-14T00:00:00\",\"2025-03-17T00:00:00\",\"2025-03-18T00:00:00\",\"2025-03-19T00:00:00\",\"2025-03-20T00:00:00\",\"2025-03-21T00:00:00\",\"2025-03-24T00:00:00\",\"2025-03-25T00:00:00\",\"2025-03-26T00:00:00\",\"2025-03-27T00:00:00\",\"2025-03-28T00:00:00\",\"2025-03-31T00:00:00\",\"2025-04-01T00:00:00\",\"2025-04-02T00:00:00\",\"2025-04-03T00:00:00\",\"2025-04-04T00:00:00\",\"2025-04-07T00:00:00\",\"2025-04-08T00:00:00\",\"2025-04-09T00:00:00\",\"2025-04-10T00:00:00\",\"2025-04-11T00:00:00\"],\"y\":[10000.0,9918.333477416903,9886.384968642476,9899.927074911608,10041.25665708719,10026.02424723114,10082.72517605198,10078.282635813637,10085.264238987551,10048.238260261107,9992.383467112419,10081.24345474703,10206.917559230485,10228.499266223278,10197.320721177462,10208.46697080236,10263.990225149111,10250.951166945035,10332.132638035802,10324.14020001872,10155.678280417398,10288.597388696558,10396.90868141016,10359.051205790343,10389.128149279486,10475.77744425761,10480.403512762357,10540.975343350441,10536.34797080947,10391.230907690731,10485.662038835759,10558.010620563058,10505.432532028279,10447.595917420096,10457.058656279769,10673.47324792924,10680.833228377664,10641.715401747322,10661.485242921732,10647.395131521087,10685.671202768819,10785.991361501563,10774.423908176304,10666.74246495891,10720.79281039062,10827.212598561267,10762.225301318615,10752.971860272897,10868.645741507375,10976.057812959625,10954.359748228684,10879.140977586832,10943.79660720575,11004.614631929093,11106.397885333241,11143.10277243896,11121.976490393095,11091.249271404493,11070.76270009049,11163.800382344918,11161.666254583775,11142.248066141545,10865.020532027173,11593.493344981303,11734.413390494477,12443.780539426754,12461.294779430375,12475.708891660493,12350.789308018295,5787.556841928185,5707.67161712085,5636.164976131227,5625.8854648523975,5592.590400959891,5581.082279343794,5532.3688118061855,5583.317120856664,5649.572298662153,5646.890626970413,5625.438634673526,5678.734010745476,5698.844821887235,5608.567860292466,5590.356250065535,5642.645049652625,5712.587439706942,5771.579727904867,5777.947921226918,5778.507667532907,5811.802731425414,5819.2890361224145,5820.069435043781,5846.773581143315,5919.173882490678,5906.9962062247905,5915.487360860364,5922.303074979803,5936.826782339391,5943.667957127887,5900.254193770866,5939.29322772765,5943.443291994637,5901.8247694709025,4736.973618408889,4780.118182504743,4784.015407274579,4789.363726373609,4846.285842843679,4846.195079414595,4840.303300277217,4855.259096425291,4866.951891270961,4906.924217493496,4916.804545097875,4919.796376649187,4958.951832009959,4971.551140610314,4958.045878523353,4951.399418281178,4935.303476588738,4954.308890424618,4960.4920089639945,4968.312230835382,4948.761115888832,4958.94622932915,4992.318597560215,5014.597657792034,5043.514213976734,5049.333718531692,5054.244468259641,5104.256798489575,5060.245499672768,5092.162851698074,5106.166752376919,5136.448121606376,5064.428461163797,5025.5088786650285,4992.136510433964,5043.604977405817,5035.693992105345,4921.572426465225,4895.928956408382,4950.761833205261,4953.6718656167795,4928.574656938687,5008.686269271827,4937.758571318669,4845.825862749362,4704.697134543805,4748.072529088937,4716.336703921802,4201.114432131789,4219.6396030271235,4221.856106701577,4291.287694074317,4304.825731702132,4378.61179273285,4388.428504099131,4430.387933253291,4423.183320737516,4438.38422390807,4398.977689862415,4445.718608522824,4435.120745259494,4441.210289477704,4415.427791747872,4415.822976221023,4457.976636397779,4366.236339529539,4357.2991281583145,4346.701264894984,4273.545358435506,4321.392891076836,4340.216048923138,4384.742277780254,4421.676189404119,4444.769873418973,4451.333541548867,4453.152559598525,4439.945309339234,4515.710115514186,4507.904369428606,4519.168832395107,4532.099794619531,4522.104210035379,4540.032720911638,4533.4480997208975,4551.61489075421,4510.839747068878,4512.743064642402,4504.492918754707,4545.427403158561,4504.3340653166715,4546.934074417479,4578.428473989822,4576.087698083554,4603.490256366436,4641.138891038928,4605.078810469792,4625.0947873261375,4625.49143796681,4643.283634232525,4635.658476959386,4633.196120522151,4590.860860936627,4523.890989627553,4522.328987039212,4536.308814258757,4543.650610208379,4529.90441175435,4441.1043727149645,4459.848403775055,4450.241800018443,4504.053652701728,4616.04914233966,4651.741573105982,4671.891214603369,4676.34311387235,4661.816393854675,4664.081201661665,4634.090368181101,4574.734269824151,4593.47830088424,4610.269828708904,4649.364203234574,4686.784011594707,4701.309908064244,4688.200684644736,4712.680192413205,4698.400399225432,4727.586985632612,4736.06088383108,4738.258034595274,4731.0933515376255,4736.053257802811,4743.768714299645,4684.25110139422,4669.687154357989,4705.786538221278,4681.539781427792,4680.60999567588,4700.596106807836,4681.229535619069,4561.456398081064,4043.03046380577,4091.59133015174,4100.444216889207,4146.020612324188,4146.2966717336185,4102.65058161871,4055.832763059669,4041.077514258347,4031.1486619209886,4081.5514538199322,4105.063779850692,4058.6600504057974,4064.589418179918,4002.533457907645,4008.7393072003856,4014.2554300787374,4087.2748323099518,4079.414314997381,4120.371147470876,4158.087025593285,4181.46132191933,4204.28434364489,3888.0356018995453,3282.8809372963956,3311.08877189758,3296.245331515705,3313.9365476986836,3296.299986814843,3274.117312153613,3296.081030309708,3309.4450892204336,3320.947514874627,3290.5491092963302,3312.8957498549744,3315.4155938612494,3304.7350095456295,3339.624873602177,3339.4605723961795,3875.7551508984384,3884.8821032392693,3868.7200019786355,3802.549015481061,3785.245754164548,3766.4210754460964,3768.3223621763946,3708.1726343483638,3766.0408181000366,3700.059960275492,3656.2628503988253,3695.559730990186,3629.959518529401,3650.3048386143905,3264.3265001607942,3237.1905518232834,3254.368821663248,3210.986453684197,3277.3118005922406,3302.584405017294,3266.888553479874,3302.467834621393,3292.917974267305,3294.0041822070903,3352.9948627675526,3361.054974851092,3320.9298047538323,3312.110380917177,3245.41001242966,3267.195843025032,3276.4237979739264,3297.1583560998433,2743.2518459229914,2529.23814250034,2542.2156685478312,2502.3974995668045,2598.6611004093847,2400.886986342645,2443.725573957154],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Portfolio\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d1ed3b0a-9101-4ec0-a577-b8802861a60d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_capital = 10000 # scalar\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "df = spy_data[initial_train_period:].copy()\n",
    "df.loc[initial_train_period, 'Strategy_Return'] = 0\n",
    "df['Portfolio_Value'] = (1 + df['Strategy_Return']).cumprod() * initial_capital\n",
    "fig.add_trace(go.Scatter(x=df['Date'], y=df['Portfolio_Value'], mode='lines', name='PV SPY_Hold'))\n",
    "\n",
    "df_to_build.loc[initial_train_period, 'Strategy_Return'] = 0\n",
    "df_to_build['Portfolio_Value'] = (1 + df_to_build['Strategy_Return']).cumprod() * initial_capital\n",
    "fig.add_trace(go.Scatter(x=df_to_build['Date'], y=df_to_build['Portfolio_Value'], mode='lines', name=\"PV (Logit)\"))\n",
    "\n",
    "fig.update_layout(title=\"Portfolio\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

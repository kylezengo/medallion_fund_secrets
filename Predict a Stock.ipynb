{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a434b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import urllib.parse\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pytz\n",
    "import tensorflow as tf\n",
    "from astral import LocationInfo\n",
    "from astral.sun import sun\n",
    "from keras import layers, models\n",
    "from prophet import Prophet\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import strat_defs # custom functions\n",
    "import prep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138eb238-b332-428a-83a1-c16af5fd380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_powerset(some_list):\n",
    "    powerset = [[]]\n",
    "\n",
    "    for i in some_list:\n",
    "        powerset += [x+[i] for x in powerset]\n",
    "\n",
    "    return powerset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c852914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress prophet logging (prophet prints something each time)\n",
    "for lib in [\"prophet\", \"cmdstanpy\"]:\n",
    "    logger = logging.getLogger(lib)\n",
    "    logger.setLevel(logging.ERROR)  # Set logging level\n",
    "    \n",
    "    # Remove all existing handlers\n",
    "    while logger.hasHandlers():\n",
    "        logger.removeHandler(logger.handlers[0])\n",
    "    \n",
    "    # Add a NullHandler to prevent logs from propagating\n",
    "    logger.addHandler(logging.NullHandler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cea3f2-6dac-4182-a8b6-9c7e248b405d",
   "metadata": {},
   "source": [
    "### Build dataframe for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cacd5d85-7370-439e-882b-5d174604529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "moving_average_config = prep_data.MovingAverageConfig(short_window=10, long_window=50)\n",
    "bollinger_config = prep_data.BollingerConfig(window=90, num_std=3.0)\n",
    "macd_config = prep_data.MACDConfig(short_window=12, long_window=26)\n",
    "\n",
    "indicator_config = prep_data.IndicatorConfig(\n",
    "    ticker='SPY',\n",
    "    target='Adj Close', # probably should always be Adj Close\n",
    "    rsi_window = 30,\n",
    "    moving_average=moving_average_config,\n",
    "    bollinger=bollinger_config,\n",
    "    macd=macd_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aa2daee-41ff-42e3-86b2-aab6fd0f1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df, wiki_pageviews, ffr_raw, weather, gt_adjusted = prep_data.load_data()\n",
    "\n",
    "prepd_data = prep_data.prep_data(\n",
    "    stocks_df,\n",
    "    wiki_pageviews,\n",
    "    ffr_raw,\n",
    "    weather,\n",
    "    gt_adjusted,\n",
    "    config=indicator_config,drop_tickers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b6c35",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Set configuration and parameters for model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2db9ea38-1a36-4a8a-b2fb-a95218a546e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "keras_config = strat_defs.KerasConfig(proba=0.5, sequence_length=30, epochs=20)\n",
    "proba_config = strat_defs.ProbaConfig(knn = 0.5, logit = 0.5, mlp = 0.5, rf = 0.5, svc = 0.5, xgboost = 0.5)\n",
    "\n",
    "backtest_config = strat_defs.BacktestConfig(\n",
    "    overbought = 70,\n",
    "    retrain_days = 10,\n",
    "    logit_warm_start = False, # true with drop tickers = false fails. not sure why. true with drop tickers = True fails. not sure why.    \n",
    "    proba = proba_config,\n",
    "    keras = keras_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df6292-7ba4-4a24-873e-2c1d0487c7ee",
   "metadata": {},
   "source": [
    "**s_date**\\\n",
    "data start date S&P 500 minimum is 1993-01-29, Wikipedia page views minimum is 2015-07-01\n",
    "\n",
    "**exclude_vars**\\\n",
    "enum {\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\",\"movement\", \"views\"}\n",
    "\n",
    "**strategy_list**\\\n",
    "enum {\"Hold\", \"SMA\", \"RSI\", \"VWAP\", \"Bollinger\", \"Breakout\", \"Prophet\", \"KNN\", \"LinearSVC\", \"Logit\",\n",
    "\"MLP\", \"RandomForest\", \"SVC\", \"SVC_proba\", \"GradientBoosting\", \"XGBoost\", \"Keras\", \"Perfection\"}\n",
    "\n",
    "From fast to slow (usually - times with drop_tickers=True):\\\n",
    "Hold, Perfection, SMA, RSI, VWAP, Bollinger, Breakout, KNN(*4s*), LinearSVC(*5s*), Logit(*20s*), XGBoost(*24s*), SVC(*102s*), Prophet(*160s*), SVC_proba(*200s*), MLP(*2978s*), Keras(*4048s*)\n",
    "\n",
    "\\\n",
    "*If testing Breakout, \"High\" and \"Low\" cannot be excluded*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c88598b0-2602-4f9a-bec4-fd0eeecd5252",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_date = \"2015-07-01\"\n",
    "exclude_vars = (\"Open\",\"High\",\"Low\",\"Close\",\"Volume\")\n",
    "\n",
    "# initial_train_period = 1890 # 2015-07-01 start predicting in 2023\n",
    "initial_train_period = 2140 # 2015-07-01 start predicting in 2024\n",
    "# initial_train_period = 7535 # 1993-01-29 start predicting in 2024\n",
    "random_state = 42\n",
    "n_jobs = None\n",
    "                                                     \n",
    "# Strategies to test\n",
    "# strategy_list = [\"Hold\", \"KNN\", \"LinearSVC\", \"Logit\", \"XGBoost\", \"SVC\"]\n",
    "strategy_list = [\"Hold\", \"GradientBoosting\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc9c206-2049-4107-8a42-a45f2a78916a",
   "metadata": {},
   "source": [
    "### Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "176ac32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on data set with 2499 rows and 32 features\n",
      "\n",
      "Hold score = None, time = 0.002488851547241211\n",
      "\n",
      "GradientBoosting "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'GradientBoostingClassifier' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:15\u001b[0m\n",
      "File \u001b[0;32m~/Documents/GitHub/medallion_fund_secrets/strat_defs.py:804\u001b[0m, in \u001b[0;36mbacktest_strategy\u001b[0;34m(data, strategy, target, ticker, config, random_state, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;66;03m# data, model, score = strat_gradient_boost(\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;66;03m#     data, initial_train_period, config.retrain_days,random_state\u001b[39;00m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    802\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpca__n_components\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0.6\u001b[39m,\u001b[38;5;241m0.65\u001b[39m,\u001b[38;5;241m0.7\u001b[39m,\u001b[38;5;241m0.75\u001b[39m,\u001b[38;5;241m0.8\u001b[39m,\u001b[38;5;241m0.85\u001b[39m,\u001b[38;5;241m0.9\u001b[39m,\u001b[38;5;241m0.95\u001b[39m]\n\u001b[1;32m    803\u001b[0m     }\n\u001b[0;32m--> 804\u001b[0m     data, model, score \u001b[38;5;241m=\u001b[39m generic_sklearn_strategy(\n\u001b[1;32m    805\u001b[0m             data, initial_train_period, GradientBoostingClassifier(), param_grid,\n\u001b[1;32m    806\u001b[0m             config\u001b[38;5;241m.\u001b[39mretrain_days, use_proba\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, proba_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    807\u001b[0m             n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     )\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m strategy \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    811\u001b[0m     initial_train_period \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial_train_period\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/medallion_fund_secrets/strat_defs.py:184\u001b[0m, in \u001b[0;36mgeneric_sklearn_strategy\u001b[0;34m(data, initial_train_period, model_cls, param_grid, retrain_days, use_proba, proba_threshold, random_state, n_jobs, **model_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m train_data[feats], train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# Grid search for best parameters\u001b[39;00m\n\u001b[1;32m    181\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m make_pipeline(\n\u001b[1;32m    182\u001b[0m     StandardScaler(),\n\u001b[1;32m    183\u001b[0m     PCA(svd_solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m--> 184\u001b[0m     model_cls(random_state\u001b[38;5;241m=\u001b[39mrandom_state, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m    185\u001b[0m )\n\u001b[1;32m    187\u001b[0m search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39mTimeSeriesSplit(), n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)\n\u001b[1;32m    188\u001b[0m search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'GradientBoostingClassifier' object is not callable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_for_chart = prepd_data.loc[prepd_data['Date']>=s_date].reset_index(drop=True)\n",
    "df_for_chart = df_for_chart.drop(columns=[\n",
    "    col for col in df_for_chart.columns \n",
    "    if any(col.startswith(prefix) for prefix in exclude_vars) and col != indicator_config.target+\"_\"+indicator_config.ticker\n",
    "])\n",
    "df_for_chart = df_for_chart.dropna(axis='columns') # drop columns with an na\n",
    "\n",
    "print(f'Training on data set with {len(df_for_chart)} rows and {df_for_chart.shape[1]-1} features')\n",
    "\n",
    "# Calculate portfolio value over time\n",
    "strat_bds, strat_mods = {}, {}\n",
    "for strat in strategy_list:\n",
    "    start_time = time.time()\n",
    "    print(f'\\n{strat}', end=\" \")\n",
    "    backtested_data,model,score = strat_defs.backtest_strategy(\n",
    "        data=df_for_chart,\n",
    "        strategy=strat,\n",
    "        target=indicator_config.target,\n",
    "        ticker=indicator_config.ticker,\n",
    "        config=backtest_config,\n",
    "        initial_train_period=initial_train_period,\n",
    "        random_state=random_state,\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f'score = {score}, time = {end_time-start_time}')\n",
    "    \n",
    "    strat_bds[strat] = backtested_data\n",
    "    strat_mods[strat] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bad6a198-002c-438a-be93-3a839884e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_strats = [x for x in strategy_list if x not in [\"Hold\",\"LinearSVC\",\"SVC\",\"Prophet\"]]\n",
    "\n",
    "combos = [x for x in gen_powerset(proba_strats) if len(x) > 1]\n",
    "\n",
    "mod_mod_dic = {}\n",
    "for mods in combos:\n",
    "    # Model of models\n",
    "    if indicator_config.ticker == \"SPY\":\n",
    "        df_prev = strat_bds[mods[0]][['Date','Daily_Return','Target','proba_1','Signal']]\n",
    "    else:\n",
    "        df_prev = strat_bds[mods[0]][['Date','Daily_Return_SPY','Daily_Return','Target','proba_1','Signal']]\n",
    "\n",
    "    df_prev = df_prev.rename(columns={'proba_1': 'proba_1'+mods[0], 'Signal': 'Signal_'+mods[0]})\n",
    "\n",
    "    for i in mods[1:]:\n",
    "        mod_mod = strat_bds[i][['Date','proba_1','Signal']].rename(columns={'proba_1': 'proba_1'+i, 'Signal': 'Signal_'+i})\n",
    "        mod_mod = mod_mod.merge(df_prev,on='Date')\n",
    "        df_prev = mod_mod\n",
    "\n",
    "    # All strats predict 0\n",
    "    signal_columns = mod_mod.columns[mod_mod.columns.str.contains('Signal')]\n",
    "\n",
    "    mod_mod['Signal_all0'] = np.where(mod_mod[signal_columns].eq(0).all(axis=1), 0, 1) \n",
    "\n",
    "    mod_mod['Strategy_Return_all0'] = mod_mod['Signal_all0'].shift(1) * mod_mod['Daily_Return']\n",
    "\n",
    "    # Using strategy with most confident prediction (furthest from 50%)\n",
    "    proba_cols = [col for col in mod_mod.columns if col.startswith('proba_1')]\n",
    "\n",
    "    for i in proba_cols:\n",
    "        mod_mod[\"dist_\"+i] = abs(mod_mod[i] - 0.5)\n",
    "\n",
    "    dist_cols = [col for col in mod_mod.columns if col.startswith('dist_')]\n",
    "\n",
    "    mask = mod_mod[proba_cols].notna().any(axis=1)\n",
    "    mod_mod.loc[mask, 'proba_1max_col'] = mod_mod.loc[mask, proba_cols].idxmax(axis=1, skipna=True)\n",
    "    mod_mod['proba_1max_col'] = mod_mod['proba_1max_col'].str.replace(\"dist_\",\"\")\n",
    "    \n",
    "    mod_mod['yesterday_proba_1max_col'] = mod_mod['proba_1max_col'].shift(1)\n",
    "    \n",
    "    mod_mod['yesterday_proba_1max'] = mod_mod.apply(\n",
    "        lambda row: row[row['yesterday_proba_1max_col']] if pd.notnull(row['yesterday_proba_1max_col']) else 1, axis=1\n",
    "    )\n",
    "\n",
    "    mod_mod['Signal'] = mod_mod['yesterday_proba_1max'].round()\n",
    "\n",
    "    mod_mod['Strategy_Return'] = mod_mod['Signal'].shift(1) * mod_mod['Daily_Return']\n",
    "\n",
    "    if indicator_config.ticker != \"SPY\":\n",
    "        mod_mod.loc[:initial_train_period, 'Strategy_Return'] = mod_mod['Daily_Return_SPY']\n",
    "\n",
    "    mod_mod.loc[0, 'Strategy_Return'] = np.nan\n",
    "\n",
    "    mod_mod_dic[\"_\".join(mods)] = mod_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f7ed1-e8d0-4948-9ad2-aabe5ee9c951",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c62efc5b-df52-40a3-9ce6-56045f2a7628",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GradientBoosting'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     fig\u001b[38;5;241m.\u001b[39madd_trace(go\u001b[38;5;241m.\u001b[39mScatter(x\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], y\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPortfolio_Value\u001b[39m\u001b[38;5;124m'\u001b[39m], mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPV SPY_Hold\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m strat \u001b[38;5;129;01min\u001b[39;00m strategy_list:\n\u001b[0;32m---> 14\u001b[0m     df \u001b[38;5;241m=\u001b[39m strat_bds[strat][initial_train_period:]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     15\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[initial_train_period, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrategy_Return\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPortfolio_Value\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrategy_Return\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcumprod() \u001b[38;5;241m*\u001b[39m initial_capital\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GradientBoosting'"
     ]
    }
   ],
   "source": [
    "initial_capital = 10000 # scalar\n",
    "\n",
    "# Plot Daily Portfolio Value\n",
    "fig = go.Figure()\n",
    "\n",
    "if indicator_config.ticker != \"SPY\":\n",
    "    df = strat_bds['Hold'][initial_train_period:].copy()\n",
    "    df.loc[initial_train_period, 'Strategy_Return'] = 0\n",
    "    df['Portfolio_Value'] = (1 + df['Daily_Return_SPY']).cumprod() * initial_capital\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=df['Date'], y=df['Portfolio_Value'], mode='lines', name='PV SPY_Hold'))\n",
    "\n",
    "for strat in strategy_list:\n",
    "    df = strat_bds[strat][initial_train_period:].copy()\n",
    "    df.loc[initial_train_period, 'Strategy_Return'] = 0\n",
    "    df['Portfolio_Value'] = (1 + df['Strategy_Return']).cumprod() * initial_capital\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=df['Date'], y=df['Portfolio_Value'], mode='lines', name=f'PV ({strat})'))\n",
    "\n",
    "try:\n",
    "    for mods in combos:\n",
    "        df = mod_mod_dic[\"_\".join(mods)][initial_train_period:].copy()\n",
    "        df.loc[initial_train_period, 'Strategy_Return'] = 0\n",
    "        df['Portfolio_Value'] = (1 + df['Strategy_Return']).cumprod() * initial_capital\n",
    "\n",
    "        fig.add_trace(go.Scatter(x=df['Date'], y=df['Portfolio_Value'], mode='lines', name=f\"Portfolio Value ({'_'.join(mods)})\"))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "fig.update_layout(title=\"Portfolio\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04f66c-7d4d-493e-b16a-760303355156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % right\n",
    "dat = []\n",
    "for i in strategy_list:\n",
    "    after_train = strat_bds[i][initial_train_period:]\n",
    "    cc = after_train.dropna().reset_index(drop=True)\n",
    "    cc['win'] = cc['Target']==cc['Signal']\n",
    "\n",
    "    win = cc['win'].value_counts(normalize=True)[True]\n",
    "    dat.append(f'{win:.2%}')\n",
    "\n",
    "try:\n",
    "    combos_join = [\"_\".join(x) for x in combos]\n",
    "    for i in combos_join:\n",
    "        cc = mod_mod_dic[i].dropna().reset_index(drop=True)\n",
    "        cc['win'] = cc['Target']==cc['Signal']\n",
    "\n",
    "        win = cc['win'].value_counts(normalize=True)[True]\n",
    "        dat.append(f'{win:.2%}')\n",
    "\n",
    "    review = pd.DataFrame({'strategy': strategy_list+combos_join, 'pct_right': dat})\n",
    "except:\n",
    "    review = pd.DataFrame({'strategy': strategy_list, 'pct_right': dat})\n",
    "\n",
    "review.sort_values(by='pct_right', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e3c56f-2d1d-4112-acaa-1a4899c9fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will this ticker go up tomorrow?\n",
    "for i in strategy_list:\n",
    "    if 'proba_1' in strat_bds[i].columns:\n",
    "        print(f'{i}: {strat_bds[i]['Signal'].iloc[-1]} (prob_1: {strat_bds[i]['proba_1'].iloc[-1]})')\n",
    "    else:\n",
    "        print(f'{i}: {strat_bds[i]['Signal'].iloc[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ae749-426c-4a1c-b85f-63d3f19c504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the case where signal is 0 across everything, how often does the market actually go down?\n",
    "KNN_Logit_XGBoost = mod_mod_dic['KNN_Logit_XGBoost']\n",
    "KNN_Logit_XGBoost_all0= KNN_Logit_XGBoost.loc[KNN_Logit_XGBoost['Signal_all0']==0]\n",
    "KNN_Logit_XGBoost_all1= KNN_Logit_XGBoost.loc[KNN_Logit_XGBoost['Signal_all0']==1]\n",
    "print(f'There are {len(KNN_Logit_XGBoost_all0)} case(s) where signal is 0 across everything.')\n",
    "print(f'There are {len(KNN_Logit_XGBoost_all1)} case(s) where signal is 1 across everything.')\n",
    "print(f'Of these, there are {sum(KNN_Logit_XGBoost_all1['Target'])} case(s) where Target is 1.')\n",
    "print(sum(KNN_Logit_XGBoost_all1['Target'])/len(KNN_Logit_XGBoost_all1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26204e12-7473-4cb1-80fa-8b112080c621",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "# Testing ##############################################################################################\n",
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb386e-e94c-46af-b841-760cce382ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(strat_bds['Logit']['proba_1'].dropna(),nbins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f97ef1-fa82-4516-8d2a-45740ded3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(strat_bds['KNN']['proba_1'].dropna(),nbins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc010bf-4b4a-464c-a23f-302d743e6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(strat_bds['XGBoost']['proba_1'].dropna(),nbins=50)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
